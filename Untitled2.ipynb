{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 16.430912971496582 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.6632180213928223 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.7620930671691895 seconds.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/master_data_7_final.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    554\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# keep track of field objects by cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                                     \u001b[0mfield\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                         \u001b[0;32melif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_clusterspec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mz_cutoff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_clusterphot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mz_cutoff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#SF_cutoff[1]: #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m                             \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'member'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m         \u001b[0;31m# member=2 for FALSE POSITIVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "run master_data_7_final.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.01)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "z_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 15.342469692230225 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.587813138961792 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.6585428714752197 seconds.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SF_cutoff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/master_data_7_final.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# keep track of field objects by cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m                             \u001b[0mfield\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0;32melif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_clusterspec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mSF_cutoff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_clusterphot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mSF_cutoff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#z_cutoff[cutoff]: #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                     \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'member'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m         \u001b[0;31m# member=2 for FALSE POSITIVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SF_cutoff' is not defined"
     ]
    }
   ],
   "source": [
    "run master_data_7_final.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 13.979583024978638 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.5765738487243652 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.630958080291748 seconds.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cutoff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/master_data_7_final.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# keep track of field objects by cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m                             \u001b[0mfield\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0;32melif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_clusterspec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mz_cutoff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_clusterphot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mz_cutoff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#SF_cutoff[1]: #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                     \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'member'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m         \u001b[0;31m# member=2 for FALSE POSITIVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cutoff' is not defined"
     ]
    }
   ],
   "source": [
    "run master_data_7_final.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 14.196934938430786 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.5310931205749512 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.5970911979675293 seconds.\n",
      "\n",
      "\n",
      "(SPEC+PHOT) Subsample\n",
      "Catalogue by MEMBER - Star-forming:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  1916      378      334      260      216       227       501\n",
      "Secure member    99       10       20       23       13        14        19\n",
      " Secure field   711      146      149       50       90        76       200\n",
      "    Fasle pos    61       21        9        8        5         8        10\n",
      "    False neg    10        2        1        1        1         0         5\n",
      "NOTE: Total (row) reported under each cluster is sum of SF+Q.\n",
      "\n",
      "Catalogue by MEMBER - Quiescent:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  1916      378      334      260      216       227       501\n",
      "Secure member   730      128      126      143       76        96       161\n",
      " Secure field    54       22        4        7        5         6        10\n",
      "    Fasle pos    31        9        2        9        2         3         6\n",
      "    False neg    47        3        7        5        0         7        25\n",
      "NOTE: Total reported under each cluster is sum of SF+Q.\n",
      "NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SF_cutoff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/master_data_7_final.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0mSF_specphot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0mQ_specphot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nOverall membership fraction: \\nSF: %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSF_specphot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' & Q: %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mQ_specphot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'   for cutoff:\\nSF: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'    Q: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTotal catalogue length: %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SF_cutoff' is not defined"
     ]
    }
   ],
   "source": [
    "run master_data_7_final.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 14.288748025894165 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.5361409187316895 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.6176910400390625 seconds.\n",
      "\n",
      "\n",
      "(SPEC+PHOT) Subsample\n",
      "Catalogue by MEMBER - Star-forming:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  1916      378      334      260      216       227       501\n",
      "Secure member    99       10       20       23       13        14        19\n",
      " Secure field   711      146      149       50       90        76       200\n",
      "    Fasle pos    61       21        9        8        5         8        10\n",
      "    False neg    10        2        1        1        1         0         5\n",
      "NOTE: Total (row) reported under each cluster is sum of SF+Q.\n",
      "\n",
      "Catalogue by MEMBER - Quiescent:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  1916      378      334      260      216       227       501\n",
      "Secure member   730      128      126      143       76        96       161\n",
      " Secure field    54       22        4        7        5         6        10\n",
      "    Fasle pos    31        9        2        9        2         3         6\n",
      "    False neg    47        3        7        5        0         7        25\n",
      "NOTE: Total reported under each cluster is sum of SF+Q.\n",
      "NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\n",
      "\n",
      "\n",
      "Overall membership fraction: \n",
      "SF: 0.11237230419977298  & Q: 0.8468677494199536    for cutoff:\n",
      "[0.015, 0.08]\n",
      "\n",
      "Total catalogue length: 44465\n",
      "SPEC+PHOT sub-sample: 1916\n",
      "SF: 881\n",
      "Q: 862\n",
      "Lost due to buffer b/w member & field\n",
      "SF: 19 ;    Q: 2\n",
      "Other (not in (spec + phot) subsample): 42549\n",
      "NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\n",
      "\n",
      "Section 4 took: 0.3282201290130615 seconds.\n",
      "\n",
      "\n",
      "PHOT-ONLY Subsample\n",
      "Catalogue by MEMBER - Star-forming:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  3444      381      524      649      555       533       802\n",
      "Secure member  2846      381      393      479      513       448       632\n",
      " Secure field   598        0      131      170       42        85       170\n",
      "NOTE: Total reported under each cluster is sum of SF+Q.\n",
      "\n",
      "Catalogue by MEMBER - Quiescent:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  3187      318      552      718      470       483       646\n",
      "Secure member  2913      318      490      616      456       453       580\n",
      " Secure field   274        0       62      102       14        30        66\n",
      "Lost due to buffer b/w member & field\n",
      "SF: 630 ;    Q: 318\n",
      "NOTE: Total reported under each cluster is sum of SF+Q.\n",
      "NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\n",
      "\n",
      "\n",
      "Overall membership fraction: \n",
      "SF: 0.101704605  & Q: 0.49760848    for cutoff: [0.015, 0.08]\n",
      "\n",
      "Total catalogue length: 44465\n",
      "PHOT ONLY sub-sample: 33837\n",
      "SF (members + field): 3444\n",
      "Q (members + field): 3187\n",
      "Field outliers (z>0.55 or z<0.3): 26258\n",
      "Lost due to buffer b/w definition of cluster member/field: 948\n",
      "Stars & outliers: 0\n",
      "Sum of the above: 33837\n",
      "Difference between # in PHOT-ONLY subsample & sum above: 0\n",
      "Other (not in phot only subsample): 10628\n",
      "NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\n",
      "\n",
      "Section 5 took: 2.452899932861328 seconds.\n",
      "\n",
      "\n",
      "Total BCGs removed from catalogue: 0 .\n",
      "BCGs removed by cluster: [0 0 0 0 0 0]\n",
      "Section 6 took: 0.0658869743347168 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run master_data_7_final.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/spec_completeness_binning.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mQ_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mQ_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpos_by_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#for tracking false pos/neg by cluster; row_1=SF, row_2=Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mneg_by_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mobjects_below_lim_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# for tracking objects below the limiting mass of each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "run spec_completeness_binning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/spec_completeness_binning.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtime_flag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "run spec_completeness_binning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'limiting_mass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d3b7dffabeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimiting_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m           \u001b[0;31m# only look at objects above the limiting mass for each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lmass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlimiting_mass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'limiting_mass' is not defined"
     ]
    }
   ],
   "source": [
    "## SECTION (3.2): calculate SPECTROSCOPIC COMPLETENESS correction. basically, look at all the false positives/false negatives, and sort them by type (i.e. SF/Q). then bin them (i.e. make histograms of false pos/neg for each of SF/Q). take their ratio of false pos to false neg, and plot that ratio. it is the correction factor to be applied to the photometric subsample\n",
    "#\n",
    "## TIME_FLAG: START\n",
    "## superior time_flag which supercedes all others and times the entire program\n",
    "time_flag = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag == 1:\n",
    "    start_time = time.time()\n",
    "#\n",
    "#\n",
    "## MODULES\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "#\n",
    "##\n",
    "#\n",
    "SF_pos = []\n",
    "SF_neg = []\n",
    "Q_pos = []\n",
    "Q_neg = []\n",
    "pos_by_cluster = np.array([[0]*6]*2)    #for tracking false pos/neg by cluster; row_1=SF, row_2=Q\n",
    "neg_by_cluster = np.array([[0]*6]*2)\n",
    "objects_below_lim_mass = np.array([0]*6)    # for tracking objects below the limiting mass of each cluster\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    for ii in range(len(limiting_mass)):\n",
    "        if master_cat['cluster'][counter] == (ii+1):           # only look at objects above the limiting mass for each cluster\n",
    "            if master_cat['lmass'][counter] > limiting_mass[ii]:      \n",
    "                if master_cat['type'][counter] == 1:      # type=1 for SF\n",
    "                    if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                        SF_pos.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[0])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                pos_by_cluster[0]+=1           # track false pos for SF\n",
    "                    elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                        SF_neg.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[0])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                neg_by_cluster[0]+=1           # track false neg for SF\n",
    "                elif master_cat['type'][counter] == 2:     # type=2 for Q\n",
    "                    if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                        Q_pos.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[1])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                pos_by_cluster[1]+=1           # track false pos for Q\n",
    "                    elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                        Q_neg.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(neg_by_cluster[1])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                neg_by_cluster[1]+=1           # track false neg for Q\n",
    "            else: \n",
    "                objects_below_lim_mass[ii]+=1\n",
    "#\n",
    "#\n",
    "#\n",
    "## sort false pos/neg lists in ascending order\n",
    "SF_pos = np.sort(SF_pos)\n",
    "SF_neg = np.sort(SF_neg)\n",
    "Q_pos = np.sort(Q_pos)\n",
    "Q_neg = np.sort(Q_neg)\n",
    "#\n",
    "#\n",
    "#\n",
    "## open a file to print to\n",
    "f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/binning_%s'%z_cutoff[0]+'_spec_cutoff_%s'%z_cutoff[1]+'_phot_cutoff.txt','w+')\n",
    "#\n",
    "## to be used in building strings throughout program\n",
    "space = ' '   \n",
    "## write a header for the file, start with hashtag to identify comment\n",
    "header1 = \"### COLS:\\n###(1)z_spec_cutoff  (2)z_phot_cutoff  (3)type[SF/Q]  (4)binning_method  (5)#_of_bins variance[SF/Q]  (6)total_variance[SF+Q]\\n\"\n",
    "#\n",
    "f.write(header1)\n",
    "#\n",
    "#\n",
    "# SPEC. BINNING: iterate through different number of histogram bins to see which yields a set of corrections closest in general to ~1; this has now been expanded to test: method = 1, SYMMETRIC binning; method = 2, ASYMMETRIC binning, EQUAL NUMBER of objects in each bin; method = 2, ASYMMETRIC binning, equal MASS in each bin;\n",
    "#\n",
    "#\n",
    "### METHOD 1: bin SF & Q in SYMMETRIC BINS, then compute false pos/neg fractions by mass bin for correction factors. \n",
    "#\n",
    "## number of histogram mass bins to try for spec. completeness correction\n",
    "num_bins_to_try = [2,3,4,5,6,7,8]   \n",
    "# write a loop that interatively uses a different number of bins in the histrogram, to isolate the largest number for which all bins have at least one entry; NOTE: the lines that stop the loop have been commented out, to investigate the relative fraction of false pos/neg for each different # of bins\n",
    "#\n",
    "# \n",
    "method = 1\n",
    "for number in range(len(num_bins_to_try)):\n",
    "    #\n",
    "    # make histograms\n",
    "    SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=num_bins_to_try[number], range=range2)\n",
    "    SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=num_bins_to_try[number], range=range2)\n",
    "    Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=num_bins_to_try[number], range=range2)\n",
    "    Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=num_bins_to_try[number], range=range2)\n",
    "    #\n",
    "    SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "    Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "    for jj in range(len(SF_pos_hist)):\n",
    "        if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            SF_ratio[jj] = 1\n",
    "    for jj in range(len(Q_pos_hist)):\n",
    "        if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            Q_ratio[jj] = 1\n",
    "    #\n",
    "    ## compute variance of SF/Q ratios from 1\n",
    "    SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    total_var = SF_var + Q_var\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "#\n",
    "#\n",
    "#\n",
    "### METHOD 2: ASYMMETRIC BINS for bins with ~EQUAL NUMBER OF OBJECTS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "#\n",
    "method = 2\n",
    "#\n",
    "##\n",
    "for number in range(len(num_bins_to_try)):    #number of bin EDGES (i.e. # of bins + 1)\n",
    "    ## compute the index corresponding to the first evenly-space bin edge\n",
    "    SF_pos_index = int(np.ceil(len(SF_pos))/(num_bins_to_try[number]))\n",
    "    SF_neg_index = int(np.ceil(len(SF_neg))/(num_bins_to_try[number]))\n",
    "    Q_pos_index = int(np.ceil(len(Q_pos))/(num_bins_to_try[number]))\n",
    "    Q_neg_index = int(np.ceil(len(Q_neg))/(num_bins_to_try[number]))\n",
    "    ## build arrays over range [7.3,12.3] with \"num_bins_to_try[number]\" bins, where each bin has ~equal # of objects in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "    num_bins_SF = [[],[]]     # [pos, neg]  i.e. bin edges of mass bins\n",
    "    num_bins_Q = [[],[]]     # [pos, neg]\n",
    "    #a=0\n",
    "    #b=0\n",
    "    for ii in range(num_bins_to_try[number]):   # -1 b/c there are 1 fewer bins than bin edges\n",
    "        num_bins_SF[0].append(SF_pos[(ii*SF_pos_index)])\n",
    "        num_bins_SF[1].append(SF_neg[(ii*SF_neg_index)])\n",
    "        num_bins_Q[0].append(Q_pos[(ii*Q_pos_index)])\n",
    "        num_bins_Q[1].append(Q_neg[(ii*Q_neg_index)])\n",
    "    #\n",
    "    num_bins_SF[0].append(SF_pos[-1])\n",
    "    num_bins_SF[1].append(SF_neg[-1])\n",
    "    num_bins_Q[0].append(Q_pos[-1])\n",
    "    num_bins_Q[1].append(Q_neg[-1])\n",
    "    #\n",
    "    num_bins_SF = np.array(num_bins_SF)\n",
    "    num_bins_Q = np.array(num_bins_Q)\n",
    "    #print('# bins: %s'%(num_bins_to_try[number]))\n",
    "    #print('length of num_bins_* array (which stores bin edges): %s'%len(num_bins_SF[0]))\n",
    "    #print(('num_bins_SF: %s'%num_bins_SF)\n",
    "    #\n",
    "    ## compute midpoints between false pos/neg bin edges\n",
    "    bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "    bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "    ## set first/last entry as limits of mass range for smf\n",
    "    bin_edge_means_SF[0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "    bin_edge_means_SF[-1] = range2[-1]\n",
    "    bin_edge_means_Q[0] = range2[0]\n",
    "    bin_edge_means_Q[-1] = range2[-1]\n",
    "    #print('length of bin_edge_means_* array: %s'%len(bin_edge_means_SF))\n",
    "    #print('bin_edge_means_SF: %s'%bin_edge_means_SF)\n",
    "    ## build new histograms\n",
    "    SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "    SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "    Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "    Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "    ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "    SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "    Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "    for jj in range(len(SF_pos_hist)):\n",
    "        if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            SF_ratio[jj] = 1\n",
    "    for jj in range(len(Q_pos_hist)):\n",
    "        if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            Q_ratio[jj] = 1\n",
    "    #\n",
    "    ## compute variance of SF/Q ratios from 1\n",
    "    SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    total_var = SF_var + Q_var\n",
    "    #\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "#\n",
    "#\n",
    "#\n",
    "### METHOD 3: ASYMMETRIC BINS for bins with ~EQUAL AMOUNTS OF MASS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "#\n",
    "method = 3\n",
    "#\n",
    "## \n",
    "for number in range(len(num_bins_to_try)):\n",
    "    SF_pos_sum_index = np.ceil(np.sum(SF_pos)/num_bins_to_try[number]) \n",
    "    SF_neg_sum_index = np.ceil(np.sum(SF_neg)/num_bins_to_try[number])\n",
    "    Q_pos_sum_index = np.ceil(np.sum(Q_pos)/num_bins_to_try[number])\n",
    "    Q_neg_sum_index = np.ceil(np.sum(Q_neg)/num_bins_to_try[number])\n",
    "    ## build arrays over range [7.3,12.3] with num_bins_to_try[number] bins, where each bin has ~equal amounts of mass in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "    num_bins_SF_index = [[],[]]     # [pos, neg]\n",
    "    num_bins_Q_index = [[],[]]     # [pos, neg]\n",
    "    # look through SF/Q false pos/neg lists one galaxy at a time, summing their mass until you reach the amount stored in *_sum_index (e.g. SF_pos_sum_index for SF_pos list), then record that index as a bin edge\n",
    "    #num_bins_SF[0].append(SF_pos[0])\n",
    "    ## SF_posfor ii in range(num_bins_to_try[number]):\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(SF_pos)):\n",
    "            mass_sum = mass_sum + SF_pos[jj]\n",
    "            if mass_sum >= ii*SF_pos_sum_index:\n",
    "                #print('\\nSF_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_pos_sum_index),'jj: %s'%jj)\n",
    "                num_bins_SF_index[0].append(jj)\n",
    "                break\n",
    "    ## SF_neg\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(SF_neg)):\n",
    "            mass_sum = mass_sum + SF_neg[jj]\n",
    "            if mass_sum >= ii*SF_neg_sum_index:\n",
    "                #print('\\nSF_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_neg_sum_index),'jj: %s'%jj)\n",
    "                num_bins_SF_index[1].append(jj)\n",
    "                break\n",
    "    ## Q_pos\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(Q_pos)):\n",
    "            mass_sum = mass_sum + Q_pos[jj]\n",
    "            if mass_sum >= ii*Q_pos_sum_index:\n",
    "                #print('\\nQ_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_pos_sum_index),'jj: %s'%jj)\n",
    "                num_bins_Q_index[0].append(jj)\n",
    "                break\n",
    "    ## Q_neg\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(Q_neg)):\n",
    "            mass_sum = mass_sum + Q_neg[jj]\n",
    "            if mass_sum >= ii*Q_neg_sum_index:\n",
    "                #print('\\nQ_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_neg_sum_index),'jj: %s'%jj)\n",
    "                num_bins_Q_index[1].append(jj)\n",
    "                break\n",
    "    #\n",
    "    ## add last (highest-mass) bin edge\n",
    "    num_bins_SF_index[0].append(len(SF_pos)-1)\n",
    "    num_bins_SF_index[1].append(len(SF_neg)-1)\n",
    "    num_bins_Q_index[0].append(len(Q_pos)-1)\n",
    "    num_bins_Q_index[1].append(len(Q_neg)-1)\n",
    "    ## convert to arrays\n",
    "    num_bins_SF_index = np.array(num_bins_SF_index)\n",
    "    num_bins_Q_index = np.array(num_bins_Q_index)\n",
    "    #print('# bins: %s'%(num_bins_to_try[number]-1))\n",
    "    #print('length of num_bins_* array: %s'%len(num_bins_SF_index[0]),'\\nlength of SF array: %s'%len(SF_pos),'\\nlength of Q array: %s'%len(Q_pos))\n",
    "    #print('indices corresponding to bin edges\\nSF: %s'%num_bins_SF_index,'\\nQ: %s'%num_bins_Q_index)\n",
    "    #\n",
    "    ## convert to arrays\n",
    "    num_bins_SF = np.empty_like(num_bins_SF_index,dtype='float32')\n",
    "    num_bins_Q = np.empty_like(num_bins_Q_index,dtype='float32')\n",
    "    #\n",
    "    ## SF: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "    # \n",
    "    try:\n",
    "        for ii in range(len(num_bins_SF[0])):\n",
    "            num_bins_SF[0][ii] = SF_pos[num_bins_SF_index[0][ii]]\n",
    "            num_bins_SF[1][ii] = SF_neg[num_bins_SF_index[1][ii]]\n",
    "        #\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        num_bins_SF[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        num_bins_SF[1][0] = range2[0]\n",
    "        num_bins_SF[0][-1] = range2[-1] \n",
    "        num_bins_SF[1][-1] = range2[-1]\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "        #\n",
    "        ## build new histograms\n",
    "        SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "        SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "        for jj in range(len(SF_pos_hist)):\n",
    "            if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                SF_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    except:\n",
    "        print('# bins exceeds length of SF false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "        SF_ratio = 'n/a'\n",
    "        SF_var = 'n/a'\n",
    "    \n",
    "    ## Q: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "    try:\n",
    "        for ii in range(len(num_bins_Q[0])):\n",
    "            num_bins_Q[0][ii] = Q_pos[num_bins_Q_index[0][ii]]\n",
    "            num_bins_Q[1][ii] = Q_neg[num_bins_Q_index[1][ii]]\n",
    "        #\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        num_bins_Q[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        num_bins_Q[1][0] = range2[0]\n",
    "        num_bins_Q[0][-1] = range2[-1]\n",
    "        num_bins_Q[1][-1] = range2[-1]\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "        #\n",
    "        ## build new histograms\n",
    "        Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "        Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "        for jj in range(len(Q_pos_hist)):\n",
    "            if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                Q_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    except:\n",
    "        print('# bins exceeds length of Q false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "        Q_ratio = 'n/a'\n",
    "        Q_var = 'n/a'\n",
    "    #\n",
    "    if SF_ratio == 'n/a':\n",
    "        total_var = Q_var\n",
    "    elif Q_ratio == 'n/a':\n",
    "        total_var = SF_var\n",
    "    else: \n",
    "        total_var = np.round((SF_var + Q_var),decimals=3)\n",
    "        SF_var = np.round(SF_var,decimals=3)\n",
    "        Q_var = np.round(Q_var,decimals=3)\n",
    "    #\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%SF_var+space+'%s'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%Q_var+space+'%s'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "    #\n",
    "#\n",
    "#\n",
    "## close the file       \n",
    "f.close()\n",
    "#\n",
    "#\n",
    "#\n",
    "## TIME_FLAG END\n",
    "#\n",
    "if time_flag == 1:\n",
    "    print('Program \"spec_completeness_binning.py\" took: %s seconds to run.\\n\\n' % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#                      \n",
    "###### PROGRAM END ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 14.93317723274231 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.5563950538635254 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.6480791568756104 seconds.\n",
      "\n",
      "\n",
      "(SPEC+PHOT) Subsample\n",
      "Catalogue by MEMBER - Star-forming:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  1916      378      334      260      216       227       501\n",
      "Secure member    99       10       20       23       13        14        19\n",
      " Secure field   711      146      149       50       90        76       200\n",
      "    Fasle pos    61       21        9        8        5         8        10\n",
      "    False neg    10        2        1        1        1         0         5\n",
      "NOTE: Total (row) reported under each cluster is sum of SF+Q.\n",
      "\n",
      "Catalogue by MEMBER - Quiescent:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  1916      378      334      260      216       227       501\n",
      "Secure member   730      128      126      143       76        96       161\n",
      " Secure field    54       22        4        7        5         6        10\n",
      "    Fasle pos    31        9        2        9        2         3         6\n",
      "    False neg    47        3        7        5        0         7        25\n",
      "NOTE: Total reported under each cluster is sum of SF+Q.\n",
      "NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\n",
      "\n",
      "\n",
      "Overall membership fraction: \n",
      "SF: 0.11237230419977298  & Q: 0.8468677494199536    for cutoff:\n",
      "[0.015, 0.08]\n",
      "\n",
      "Total catalogue length: 44465\n",
      "SPEC+PHOT sub-sample: 1916\n",
      "SF: 881\n",
      "Q: 862\n",
      "Lost due to buffer b/w member & field\n",
      "SF: 19 ;    Q: 2\n",
      "Other (not in (spec + phot) subsample): 42549\n",
      "NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\n",
      "\n",
      "Section 4 took: 0.33372998237609863 seconds.\n",
      "\n",
      "\n",
      "PHOT-ONLY Subsample\n",
      "Catalogue by MEMBER - Star-forming:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  3444      381      524      649      555       533       802\n",
      "Secure member  2846      381      393      479      513       448       632\n",
      " Secure field   598        0      131      170       42        85       170\n",
      "NOTE: Total reported under each cluster is sum of SF+Q.\n",
      "\n",
      "Catalogue by MEMBER - Quiescent:\n",
      "   Property   Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "------------- ----- -------- -------- -------- -------- --------- ---------\n",
      "        Total  3187      318      552      718      470       483       646\n",
      "Secure member  2913      318      490      616      456       453       580\n",
      " Secure field   274        0       62      102       14        30        66\n",
      "Lost due to buffer b/w member & field\n",
      "SF: 630 ;    Q: 318\n",
      "NOTE: Total reported under each cluster is sum of SF+Q.\n",
      "NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\n",
      "\n",
      "\n",
      "Overall membership fraction: \n",
      "SF: 0.101704605  & Q: 0.49760848    for cutoff: [0.015, 0.08]\n",
      "\n",
      "Total catalogue length: 44465\n",
      "PHOT ONLY sub-sample: 33837\n",
      "SF (members + field): 3444\n",
      "Q (members + field): 3187\n",
      "Field outliers (z>0.55 or z<0.3): 26258\n",
      "Lost due to buffer b/w definition of cluster member/field: 948\n",
      "Stars & outliers: 0\n",
      "Sum of the above: 33837\n",
      "Difference between # in PHOT-ONLY subsample & sum above: 0\n",
      "Other (not in phot only subsample): 10628\n",
      "NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\n",
      "\n",
      "Section 5 took: 2.5561039447784424 seconds.\n",
      "\n",
      "\n",
      "Total BCGs removed from catalogue: 0 .\n",
      "BCGs removed by cluster: [0 0 0 0 0 0]\n",
      "Section 6 took: 0.06485605239868164 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 24 10:23:11 2020\n",
    "\n",
    "@author: gsarrouh\n",
    "\"\"\"\n",
    "#### UPDATE 06/24/20 ####\n",
    "## The previous versions of this file all used HFF DR v3.5, a preliminary data release from the summer of 2017. The paper Shipley et al. 2018 (which I reference extensively in my work) corresponds to the finished data release, v3.9. That final, most up-tp-date data release is what is implemented in the following work. \n",
    "#\n",
    "#\n",
    "### WHAT THIS PROGRAM DOES:\n",
    "### This script reads in all data for the Hubble Frontier Fields images and prepares data for plotting and analysis. Key information is summarized in the tables: \n",
    "###     **\"sub_stats\",\"type_stats\",\"SF_spec_stats\",\"Q_spec_stats\",\"SF_phot_stats\",\"Q_phot_stats\"**\n",
    "#\n",
    "### Data is organized in a single catalogue (\"master_cat\"), and objects are identified through applying a series of \"FILTERS\" to designate key populations using a numerical designation for ease of writing code.\n",
    "#\n",
    "#\n",
    "## FILTER 1 - 'cluster':  cluster catalogues are designated as follows: \n",
    "## 1: macs0416\n",
    "## 2: macs1149\n",
    "## 3: macs0717\n",
    "## 4: abell370\n",
    "## 5: abell1063\n",
    "## 6: abell2744\n",
    "#\n",
    "## FILTER 2 - 'sub': :   identifies sub-type of data each object has\n",
    "## 0: no data (no photometry or spectroscopy)\n",
    "## 1: spectroscopy & photometry\n",
    "## 2: photometry only \n",
    "## 3: spectroscopy only  (there's just 3 in macs0717) \n",
    "## 4: star\n",
    "#\n",
    "## FILTER 3 - 'type': :   identifies type of data each object has\n",
    "## 0: star\n",
    "## 1: star-forming (SF)\n",
    "## 2: quiescent (Q)  \n",
    "## 3: outliers (defined as |del_z\\ > 0.15)\n",
    "#\n",
    "## FILTER 4 - 'member': :   identifies type of data each object has\n",
    "## NOTE: this designation is for objects with phot only (sub =2) and spec&phot (sub=1) only, as membership determinaion requires a good 'z_phot' estimate. as such, member=2 & =3 are for spec&phot (sub=1) subsample only, as only they can be classified as false pos/neg\n",
    "## 0: secure cluster member\n",
    "## 1: secure field    <-- this comprises the sample of field galaxies to be \n",
    "##                        compared with cluster, at similar redshifts\n",
    "## 2: false positive\n",
    "## 3: false negative\n",
    "## 4: field outlier   <-- objects well outside the redshift range of the clusters (e.g. z > 0.55)\n",
    "## 5: BCGs            <-- identified in the last section of the program, over-writing MEMBER assignment from section 4\n",
    "#\n",
    "#\n",
    "#\n",
    "### Section summary:\n",
    "#\n",
    "### PROGRAM START\n",
    "#\n",
    "### (1) import data into single table, creating KEY TABLE: \"master_cat\" \n",
    "### (1.1)  add filter (\"sieves\") columns, apply SUB-TYPE FILTER in each \n",
    "###        cluster [\"nodata\", \"phot_only\",\"spec_only\",\"both\"], \n",
    "### (1.2)  add DIAG_FLAG_1: summarize in table \"sub_stats\"\n",
    "### (1.3)  convert flux to mag.,\n",
    "### (2) calculate various del_z's, \n",
    "### (2.1)  identify outliers\n",
    "### (2.2)  compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "### (3) distinguish b/w SF/Q: apply TYPE FILTER\n",
    "### (3.1)  add DIAG_FLAG_2: summarize in table \"type_stats\"\n",
    "### (4) make membership cuts to spec samples (i.e. apply MEMBER FILTER), add DIAG_FLAG_3: apply diagnostic to test different redshift cutoff (OUTPUT FILE: /Documents/Programs/Python/nserc17/HFF_ToAdamFinal/working_data/section_4_false_pos_neg_redshift_cuts_*.txt) \n",
    "### (4.1) add DIAG_FLAG_4: summarize in table \"SF_spec_stats\" & \"Q_spec_stats\"\n",
    "### (5) make membership cuts to phot samples\n",
    "### (5.1) add DIAG_FLAG_4: summarize in table \"SF_phot_stats\" & \"Q_phot_stats\"\n",
    "#\n",
    "### PROGRAM END\n",
    "#\n",
    "#\n",
    "#\n",
    "###################     PROGRAM START\n",
    "#\n",
    "## TIME_FLAG: START\n",
    "## superior time_flag which supercedes all others and times the entire program\n",
    "time_flag = 0     # track & print time to execute current section\n",
    "#\n",
    "if time_flag == 1:\n",
    "    start_time = time.time()\n",
    "#\n",
    "#\n",
    "## MASTER diagnostic flag:   0=all flags off;   1=all flags on;    2=individual flags may be turned on\n",
    "diag_flag_master = 2\n",
    "#\n",
    "#\n",
    "# Read in ALL data from WORKING DIRECTORY: NSERC17/HFFtoAdam/working_data\n",
    "#\n",
    "## MODULES\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "#\n",
    "##SECTION 1: import all data from HFF team, convert flux to luminosity & gather full \n",
    "#\n",
    "## TIME_FLAG_1 START\n",
    "time_flag_1 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "## import catalogues into single table \"master_cat\"; separate objects for which there is no redshift data (both photo & spec) as \"nodata\"\n",
    "#\n",
    "##create table from EAZY output redshift \".zout\" file\n",
    "z_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.zout',format='ascii')\n",
    "z_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.zout',format='ascii')\n",
    "z_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.zout',format='ascii')\n",
    "z_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.zout',format='ascii')\n",
    "z_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.zout',format='ascii')   \n",
    "z_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.zout',format='ascii') \n",
    "#   \n",
    "#create table from FAST \".fout\" file (contains mass estimates)\n",
    "f_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.fout',format='ascii')\n",
    "f_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.fout',format='ascii')\n",
    "f_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.fout',format='ascii')\n",
    "f_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.fout',format='ascii')\n",
    "f_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.fout',format='ascii')\n",
    "f_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.fout',format='ascii')\n",
    "#\n",
    "# rename columns of the .fout files because for some reason the column names didn't register\n",
    "col_names_old = ['col1','col2','col3','col4','col5','col6','col7','col8','col9','col10','col11']\n",
    "col_names_new = ['id','z','ltau','metal','lage','Av','lmass','lsfr','lssfr','la2t','chi2']\n",
    "for ii in range(len(col_names_new)):\n",
    "    f_macs0416.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs1149.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs0717.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell370.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell1063.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell2744.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "#\n",
    "##read in the whole bloody catalogue\n",
    "cat_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/hffds_macs0416clu_v3.9.cat',format='ascii')\n",
    "cat_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/hffds_macs1149clu_v3.9.cat',format='ascii')\n",
    "cat_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/hffds_macs0717clu_v3.9.cat',format='ascii')\n",
    "cat_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/hffds_abell370clu_v3.9.cat',format='ascii')\n",
    "cat_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/hffds_abell1063clu_v3.9.cat',format='ascii')\n",
    "cat_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/hffds_abell2744clu_v3.9.cat',format='ascii')\n",
    "#\n",
    "##creat table for colours\n",
    "#macs0416\n",
    "F0416_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.153.rf',format='ascii')\n",
    "F0416_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.155.rf',format='ascii')\n",
    "F0416_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.161.rf',format='ascii')\n",
    "#macs1149\n",
    "F1149_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.153.rf',format='ascii')\n",
    "F1149_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.155.rf',format='ascii')\n",
    "F1149_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.161.rf',format='ascii')\n",
    "#macs0717\n",
    "F0717_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.153.rf',format='ascii')\n",
    "F0717_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.155.rf',format='ascii')   \n",
    "F0717_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.161.rf',format='ascii')\n",
    "#abell370\n",
    "F370_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.153.rf',format='ascii')\n",
    "F370_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.155.rf',format='ascii')\n",
    "F370_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.161.rf',format='ascii')\n",
    "#abell1063\n",
    "F1063_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.153.rf',format='ascii')\n",
    "F1063_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.155.rf',format='ascii')\n",
    "F1063_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.161.rf',format='ascii')\n",
    "#abell2744\n",
    "F2744_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.153.rf',format='ascii')\n",
    "F2744_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.155.rf',format='ascii')\n",
    "F2744_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.161.rf',format='ascii')\n",
    "##aggregate into a single table\n",
    "macs0416 = Table([z_macs0416['id'],z_macs0416['z_peak'],z_macs0416['z_spec'],F0416_u['L153'],F0416_v['L155'],F0416_j['L161'],F0416_u['DM'],f_macs0416['lmass'],f_macs0416['lsfr'],f_macs0416['lssfr'],cat_macs0416['flux_radius'],cat_macs0416['star_flag'],cat_macs0416['use_phot'],cat_macs0416['f_F160W'],cat_macs0416['e_F160W'],cat_macs0416['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs1149 = Table([z_macs1149['id'],z_macs1149['z_peak'],z_macs1149['z_spec'],F1149_u['L153'],F1149_v['L155'],F1149_j['L161'],F1149_u['DM'],f_macs1149['lmass'],f_macs1149['lsfr'],f_macs1149['lssfr'],cat_macs1149['flux_radius'],cat_macs1149['star_flag'],cat_macs1149['use_phot'],cat_macs1149['f_F160W'],cat_macs1149['e_F160W'],cat_macs1149['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs0717 = Table([z_macs0717['id'],z_macs0717['z_peak'],z_macs0717['z_spec'],F0717_u['L153'],F0717_v['L155'],F0717_j['L161'],F0717_u['DM'],f_macs0717['lmass'],f_macs0717['lsfr'],f_macs0717['lssfr'],cat_macs0717['flux_radius'],cat_macs0717['star_flag'],cat_macs0717['use_phot'],cat_macs0717['f_F160W'],cat_macs0717['e_F160W'],cat_macs0717['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell370 = Table([z_abell370['id'],z_abell370['z_peak'],z_abell370['z_spec'],F370_u['L153'],F370_v['L155'],F370_j['L161'],F370_u['DM'],f_abell370['lmass'],f_abell370['lsfr'],f_abell370['lssfr'],cat_abell370['flux_radius'],cat_abell370['star_flag'],cat_abell370['use_phot'],cat_abell370['f_F160W'],cat_abell370['e_F160W'],cat_abell370['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell1063 = Table([z_abell1063['id'],z_abell1063['z_peak'],z_abell1063['z_spec'],F1063_u['L153'],F1063_v['L155'],F1063_j['L161'],F1063_u['DM'],f_abell1063['lmass'],f_abell1063['lsfr'],f_abell1063['lssfr'],cat_abell1063['flux_radius'],cat_abell1063['star_flag'],cat_abell1063['use_phot'],cat_abell1063['f_F160W'],cat_abell1063['e_F160W'],cat_abell1063['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell2744 = Table([z_abell2744['id'],z_abell2744['z_peak'],z_abell2744['z_spec'],F2744_u['L153'],F2744_v['L155'],F2744_j['L161'],F2744_u['DM'],f_abell2744['lmass'],f_abell2744['lsfr'],f_abell2744['lssfr'],cat_abell2744['flux_radius'],cat_abell2744['star_flag'],cat_abell2744['use_phot'],cat_abell2744['f_F160W'],cat_abell2744['e_F160W'],cat_abell2744['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "#\n",
    "#\n",
    "## NOTE: cat_*['flag_F160W'] identifies BCGs IN EACH FILTER. ***** CONFIRM w/ AM ***** that I'm using the right filter; BCGs are identified as ['flag_F160W']==4, see Shipley et al 2018. Section 3.9\n",
    "#\n",
    "## create columns and append to master_cat to identify sub-sample, type, \n",
    "## and fraction for catalogue: \n",
    "##   type: 0 = stars,  1 = SF,  2 = Q\n",
    "##   member:  0 = not in spec sub-sample,  1 = secure in cluster,  2 = secure in field\n",
    "##            3 = false positive,  4 = false negative\n",
    "## Note: \"member\" only applies to the spec sub-sample\n",
    "#\n",
    "D1 = Column([1]*len(macs0416),name='cluster')\n",
    "D2 = Column([2]*len(macs1149),name='cluster')        #cluster designation columns\n",
    "D3 = Column([3]*len(macs0717),name='cluster')\n",
    "D4 = Column([4]*len(abell370),name='cluster')\n",
    "D5 = Column([5]*len(abell1063),name='cluster')\n",
    "D6 = Column([6]*len(abell2744),name='cluster')\n",
    "#\n",
    "macs0416.add_column(D1)       \n",
    "macs1149.add_column(D2)\n",
    "macs0717.add_column(D3)\n",
    "abell370.add_column(D4)\n",
    "abell1063.add_column(D5)\n",
    "abell2744.add_column(D6)\n",
    "#\n",
    "global master_cat\n",
    "master_cat = Table(np.concatenate((macs0416,macs1149,macs0717,abell370,abell1063,abell2744), axis=0))  #create a master catalogue of all clusters\n",
    "#\n",
    "## add \"empty\" columns (with value set = 99) for the remaining sieves: sub, type, member for [phot or spec],[SF or Q],[cluster member, field, false pos/neg] respectively\n",
    "E1 = Column([-99]*len(master_cat), name='sub', dtype=np.int8)    # create columns\n",
    "E2 = Column([-99]*len(master_cat), name='type', dtype=np.int8)\n",
    "E3 = Column([-99]*len(master_cat), name='member', dtype=np.int8)\n",
    "master_cat.add_columns([E1,E2,E3],[-1,-1,-1])                   # add columns to the end of table\n",
    "#\n",
    "#\n",
    "## SECTION (1.1) - SUB-TYPE FILTER: this section classifies all objects as either:\n",
    "##  sub = 0: no data (neither spec. nor phot.)\n",
    "##  sub = 1: both\n",
    "##  sub = 2: phot only\n",
    "##  sub = 3: spec only\n",
    "##  sub = 4: stars\n",
    "#\n",
    "# sift for targets without no data, spec only, phot only, and both\n",
    "spec_only = np.array([0]*6)    # to keep track by cluster\n",
    "phot_only = np.array([0]*6)\n",
    "error = 0\n",
    "other = 0\n",
    "both = np.array([0]*6)\n",
    "no_data = np.array([0]*6)\n",
    "stars_sub = np.array([0]*6)\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] > 0:  #entries w/ both spectroscopy and photometry  (SPECTROSCOPIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:     # use_phot = 0 means bad photometry\n",
    "            for jj in range(len(spec_only)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        spec_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "        elif master_cat['use_phot'][counter] ==1:     # use_phot = 1 means good photometry\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of (spec & phot) objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        both[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 1          # APPLY FILTER: sub=1 for objects w/ BOTH SPEC & PHOT\n",
    "        else: error+=1                              # just to keep track of erroneous objects\n",
    "    elif master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] < 0:  #entries w/ spectroscopy alone\n",
    "        for jj in range(len(spec_only)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    spec_only[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] > 0:  #entries w/ photometry alone (PHOTOMETRIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        no_data[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "        elif master_cat['use_phot'][counter] ==1:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of phot only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        phot_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 2          # APPLY FILTER: sub=2 for objects w/ PHOT ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] < 0:  #entries w/ no z estimates at all\n",
    "        for jj in range(len(both)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    no_data[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "    else: other+=1\n",
    "#\n",
    "#\n",
    "## SECTION (1.2): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_1\n",
    "##  summarize data population as segregated above, and display in a table\n",
    "diag_flag_1 = 1             # 0=off (don't display diagnostic); 1=on (display diagnostic table)\n",
    "#\n",
    "if (diag_flag_1 == 1 and diag_flag_master == 2) or diag_flag_master ==1:\n",
    "    ## Summarize initial data stats in table\n",
    "    sub_names = Column(['total','spec & phot','only phot','spec only','no data','stars'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    sub0 = Column([np.sum([np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)]),np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)],name='Total')  # total column\n",
    "    sub_stats = Table([sub_names,sub0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        sub_col = Column([np.sum([both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]]),both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]],name=col_names[ii])  # add columns to table one cluster at a time\n",
    "        sub_stats.add_column(sub_col)\n",
    "    #\n",
    "    print('Catalogue by SUB-type:')\n",
    "    print(sub_stats)\n",
    "    print('Other skipped objects: %s'%other)\n",
    "#\n",
    "#\n",
    "## SECTION (1.3): convert FLUX TO MAGNITUDE; using well-known mag = -2.5*log_10(flux) + zero_pt. zero_pt = 25\n",
    "#\n",
    "# add columns for luminosity calculations\n",
    "empty_u = Column([99]*len(master_cat), name='L_u', dtype=np.float64)\n",
    "empty_v = Column([99]*len(master_cat), name='L_v', dtype=np.float64)\n",
    "empty_j = Column([99]*len(master_cat), name='L_j', dtype=np.float64)\n",
    "empty_uv = Column([99]*len(master_cat), name='uv', dtype=np.float64)\n",
    "empty_vj = Column([99]*len(master_cat), name='vj', dtype=np.float64)\n",
    "master_cat.add_columns([empty_u,empty_v,empty_j,empty_uv,empty_vj])\n",
    "#\n",
    "##convert flux to magnitude (erroneously labelled as luminosity, e.g. L_u for magnitude in UV), get color indices U-V, V-J, add to table\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat[counter]['sub'] ==0 or master_cat[counter]['sub'] ==3 or master_cat[counter]['sub'] ==4:      # skip objects w/ \"no data\" (sub=0); \"spec only\" (sub=3); \"stars\" (sub=4)\n",
    "        pass\n",
    "    else:\n",
    "        master_cat['L_u'][counter] = -2.5*np.log10(master_cat['u'][counter]) + 25\n",
    "        master_cat['L_v'][counter] = -2.5*np.log10(master_cat['v'][counter]) + 25\n",
    "        master_cat['L_j'][counter] = -2.5*np.log10(master_cat['j'][counter]) + 25\n",
    "        master_cat['uv'][counter] = master_cat['L_u'][counter] - master_cat['L_v'][counter]\n",
    "        master_cat['vj'][counter] = master_cat['L_v'][counter] - master_cat['L_j'][counter]\n",
    "#\n",
    "## TIME_FLAG_1 END\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    print(\"Section 1 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (2): calulate DEL_Z's & separate OUTLIERS\n",
    "#\n",
    "## TIME_FLAG_2 START\n",
    "time_flag_2 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "#####Note: the photometric redshift used is 'z_peak' column from data\n",
    "#\n",
    "#(i) calculate delta_z for targets w/ both z_spec & z_phot\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='del_z', dtype=np.float64))           # del_z = (z_phot - z_spec) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterspec', dtype=np.float64))   # del_z = (z_spec - z_cl) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterphot', dtype=np.float64))   # del_z = (z_phot - z_cl) / (1 + z_phot)\n",
    "#\n",
    "# store cluster redshifts; obtained from https://archive.stsci.edu/prepds/frontier/\n",
    "z_cluster = [0.396,0.543,0.545,0.375,0.348,0.308]\n",
    "#\n",
    "#calucalte del_z, z_clusterspec, z_clusterphot for outlier cut (defined above); these will be used to make cuts (member, field, false pos/neg) to spec sample, from which we will use relative fractions by mass to correct the photometric sample for completeness.\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:   # sub=1 identifies spec&phot subsample\n",
    "        master_cat['del_z'][counter] = ((master_cat['z_peak'][counter] - master_cat['z_spec'][counter]) / (1 + master_cat['z_spec'][counter]))\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterspec'][counter] = ((master_cat['z_spec'][counter] - z_cluster[ii]) / (1 + master_cat['z_spec'][counter]))\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "    elif master_cat['sub'][counter] == 2:   # sub=2 identifies phot-only subsample\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "#\n",
    "#\n",
    "## SECTION (2.1): separate OUTLIERS from both phot & spec sub-sample, defined as |del_z| < 0.15. apply FILTER TYPE = 3 for outliers;   \n",
    "#\n",
    "outliers = np.array([0]*6)      # initialize array to track outliers by cluster, for computing outlier fraction later\n",
    "sum_delz = []                   # for computing mean |del_z|\n",
    "count_stars = 0\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:                        # sub=1 for objects with both spec & phot; total # of such objects tracked by cluster above in the array called \"both\"\n",
    "        if np.abs(master_cat['del_z'][counter]) > 0.15:        # |del_z| > 0.15 for outliers, threshold chosen for historical reasons to facilitate comparison with other studies\n",
    "            master_cat['type'][counter] = 3                  # type=3 identifies outliers\n",
    "            for ii in range(len(outliers)):\n",
    "                if master_cat['cluster'][counter] == (ii+1):   # keep track of outliers by cluster\n",
    "                    outliers[ii]+=1\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))    # keep track of all |del_z| measurements for stats computation\n",
    "        else:\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))\n",
    "        if master_cat['type'][counter] == 3 and master_cat['star_flag'][counter] == 1:                  # overwrite designation for stars\n",
    "            master_cat['type'][counter] = 0                        # type=0 for stars\n",
    "            outliers-=1\n",
    "            count_stars+=1\n",
    "#\n",
    "#\n",
    "## SECTION (2.2): compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "#\n",
    "delz_mean = np.mean(sum_delz)\n",
    "delz_scatter = np.std(sum_delz)\n",
    "print('OUTLIERS total: %s' % np.sum(outliers))\n",
    "print('Outlier fraction: %s' % (np.sum(outliers)/np.sum(both)))\n",
    "print('|del_z| mean: %s'%delz_mean)\n",
    "print('|del_z| scatter: %s\\n'%delz_scatter)\n",
    "#\n",
    "## TIME_FLAG_2 END\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    print(\"Section 2 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#  \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (3): add FILTER TYPE: separate SF/Q for both subsamples based on van der Burg (2013) \n",
    "## colour criteria;    filter name: 'type'  IDs below\n",
    "##   0 = stars;  1 = SF (star-forming);    2 = Q (quiscient);    3 = outliers\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_3 START\n",
    "time_flag_3 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "SF_type = np.array([0]*6)                             # initialize arrays\n",
    "Q_type = np.array([0]*6)\n",
    "stars_type = np.array([0]*6)                          # count # of stars by cluster\n",
    "lost_type = np.array([0]*6)                           # objects lost due no data (sub=0), spec only (sub=3), \n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['star_flag'][counter] == 1:          # identify STARS, filter type=0\n",
    "        master_cat['type'][counter] = 0              \n",
    "        for ii in range(len(stars_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                stars_type[ii]+=1\n",
    "    elif master_cat['sub'][counter]==1 or master_cat['sub'][counter]==2:    # sub=1 for (spec & phot) subsample, sub=2 for phot subsample; i.e. look at all objects with photometry\n",
    "        if master_cat['uv'][counter] > 1.3 and master_cat['vj'][counter] < 1.6 and master_cat['uv'][counter] > ((0.88*master_cat[counter]['vj']) + 0.6): \n",
    "            if master_cat['type'][counter] !=3:             # skip outliers\n",
    "                master_cat['type'][counter] = 2             # identify passive (QUIESCENT) galaxies, type=2\n",
    "                for ii in range(len(Q_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        Q_type[ii]+=1\n",
    "        else:\n",
    "            if master_cat['type'][counter] !=3:             # skip outliers    \n",
    "                master_cat['type'][counter] = 1             # identify STAR-FORMING galaxies, type=1\n",
    "                for ii in range(len(SF_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        SF_type[ii]+=1\n",
    "    else:\n",
    "        for ii in range(len(lost_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                lost_type[ii]+=1      # objects lost due to spec only (sub=3),no data (sub=0), and possibly outliers (type=3) \n",
    "#        \n",
    "#\n",
    "## SECTION (3.1): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_2\n",
    "##  summarize data TYPE population as segregated above, and display in a table\n",
    "diag_flag_2 = 1\n",
    "#\n",
    "if (diag_flag_2 == 1 and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## Summarize initial data stats in table\n",
    "    type_names = Column(['Total','SF','Q','Outliers','Other'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    type0 = Column([np.sum([np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type),np.sum(stars_type)]),np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type+stars_type)],name='Total')  # total column\n",
    "    type_stats = Table([type_names,type0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        type_col = Column([np.sum([SF_type[ii],Q_type[ii],outliers[ii],lost_type[ii],stars_type[ii]]),SF_type[ii],Q_type[ii],outliers[ii],(lost_type[ii]+stars_type[ii])],name=col_names[ii])\n",
    "        type_stats.add_column(type_col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    print('Catalogue by TYPE:')\n",
    "    print(type_stats)\n",
    "    print('NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\\n')\n",
    "#\n",
    "## TIME_FLAG_3 END\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    print(\"Section 3 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION 4: apply MEMBER FILTER based on cuts discussed with AM in 2017 (see comments below), based on cuts made in VDB2013. MEMBER isolates: 0=cluster member (secure); 1=field (secure); 2=false pos; 3=false neg; write an interative loop which test varying values for redshift membership cutoffs, and print result to an output document. Then INSPECT BY EYE and pick the one you want, and hard code the cuts after the diag_flag_ loop\n",
    "#\n",
    "## CRITERIA:\n",
    "#\n",
    "## SF: cluster = 0: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) < 0.03; \n",
    "##      field = 1: abs(z_clusterspec) > 0.02 & abs(z_cluster phot) > 0.1; \n",
    "## false pos = 2: abs(z_clusterspec) > 0.01 & abs(z_cluster phot) < 0.03;\n",
    "## false neg = 3: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) > 0.03;\n",
    "## Q: same cutoff for z_clusterspec, cutoff for z_clusterphot > 0.07\n",
    "#\n",
    "## Note: this is only done for spec sample; results used to correct photo sample for completeness at end of analysis in file \"master_smf_8.py\"\n",
    "#\n",
    "### SF sub-sample: SF_spec into secure member, field, false pos/neg\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_4 START\n",
    "time_flag_4 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_4 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#\n",
    "### MAY NEED TO EDIT ### diag_flag_3\n",
    "##  test different redshift cutoffs and print result to output document\n",
    "diag_flag_3 = 0\n",
    "#\n",
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    SF_cutoff = [0.01,0.03]      # [spec,phot]\n",
    "    Q_cutoff = [0.01,0.07]\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "    #\n",
    "    # open a file to print to\n",
    "    f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "        #\n",
    "        ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "            #\n",
    "            # compute membership acceptance fraction\n",
    "            SF_specphot = np.sum([np.sum(mem[0]),np.sum(field[0]),np.sum(pos[0]),np.sum(neg[0])]) # total # of galaxies with both spec & phot - SF\n",
    "            Q_specphot = np.sum([np.sum(mem[1]),np.sum(field[1]),np.sum(pos[1]),np.sum(neg[1])])  # total # of galaxies with both spec & phot - Q\n",
    "            mem_fraction = np.array([(np.sum(mem[0])/SF_specphot),(np.sum(mem[1])/Q_specphot)]) # [SF acceptance fraction, Q acceptance fraction]\n",
    "        #print('\\nOverall membership fraction: \\nSF: %s'%mem_fraction[0],' & Q: %s'%mem_fraction[1],'   for Spec cutoff:  %s'%z_cutoff_spec[cutoff_spec],'   for Phot cutoff:  %s'%z_cutoff_phot[cutoff_phot])\n",
    "        # print # of memebrs, false pos/neg, & acceptance fraction for each of SF & Q to a file\n",
    "        # FORMAT: row_1 = SF;   row_2 = Q;\n",
    "        #   col_1 = z_cut;  col_2 = TYPE;  col_3=members; col_4 = false pos; col_5 = false neg; col_6 = acceptance fraction; col_7 = False pos/neg ratio\n",
    "            zcut = str(np.round(z_cutoff[0]*1000)/1000)+space+str(np.round(z_cutoff[1]*100)/100)\n",
    "            SF_1 = str(np.sum(mem[0]))      # cluster members\n",
    "            SF_2 = str(np.sum(pos[0]))      # false pos\n",
    "            SF_3 = str(np.sum(neg[0]))      # false neg\n",
    "            SF_4 = str(mem_fraction[0])     # cluster membership fraction\n",
    "            SF_5 = str((np.sum(pos[0])/np.sum(neg[0])))    # overall false pos/neg ratio\n",
    "            entry_1 = zcut+space+'SF'+space+SF_1+space+SF_2+space+SF_3+space+SF_4+space+SF_5\n",
    "            Q_1 = str(np.sum(mem[1]))\n",
    "            Q_2 = str(np.sum(pos[1]))\n",
    "            Q_3 = str(np.sum(neg[1]))\n",
    "            Q_4 = str(mem_fraction[1])\n",
    "            Q_5 = str((np.sum(pos[1])/np.sum(neg[1])))\n",
    "            entry_2 = zcut+space+' Q'+space+Q_1+space+Q_2+space+Q_3+space+Q_4+space+Q_5\n",
    "            # write it\n",
    "            writer = '%s\\n'%entry_1+'%s\\n'%entry_2\n",
    "            f.write(writer)\n",
    "        writer = '\\n'+asterisks+'\\n'\n",
    "        f.write(writer)       \n",
    "    #        \n",
    "    f.close()\n",
    "    #\n",
    "    #\n",
    "    # END of DIAGNOSTIC loop\n",
    "else:\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff = [0.015,0.08]\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "    ##\n",
    "    ## open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/HFF_ToAdamFinal/working_data/section_4_false_pos_neg_redshift_cuts_001.txt','w+')\n",
    "    #\n",
    "    #for cutoff in range(len(z_cutoff)):\n",
    "    ##\n",
    "    ## INDENT HERE for diagnostic \n",
    "    mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "    field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "    pos = np.array([[0]*6]*2)\n",
    "    neg = np.array([[0]*6]*2)\n",
    "    other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "    lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "    #\n",
    "    ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "    for counter in range(len(master_cat)):\n",
    "        if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "            if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                    master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                    for ii in range(len(field[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                            field[0][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                    for ii in range(len(pos[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                            pos[0][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                    for ii in range(len(neg[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                            neg[0][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                    for ii in range(len(mem[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                            mem[0][ii]+=1\n",
    "                else: \n",
    "                    for ii in range(len(lost_due_to_buffer[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                            lost_due_to_buffer[0][ii]+=1\n",
    "            elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                    master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                    for ii in range(len(field[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                            field[1][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                    for ii in range(len(pos[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                            pos[1][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                    for ii in range(len(neg[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                            neg[1][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                    for ii in range(len(mem[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                            mem[1][ii]+=1\n",
    "                else: \n",
    "                    for ii in range(len(lost_due_to_buffer[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                            lost_due_to_buffer[1][ii]+=1\n",
    "        else: other_member+=1\n",
    "#\n",
    "#\n",
    "#    \n",
    "## SECTION (4.1): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_4\n",
    "##  summarize data population as segregated above, and display in a table\n",
    "diag_flag_4 = 1\n",
    "#\n",
    "if (diag_flag_4 == 1 and diag_flag_master ==2) or diag_flag_master ==1:\n",
    "    ## Summarize initial data stats in table\n",
    "    member_names = Column(['Total','Secure member','Secure field','Fasle pos','False neg'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    # SF table\n",
    "    member0 = Column([np.sum(both),np.sum(mem[0]),np.sum(field[0]),np.sum(pos[0]),np.sum(neg[0])],name='Total')  # total column\n",
    "    SF_spec_stats = Table([member_names,member0])\n",
    "    for ii in range(len(mem[0])):\n",
    "        col = Column([both[ii],mem[0][ii],field[0][ii],pos[0][ii],neg[0][ii]],name=col_names[ii])\n",
    "        SF_spec_stats.add_column(col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    # Q table\n",
    "    member0 = Column([np.sum(both),np.sum(mem[1]),np.sum(field[1]),np.sum(pos[1]),np.sum(neg[1])],name='Total')  # total column\n",
    "    Q_spec_stats = Table([member_names,member0])\n",
    "    for ii in range(len(mem[1])):\n",
    "        col = Column([both[ii],mem[1][ii],field[1][ii],pos[1][ii],neg[1][ii]],name=col_names[ii])\n",
    "        Q_spec_stats.add_column(col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    print('(SPEC+PHOT) Subsample\\nCatalogue by MEMBER - Star-forming:')\n",
    "    print(SF_spec_stats)\n",
    "    print('NOTE: Total (row) reported under each cluster is sum of SF+Q.\\n')\n",
    "    print('Catalogue by MEMBER - Quiescent:')\n",
    "    print(Q_spec_stats)\n",
    "    print('NOTE: Total reported under each cluster is sum of SF+Q.')\n",
    "    print('NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\\n')\n",
    "#\n",
    "SF_specphot = np.sum([np.sum(mem[0]),np.sum(field[0]),np.sum(pos[0]),np.sum(neg[0])])\n",
    "Q_specphot = np.sum([np.sum(mem[1]),np.sum(field[1]),np.sum(pos[1]),np.sum(neg[1])])\n",
    "print('\\nOverall membership fraction: \\nSF: %s'%(np.sum(mem[0])/SF_specphot),' & Q: %s'%(np.sum(mem[1])/Q_specphot),'   for cutoff:\\n%s'%str(z_cutoff))\n",
    "#\n",
    "print('\\nTotal catalogue length: %s'%len(master_cat))\n",
    "print('SPEC+PHOT sub-sample: %s' % np.sum(both))\n",
    "print('SF: %s' % np.sum([mem[0],field[0],pos[0],neg[0]]))\n",
    "print('Q: %s' % np.sum([mem[1],field[1],pos[1],neg[1]]))\n",
    "print('Lost due to buffer b/w member & field\\nSF: %s'%np.sum(lost_due_to_buffer[0]),';    Q: %s'%np.sum(lost_due_to_buffer[1]))\n",
    "print('Other (not in (spec + phot) subsample): %s'%other_member)\n",
    "print('NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\\n')                        \n",
    "#\n",
    "## TIME_FLAG_4 END\n",
    "#\n",
    "if time_flag_4 == 1 and time_flag == 0:\n",
    "    print(\"Section 4 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SETION (5): make cuts to PHOTOMETRIC SUBSAMPLE based on defintion for del_z:  del_z = (z_phot - z_cl)/(1 + z_phot) < **some number** (to match cut made above in z_cutoff[1]; apply MEMBER FILTER for PHOTOMETRIC SUBSAMPLE MEMBERS); same photometric cut made to specroscopic sub-sample. this is a preliminary measure for determining the photometric sample, final corrections will be made by mass bins to match false pos/neg fractions in spec. sample per van der Burg (2013)\n",
    "#\n",
    "## apply cut at |z_clusterphot| < z_cutoff[1] to separate cluster members from field for targets with photometry only. store in MEMBER FILTER: \n",
    "## 0 = cluster member; 1 = field; 2 = false pos; 3 = false neg; 4 = field outlier\n",
    "#\n",
    "## recall: z_clusterphot defined as (z_peak - z_cluster / 1 + z_peak)\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_5 START\n",
    "time_flag_5 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_5 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "### Quiescent sub-sample: segregate into secure member, field\n",
    "# initialize arrays, format is row_1=SF, row_2=Q\n",
    "mem_phot = np.array([[0]*6]*2)    # for tracking phot members/field galaxies, by cluster\n",
    "field_phot = np.array([[0]*6]*2)\n",
    "other_phot = 0      # objects not in sub=2 phot only subsample\n",
    "n_phot_only = 0     # number of objects in sub=2 subsample\n",
    "stars_outliers = 0  # number of objects in sub=0 or sub=3 subsamples\n",
    "field_outliers = np.array([[0]*6]*2)  # track field objects with very large (i.e. highly discrepant) redshifts, far outside the redshift range of the clusters\n",
    "n_SF = 0\n",
    "n_Q = 0\n",
    "lost_due_to_buffer_phot = np.array([[0]*6]*2)    # objects lost due to buffer b/w definition of cluster and field\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat[counter]['sub'] ==2:      # sub=2 identifies phot only subsample\n",
    "        n_phot_only+=1\n",
    "        if master_cat[counter]['type'] == 0 or master_cat[counter]['type'] ==3: #skip stars and outliers\n",
    "            stars_outliers+=1\n",
    "            pass       \n",
    "        elif master_cat[counter]['type'] ==1:       # type=1 identifies SF\n",
    "            n_SF+=1\n",
    "            if abs(master_cat[counter]['z_clusterphot']) > 0.1:     # identify field galaxies\n",
    "                if master_cat[counter]['z_peak'] >0.55 or master_cat[counter]['z_peak'] <0.3:\n",
    "                    master_cat[counter]['member'] = 4       # memfield outlier\n",
    "                    for ii in range(len(field_outliers[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of field outlier galaxies by cluster\n",
    "                            field_outliers[0][ii]+=1\n",
    "                else:\n",
    "                    master_cat[counter]['member'] = 1               #phot SF field sample\n",
    "                    for ii in range(len(field_phot[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of field galaxies by cluster\n",
    "                            field_phot[0][ii]+=1\n",
    "            elif abs(master_cat[counter]['z_clusterphot']) < z_cutoff[1]:\n",
    "                master_cat[counter]['member'] = 0           # member=0 is secure cluster member\n",
    "                for ii in range(len(mem_phot[0])):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):  # keep track of field galaxies by cluster\n",
    "                        mem_phot[0][ii]+=1\n",
    "            else:\n",
    "                for ii in range(len(lost_due_to_buffer_phot[0])):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):  # keep track of field galaxies by cluster\n",
    "                        lost_due_to_buffer_phot[0][ii]+=1\n",
    "        elif master_cat[counter]['type'] ==2:       #Q\n",
    "            n_Q+=1\n",
    "            if abs(master_cat[counter]['z_clusterphot']) > 0.1:     # identify field galaxies\n",
    "                if master_cat[counter]['z_peak'] >0.55 or master_cat[counter]['z_peak'] <0.3:\n",
    "                    master_cat[counter]['member'] = 4       # memfield outlier\n",
    "                    for ii in range(len(field_outliers[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of field outlier galaxies by cluster\n",
    "                            field_outliers[1][ii]+=1\n",
    "                else:\n",
    "                    master_cat[counter]['member'] = 1               #phot SF field sample\n",
    "                    for ii in range(len(field_phot[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of field galaxies by cluster\n",
    "                            field_phot[1][ii]+=1\n",
    "            elif abs(master_cat[counter]['z_clusterphot']) < z_cutoff[1]:\n",
    "                master_cat[counter]['member'] = 0           # member=0 is secure cluster member\n",
    "                for ii in range(len(mem_phot[1])):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):  # keep track of field galaxies by cluster\n",
    "                        mem_phot[1][ii]+=1\n",
    "            else:\n",
    "                for ii in range(len(lost_due_to_buffer_phot[1])):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):  # keep track of field galaxies by cluster\n",
    "                        lost_due_to_buffer_phot[1][ii]+=1\n",
    "    else: \n",
    "        other_phot+=1\n",
    "#                        \n",
    "## SECTION (5.1): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_5\n",
    "##  summarize data population as segregated above, and display in a table\n",
    "diag_flag_5 = 1\n",
    "#\n",
    "if (diag_flag_5== 1 and diag_flag_master ==2) or diag_flag_master ==1:\n",
    "    ## Summarize initial data stats in table\n",
    "    member_names = Column(['Total','Secure member','Secure field'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    # SF table\n",
    "    member0 = Column([np.sum([mem_phot[0],field_phot[0]]),np.sum(mem_phot[0]),np.sum(field_phot[0])],name='Total')  # total column\n",
    "    SF_phot_stats = Table([member_names,member0])\n",
    "    for ii in range(len(mem_phot[0])):\n",
    "        col = Column([np.sum([mem_phot[0][ii],field_phot[0][ii]]),mem_phot[0][ii],field_phot[0][ii]],name=col_names[ii])\n",
    "        SF_phot_stats.add_column(col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    # Q table\n",
    "    member0 = Column([np.sum([mem_phot[1],field_phot[1]]),np.sum(mem_phot[1]),np.sum(field_phot[1])],name='Total')  # total column\n",
    "    Q_phot_stats = Table([member_names,member0])\n",
    "    for ii in range(len(mem_phot[1])):\n",
    "        col = Column([np.sum([mem_phot[1][ii],field_phot[1][ii]]),mem_phot[1][ii],field_phot[1][ii]],name=col_names[ii])\n",
    "        Q_phot_stats.add_column(col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    print('PHOT-ONLY Subsample\\nCatalogue by MEMBER - Star-forming:')\n",
    "    print(SF_phot_stats)\n",
    "    print('NOTE: Total reported under each cluster is sum of SF+Q.\\n')\n",
    "    print('Catalogue by MEMBER - Quiescent:')\n",
    "    print(Q_phot_stats)\n",
    "    print('Lost due to buffer b/w member & field\\nSF: %s'%np.sum(lost_due_to_buffer_phot[0]),';    Q: %s'%np.sum(lost_due_to_buffer_phot[1]))\n",
    "    print('NOTE: Total reported under each cluster is sum of SF+Q.')\n",
    "    print('NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\\n')\n",
    "#\n",
    "mem_phot_fraction = np.array([0]*2,dtype='float32')     # to keep track of membership acceptance fraction\n",
    "mem_phot_fraction[0] = (np.sum(mem_phot[0]) / n_SF)\n",
    "mem_phot_fraction[1] = (np.sum(mem_phot[1]) / n_Q)\n",
    "#\n",
    "print('\\nOverall membership fraction: \\nSF: %s'%mem_phot_fraction[0],' & Q: %s'%mem_phot_fraction[1],'   for cutoff: %s'%str(z_cutoff))\n",
    "#\n",
    "print('\\nTotal catalogue length: %s'%len(master_cat))\n",
    "print('PHOT ONLY sub-sample: %s' %n_phot_only)\n",
    "print('SF (members + field): %s' % np.sum([mem_phot[0],field_phot[0]]))\n",
    "print('Q (members + field): %s' % np.sum([mem_phot[1],field_phot[1]]))\n",
    "print('Field outliers (z>0.55 or z<0.3): %s' % np.sum(field_outliers))\n",
    "print('Lost due to buffer b/w definition of cluster member/field: %s'%np.sum(lost_due_to_buffer_phot))\n",
    "print('Stars & outliers: %s' % stars_outliers)\n",
    "print('Sum of the above: %s'%np.sum([np.sum(lost_due_to_buffer_phot),np.sum(field_outliers),np.sum([mem_phot[1],field_phot[1]]),np.sum([mem_phot[0],field_phot[0]])]))\n",
    "print('Difference between # in PHOT-ONLY subsample & sum above: %s'%(n_phot_only - np.sum([np.sum(lost_due_to_buffer_phot),np.sum(field_outliers),np.sum([mem_phot[1],field_phot[1]]),np.sum([mem_phot[0],field_phot[0]])])))\n",
    "print('Other (not in phot only subsample): %s'%other_phot)\n",
    "print('NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\\n')                        \n",
    "#\n",
    "## TIME_FLAG_5 END\n",
    "#\n",
    "if time_flag_5 == 1 and time_flag == 0:\n",
    "    print(\"Section 5 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#                        \n",
    "## SECTION (6): BCGs. Brightest Cluster Galaxies (BCGs) need to be taken out of the cluster sample as they are unique to overly dense environments and so lack a counterpart in the field against which to make a fair comparison. as such, we remove them from our sample before making the SMF\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_6 START\n",
    "time_flag_6 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_6 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#\n",
    "## BCGs are identified in the \"flag_{band}\" column, flag_{ban} = 4 for BCGs. I will use band=F160W to identify BCGs\n",
    "#\n",
    "num_BCG = np.array([0]*6)\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['flag_F160W'][counter] == 4:\n",
    "        master_cat['member'][counter] = 5              # member=5 for BCGs so they don't contaminate the \"member=0\" cluster member sample\n",
    "        for ii in range(len(num_BCG)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                num_bcg[ii]+=1\n",
    "#\n",
    "## print summary of operation\n",
    "print('Total BCGs removed from catalogue: %s'%np.sum(num_BCG),'.\\nBCGs removed by cluster: %s'%num_BCG)\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_6 END\n",
    "time_flag_6 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_6 == 1 and time_flag == 0:\n",
    "    print(\"Section 6 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## TIME_FLAG END\n",
    "#\n",
    "if time_flag == 1:\n",
    "    print('Program \"master_data_7_final.py\" took: %s seconds to run.\\n\\n' % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#                        \n",
    "###### PROGRAM END ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'limiting_mass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d3b7dffabeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimiting_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m           \u001b[0;31m# only look at objects above the limiting mass for each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lmass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlimiting_mass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'limiting_mass' is not defined"
     ]
    }
   ],
   "source": [
    "## SECTION (3.2): calculate SPECTROSCOPIC COMPLETENESS correction. basically, look at all the false positives/false negatives, and sort them by type (i.e. SF/Q). then bin them (i.e. make histograms of false pos/neg for each of SF/Q). take their ratio of false pos to false neg, and plot that ratio. it is the correction factor to be applied to the photometric subsample\n",
    "#\n",
    "## TIME_FLAG: START\n",
    "## superior time_flag which supercedes all others and times the entire program\n",
    "time_flag = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag == 1:\n",
    "    start_time = time.time()\n",
    "#\n",
    "#\n",
    "## MODULES\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "#\n",
    "##\n",
    "#\n",
    "SF_pos = []\n",
    "SF_neg = []\n",
    "Q_pos = []\n",
    "Q_neg = []\n",
    "pos_by_cluster = np.array([[0]*6]*2)    #for tracking false pos/neg by cluster; row_1=SF, row_2=Q\n",
    "neg_by_cluster = np.array([[0]*6]*2)\n",
    "objects_below_lim_mass = np.array([0]*6)    # for tracking objects below the limiting mass of each cluster\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    for ii in range(len(limiting_mass)):\n",
    "        if master_cat['cluster'][counter] == (ii+1):           # only look at objects above the limiting mass for each cluster\n",
    "            if master_cat['lmass'][counter] > limiting_mass[ii]:      \n",
    "                if master_cat['type'][counter] == 1:      # type=1 for SF\n",
    "                    if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                        SF_pos.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[0])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                pos_by_cluster[0]+=1           # track false pos for SF\n",
    "                    elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                        SF_neg.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[0])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                neg_by_cluster[0]+=1           # track false neg for SF\n",
    "                elif master_cat['type'][counter] == 2:     # type=2 for Q\n",
    "                    if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                        Q_pos.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[1])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                pos_by_cluster[1]+=1           # track false pos for Q\n",
    "                    elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                        Q_neg.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(neg_by_cluster[1])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                neg_by_cluster[1]+=1           # track false neg for Q\n",
    "            else: \n",
    "                objects_below_lim_mass[ii]+=1\n",
    "#\n",
    "#\n",
    "#\n",
    "## sort false pos/neg lists in ascending order\n",
    "SF_pos = np.sort(SF_pos)\n",
    "SF_neg = np.sort(SF_neg)\n",
    "Q_pos = np.sort(Q_pos)\n",
    "Q_neg = np.sort(Q_neg)\n",
    "#\n",
    "#\n",
    "#\n",
    "## open a file to print to\n",
    "f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/binning_%s'%z_cutoff[0]+'_spec_cutoff_%s'%z_cutoff[1]+'_phot_cutoff.txt','w+')\n",
    "#\n",
    "## to be used in building strings throughout program\n",
    "space = ' '   \n",
    "## write a header for the file, start with hashtag to identify comment\n",
    "header1 = \"### COLS:\\n###(1)z_spec_cutoff  (2)z_phot_cutoff  (3)type[SF/Q]  (4)binning_method  (5)#_of_bins variance[SF/Q]  (6)total_variance[SF+Q]\\n\"\n",
    "#\n",
    "f.write(header1)\n",
    "#\n",
    "#\n",
    "# SPEC. BINNING: iterate through different number of histogram bins to see which yields a set of corrections closest in general to ~1; this has now been expanded to test: method = 1, SYMMETRIC binning; method = 2, ASYMMETRIC binning, EQUAL NUMBER of objects in each bin; method = 2, ASYMMETRIC binning, equal MASS in each bin;\n",
    "#\n",
    "#\n",
    "### METHOD 1: bin SF & Q in SYMMETRIC BINS, then compute false pos/neg fractions by mass bin for correction factors. \n",
    "#\n",
    "## number of histogram mass bins to try for spec. completeness correction\n",
    "num_bins_to_try = [2,3,4,5,6,7,8]   \n",
    "# write a loop that interatively uses a different number of bins in the histrogram, to isolate the largest number for which all bins have at least one entry; NOTE: the lines that stop the loop have been commented out, to investigate the relative fraction of false pos/neg for each different # of bins\n",
    "#\n",
    "# \n",
    "method = 1\n",
    "for number in range(len(num_bins_to_try)):\n",
    "    #\n",
    "    # make histograms\n",
    "    SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=num_bins_to_try[number], range=range2)\n",
    "    SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=num_bins_to_try[number], range=range2)\n",
    "    Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=num_bins_to_try[number], range=range2)\n",
    "    Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=num_bins_to_try[number], range=range2)\n",
    "    #\n",
    "    SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "    Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "    for jj in range(len(SF_pos_hist)):\n",
    "        if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            SF_ratio[jj] = 1\n",
    "    for jj in range(len(Q_pos_hist)):\n",
    "        if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            Q_ratio[jj] = 1\n",
    "    #\n",
    "    ## compute variance of SF/Q ratios from 1\n",
    "    SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    total_var = SF_var + Q_var\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "#\n",
    "#\n",
    "#\n",
    "### METHOD 2: ASYMMETRIC BINS for bins with ~EQUAL NUMBER OF OBJECTS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "#\n",
    "method = 2\n",
    "#\n",
    "##\n",
    "for number in range(len(num_bins_to_try)):    #number of bin EDGES (i.e. # of bins + 1)\n",
    "    ## compute the index corresponding to the first evenly-space bin edge\n",
    "    SF_pos_index = int(np.ceil(len(SF_pos))/(num_bins_to_try[number]))\n",
    "    SF_neg_index = int(np.ceil(len(SF_neg))/(num_bins_to_try[number]))\n",
    "    Q_pos_index = int(np.ceil(len(Q_pos))/(num_bins_to_try[number]))\n",
    "    Q_neg_index = int(np.ceil(len(Q_neg))/(num_bins_to_try[number]))\n",
    "    ## build arrays over range [7.3,12.3] with \"num_bins_to_try[number]\" bins, where each bin has ~equal # of objects in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "    num_bins_SF = [[],[]]     # [pos, neg]  i.e. bin edges of mass bins\n",
    "    num_bins_Q = [[],[]]     # [pos, neg]\n",
    "    #a=0\n",
    "    #b=0\n",
    "    for ii in range(num_bins_to_try[number]):   # -1 b/c there are 1 fewer bins than bin edges\n",
    "        num_bins_SF[0].append(SF_pos[(ii*SF_pos_index)])\n",
    "        num_bins_SF[1].append(SF_neg[(ii*SF_neg_index)])\n",
    "        num_bins_Q[0].append(Q_pos[(ii*Q_pos_index)])\n",
    "        num_bins_Q[1].append(Q_neg[(ii*Q_neg_index)])\n",
    "    #\n",
    "    num_bins_SF[0].append(SF_pos[-1])\n",
    "    num_bins_SF[1].append(SF_neg[-1])\n",
    "    num_bins_Q[0].append(Q_pos[-1])\n",
    "    num_bins_Q[1].append(Q_neg[-1])\n",
    "    #\n",
    "    num_bins_SF = np.array(num_bins_SF)\n",
    "    num_bins_Q = np.array(num_bins_Q)\n",
    "    #print('# bins: %s'%(num_bins_to_try[number]))\n",
    "    #print('length of num_bins_* array (which stores bin edges): %s'%len(num_bins_SF[0]))\n",
    "    #print(('num_bins_SF: %s'%num_bins_SF)\n",
    "    #\n",
    "    ## compute midpoints between false pos/neg bin edges\n",
    "    bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "    bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "    ## set first/last entry as limits of mass range for smf\n",
    "    bin_edge_means_SF[0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "    bin_edge_means_SF[-1] = range2[-1]\n",
    "    bin_edge_means_Q[0] = range2[0]\n",
    "    bin_edge_means_Q[-1] = range2[-1]\n",
    "    #print('length of bin_edge_means_* array: %s'%len(bin_edge_means_SF))\n",
    "    #print('bin_edge_means_SF: %s'%bin_edge_means_SF)\n",
    "    ## build new histograms\n",
    "    SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "    SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "    Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "    Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "    ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "    SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "    Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "    for jj in range(len(SF_pos_hist)):\n",
    "        if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            SF_ratio[jj] = 1\n",
    "    for jj in range(len(Q_pos_hist)):\n",
    "        if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            Q_ratio[jj] = 1\n",
    "    #\n",
    "    ## compute variance of SF/Q ratios from 1\n",
    "    SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    total_var = SF_var + Q_var\n",
    "    #\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "#\n",
    "#\n",
    "#\n",
    "### METHOD 3: ASYMMETRIC BINS for bins with ~EQUAL AMOUNTS OF MASS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "#\n",
    "method = 3\n",
    "#\n",
    "## \n",
    "for number in range(len(num_bins_to_try)):\n",
    "    SF_pos_sum_index = np.ceil(np.sum(SF_pos)/num_bins_to_try[number]) \n",
    "    SF_neg_sum_index = np.ceil(np.sum(SF_neg)/num_bins_to_try[number])\n",
    "    Q_pos_sum_index = np.ceil(np.sum(Q_pos)/num_bins_to_try[number])\n",
    "    Q_neg_sum_index = np.ceil(np.sum(Q_neg)/num_bins_to_try[number])\n",
    "    ## build arrays over range [7.3,12.3] with num_bins_to_try[number] bins, where each bin has ~equal amounts of mass in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "    num_bins_SF_index = [[],[]]     # [pos, neg]\n",
    "    num_bins_Q_index = [[],[]]     # [pos, neg]\n",
    "    # look through SF/Q false pos/neg lists one galaxy at a time, summing their mass until you reach the amount stored in *_sum_index (e.g. SF_pos_sum_index for SF_pos list), then record that index as a bin edge\n",
    "    #num_bins_SF[0].append(SF_pos[0])\n",
    "    ## SF_posfor ii in range(num_bins_to_try[number]):\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(SF_pos)):\n",
    "            mass_sum = mass_sum + SF_pos[jj]\n",
    "            if mass_sum >= ii*SF_pos_sum_index:\n",
    "                #print('\\nSF_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_pos_sum_index),'jj: %s'%jj)\n",
    "                num_bins_SF_index[0].append(jj)\n",
    "                break\n",
    "    ## SF_neg\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(SF_neg)):\n",
    "            mass_sum = mass_sum + SF_neg[jj]\n",
    "            if mass_sum >= ii*SF_neg_sum_index:\n",
    "                #print('\\nSF_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_neg_sum_index),'jj: %s'%jj)\n",
    "                num_bins_SF_index[1].append(jj)\n",
    "                break\n",
    "    ## Q_pos\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(Q_pos)):\n",
    "            mass_sum = mass_sum + Q_pos[jj]\n",
    "            if mass_sum >= ii*Q_pos_sum_index:\n",
    "                #print('\\nQ_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_pos_sum_index),'jj: %s'%jj)\n",
    "                num_bins_Q_index[0].append(jj)\n",
    "                break\n",
    "    ## Q_neg\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(Q_neg)):\n",
    "            mass_sum = mass_sum + Q_neg[jj]\n",
    "            if mass_sum >= ii*Q_neg_sum_index:\n",
    "                #print('\\nQ_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_neg_sum_index),'jj: %s'%jj)\n",
    "                num_bins_Q_index[1].append(jj)\n",
    "                break\n",
    "    #\n",
    "    ## add last (highest-mass) bin edge\n",
    "    num_bins_SF_index[0].append(len(SF_pos)-1)\n",
    "    num_bins_SF_index[1].append(len(SF_neg)-1)\n",
    "    num_bins_Q_index[0].append(len(Q_pos)-1)\n",
    "    num_bins_Q_index[1].append(len(Q_neg)-1)\n",
    "    ## convert to arrays\n",
    "    num_bins_SF_index = np.array(num_bins_SF_index)\n",
    "    num_bins_Q_index = np.array(num_bins_Q_index)\n",
    "    #print('# bins: %s'%(num_bins_to_try[number]-1))\n",
    "    #print('length of num_bins_* array: %s'%len(num_bins_SF_index[0]),'\\nlength of SF array: %s'%len(SF_pos),'\\nlength of Q array: %s'%len(Q_pos))\n",
    "    #print('indices corresponding to bin edges\\nSF: %s'%num_bins_SF_index,'\\nQ: %s'%num_bins_Q_index)\n",
    "    #\n",
    "    ## convert to arrays\n",
    "    num_bins_SF = np.empty_like(num_bins_SF_index,dtype='float32')\n",
    "    num_bins_Q = np.empty_like(num_bins_Q_index,dtype='float32')\n",
    "    #\n",
    "    ## SF: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "    # \n",
    "    try:\n",
    "        for ii in range(len(num_bins_SF[0])):\n",
    "            num_bins_SF[0][ii] = SF_pos[num_bins_SF_index[0][ii]]\n",
    "            num_bins_SF[1][ii] = SF_neg[num_bins_SF_index[1][ii]]\n",
    "        #\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        num_bins_SF[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        num_bins_SF[1][0] = range2[0]\n",
    "        num_bins_SF[0][-1] = range2[-1] \n",
    "        num_bins_SF[1][-1] = range2[-1]\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "        #\n",
    "        ## build new histograms\n",
    "        SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "        SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "        for jj in range(len(SF_pos_hist)):\n",
    "            if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                SF_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    except:\n",
    "        print('# bins exceeds length of SF false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "        SF_ratio = 'n/a'\n",
    "        SF_var = 'n/a'\n",
    "    \n",
    "    ## Q: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "    try:\n",
    "        for ii in range(len(num_bins_Q[0])):\n",
    "            num_bins_Q[0][ii] = Q_pos[num_bins_Q_index[0][ii]]\n",
    "            num_bins_Q[1][ii] = Q_neg[num_bins_Q_index[1][ii]]\n",
    "        #\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        num_bins_Q[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        num_bins_Q[1][0] = range2[0]\n",
    "        num_bins_Q[0][-1] = range2[-1]\n",
    "        num_bins_Q[1][-1] = range2[-1]\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "        #\n",
    "        ## build new histograms\n",
    "        Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "        Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "        for jj in range(len(Q_pos_hist)):\n",
    "            if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                Q_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    except:\n",
    "        print('# bins exceeds length of Q false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "        Q_ratio = 'n/a'\n",
    "        Q_var = 'n/a'\n",
    "    #\n",
    "    if SF_ratio == 'n/a':\n",
    "        total_var = Q_var\n",
    "    elif Q_ratio == 'n/a':\n",
    "        total_var = SF_var\n",
    "    else: \n",
    "        total_var = np.round((SF_var + Q_var),decimals=3)\n",
    "        SF_var = np.round(SF_var,decimals=3)\n",
    "        Q_var = np.round(Q_var,decimals=3)\n",
    "    #\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%SF_var+space+'%s'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%Q_var+space+'%s'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "    #\n",
    "#\n",
    "#\n",
    "## close the file       \n",
    "f.close()\n",
    "#\n",
    "#\n",
    "#\n",
    "## TIME_FLAG END\n",
    "#\n",
    "if time_flag == 1:\n",
    "    print('Program \"spec_completeness_binning.py\" took: %s seconds to run.\\n\\n' % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#                      \n",
    "###### PROGRAM END ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'range2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bb168a061bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# make histograms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mSF_pos_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins_SF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bins_to_try\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mSF_neg_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins_SF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSF_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bins_to_try\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mQ_pos_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bins_to_try\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'range2' is not defined"
     ]
    }
   ],
   "source": [
    "## SECTION (3.2): calculate SPECTROSCOPIC COMPLETENESS correction. basically, look at all the false positives/false negatives, and sort them by type (i.e. SF/Q). then bin them (i.e. make histograms of false pos/neg for each of SF/Q). take their ratio of false pos to false neg, and plot that ratio. it is the correction factor to be applied to the photometric subsample\n",
    "#\n",
    "## TIME_FLAG: START\n",
    "## superior time_flag which supercedes all others and times the entire program\n",
    "time_flag = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag == 1:\n",
    "    start_time = time.time()\n",
    "#\n",
    "#\n",
    "## MODULES\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "#\n",
    "##\n",
    "limiting_mass = [7.5,7.8,8.0,7.5,7.4,7.3] # clusters 1,2,3,4,5,6, see IDs below\n",
    "#\n",
    "SF_pos = []\n",
    "SF_neg = []\n",
    "Q_pos = []\n",
    "Q_neg = []\n",
    "pos_by_cluster = np.array([[0]*6]*2)    #for tracking false pos/neg by cluster; row_1=SF, row_2=Q\n",
    "neg_by_cluster = np.array([[0]*6]*2)\n",
    "objects_below_lim_mass = np.array([0]*6)    # for tracking objects below the limiting mass of each cluster\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    for ii in range(len(limiting_mass)):\n",
    "        if master_cat['cluster'][counter] == (ii+1):           # only look at objects above the limiting mass for each cluster\n",
    "            if master_cat['lmass'][counter] > limiting_mass[ii]:      \n",
    "                if master_cat['type'][counter] == 1:      # type=1 for SF\n",
    "                    if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                        SF_pos.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[0])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                pos_by_cluster[0]+=1           # track false pos for SF\n",
    "                    elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                        SF_neg.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[0])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                neg_by_cluster[0]+=1           # track false neg for SF\n",
    "                elif master_cat['type'][counter] == 2:     # type=2 for Q\n",
    "                    if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                        Q_pos.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[1])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                pos_by_cluster[1]+=1           # track false pos for Q\n",
    "                    elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                        Q_neg.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(neg_by_cluster[1])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                neg_by_cluster[1]+=1           # track false neg for Q\n",
    "            else: \n",
    "                objects_below_lim_mass[ii]+=1\n",
    "#\n",
    "#\n",
    "#\n",
    "## sort false pos/neg lists in ascending order\n",
    "SF_pos = np.sort(SF_pos)\n",
    "SF_neg = np.sort(SF_neg)\n",
    "Q_pos = np.sort(Q_pos)\n",
    "Q_neg = np.sort(Q_neg)\n",
    "#\n",
    "#\n",
    "#\n",
    "## open a file to print to\n",
    "f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/binning_%s'%z_cutoff[0]+'_spec_cutoff_%s'%z_cutoff[1]+'_phot_cutoff.txt','w+')\n",
    "#\n",
    "## to be used in building strings throughout program\n",
    "space = ' '   \n",
    "## write a header for the file, start with hashtag to identify comment\n",
    "header1 = \"### COLS:\\n###(1)z_spec_cutoff  (2)z_phot_cutoff  (3)type[SF/Q]  (4)binning_method  (5)#_of_bins variance[SF/Q]  (6)total_variance[SF+Q]\\n\"\n",
    "#\n",
    "f.write(header1)\n",
    "#\n",
    "#\n",
    "# SPEC. BINNING: iterate through different number of histogram bins to see which yields a set of corrections closest in general to ~1; this has now been expanded to test: method = 1, SYMMETRIC binning; method = 2, ASYMMETRIC binning, EQUAL NUMBER of objects in each bin; method = 2, ASYMMETRIC binning, equal MASS in each bin;\n",
    "#\n",
    "#\n",
    "### METHOD 1: bin SF & Q in SYMMETRIC BINS, then compute false pos/neg fractions by mass bin for correction factors. \n",
    "#\n",
    "## number of histogram mass bins to try for spec. completeness correction\n",
    "num_bins_to_try = [2,3,4,5,6,7,8]   \n",
    "# write a loop that interatively uses a different number of bins in the histrogram, to isolate the largest number for which all bins have at least one entry; NOTE: the lines that stop the loop have been commented out, to investigate the relative fraction of false pos/neg for each different # of bins\n",
    "#\n",
    "# \n",
    "method = 1\n",
    "for number in range(len(num_bins_to_try)):\n",
    "    #\n",
    "    # make histograms\n",
    "    SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=num_bins_to_try[number], range=range2)\n",
    "    SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=num_bins_to_try[number], range=range2)\n",
    "    Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=num_bins_to_try[number], range=range2)\n",
    "    Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=num_bins_to_try[number], range=range2)\n",
    "    #\n",
    "    SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "    Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "    for jj in range(len(SF_pos_hist)):\n",
    "        if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            SF_ratio[jj] = 1\n",
    "    for jj in range(len(Q_pos_hist)):\n",
    "        if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            Q_ratio[jj] = 1\n",
    "    #\n",
    "    ## compute variance of SF/Q ratios from 1\n",
    "    SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    total_var = SF_var + Q_var\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "#\n",
    "#\n",
    "#\n",
    "### METHOD 2: ASYMMETRIC BINS for bins with ~EQUAL NUMBER OF OBJECTS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "#\n",
    "method = 2\n",
    "#\n",
    "##\n",
    "for number in range(len(num_bins_to_try)):    #number of bin EDGES (i.e. # of bins + 1)\n",
    "    ## compute the index corresponding to the first evenly-space bin edge\n",
    "    SF_pos_index = int(np.ceil(len(SF_pos))/(num_bins_to_try[number]))\n",
    "    SF_neg_index = int(np.ceil(len(SF_neg))/(num_bins_to_try[number]))\n",
    "    Q_pos_index = int(np.ceil(len(Q_pos))/(num_bins_to_try[number]))\n",
    "    Q_neg_index = int(np.ceil(len(Q_neg))/(num_bins_to_try[number]))\n",
    "    ## build arrays over range [7.3,12.3] with \"num_bins_to_try[number]\" bins, where each bin has ~equal # of objects in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "    num_bins_SF = [[],[]]     # [pos, neg]  i.e. bin edges of mass bins\n",
    "    num_bins_Q = [[],[]]     # [pos, neg]\n",
    "    #a=0\n",
    "    #b=0\n",
    "    for ii in range(num_bins_to_try[number]):   # -1 b/c there are 1 fewer bins than bin edges\n",
    "        num_bins_SF[0].append(SF_pos[(ii*SF_pos_index)])\n",
    "        num_bins_SF[1].append(SF_neg[(ii*SF_neg_index)])\n",
    "        num_bins_Q[0].append(Q_pos[(ii*Q_pos_index)])\n",
    "        num_bins_Q[1].append(Q_neg[(ii*Q_neg_index)])\n",
    "    #\n",
    "    num_bins_SF[0].append(SF_pos[-1])\n",
    "    num_bins_SF[1].append(SF_neg[-1])\n",
    "    num_bins_Q[0].append(Q_pos[-1])\n",
    "    num_bins_Q[1].append(Q_neg[-1])\n",
    "    #\n",
    "    num_bins_SF = np.array(num_bins_SF)\n",
    "    num_bins_Q = np.array(num_bins_Q)\n",
    "    #print('# bins: %s'%(num_bins_to_try[number]))\n",
    "    #print('length of num_bins_* array (which stores bin edges): %s'%len(num_bins_SF[0]))\n",
    "    #print(('num_bins_SF: %s'%num_bins_SF)\n",
    "    #\n",
    "    ## compute midpoints between false pos/neg bin edges\n",
    "    bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "    bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "    ## set first/last entry as limits of mass range for smf\n",
    "    bin_edge_means_SF[0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "    bin_edge_means_SF[-1] = range2[-1]\n",
    "    bin_edge_means_Q[0] = range2[0]\n",
    "    bin_edge_means_Q[-1] = range2[-1]\n",
    "    #print('length of bin_edge_means_* array: %s'%len(bin_edge_means_SF))\n",
    "    #print('bin_edge_means_SF: %s'%bin_edge_means_SF)\n",
    "    ## build new histograms\n",
    "    SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "    SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "    Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "    Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "    ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "    SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "    Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "    for jj in range(len(SF_pos_hist)):\n",
    "        if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            SF_ratio[jj] = 1\n",
    "    for jj in range(len(Q_pos_hist)):\n",
    "        if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            Q_ratio[jj] = 1\n",
    "    #\n",
    "    ## compute variance of SF/Q ratios from 1\n",
    "    SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    total_var = SF_var + Q_var\n",
    "    #\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "#\n",
    "#\n",
    "#\n",
    "### METHOD 3: ASYMMETRIC BINS for bins with ~EQUAL AMOUNTS OF MASS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "#\n",
    "method = 3\n",
    "#\n",
    "## \n",
    "for number in range(len(num_bins_to_try)):\n",
    "    SF_pos_sum_index = np.ceil(np.sum(SF_pos)/num_bins_to_try[number]) \n",
    "    SF_neg_sum_index = np.ceil(np.sum(SF_neg)/num_bins_to_try[number])\n",
    "    Q_pos_sum_index = np.ceil(np.sum(Q_pos)/num_bins_to_try[number])\n",
    "    Q_neg_sum_index = np.ceil(np.sum(Q_neg)/num_bins_to_try[number])\n",
    "    ## build arrays over range [7.3,12.3] with num_bins_to_try[number] bins, where each bin has ~equal amounts of mass in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "    num_bins_SF_index = [[],[]]     # [pos, neg]\n",
    "    num_bins_Q_index = [[],[]]     # [pos, neg]\n",
    "    # look through SF/Q false pos/neg lists one galaxy at a time, summing their mass until you reach the amount stored in *_sum_index (e.g. SF_pos_sum_index for SF_pos list), then record that index as a bin edge\n",
    "    #num_bins_SF[0].append(SF_pos[0])\n",
    "    ## SF_posfor ii in range(num_bins_to_try[number]):\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(SF_pos)):\n",
    "            mass_sum = mass_sum + SF_pos[jj]\n",
    "            if mass_sum >= ii*SF_pos_sum_index:\n",
    "                #print('\\nSF_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_pos_sum_index),'jj: %s'%jj)\n",
    "                num_bins_SF_index[0].append(jj)\n",
    "                break\n",
    "    ## SF_neg\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(SF_neg)):\n",
    "            mass_sum = mass_sum + SF_neg[jj]\n",
    "            if mass_sum >= ii*SF_neg_sum_index:\n",
    "                #print('\\nSF_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_neg_sum_index),'jj: %s'%jj)\n",
    "                num_bins_SF_index[1].append(jj)\n",
    "                break\n",
    "    ## Q_pos\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(Q_pos)):\n",
    "            mass_sum = mass_sum + Q_pos[jj]\n",
    "            if mass_sum >= ii*Q_pos_sum_index:\n",
    "                #print('\\nQ_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_pos_sum_index),'jj: %s'%jj)\n",
    "                num_bins_Q_index[0].append(jj)\n",
    "                break\n",
    "    ## Q_neg\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(Q_neg)):\n",
    "            mass_sum = mass_sum + Q_neg[jj]\n",
    "            if mass_sum >= ii*Q_neg_sum_index:\n",
    "                #print('\\nQ_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_neg_sum_index),'jj: %s'%jj)\n",
    "                num_bins_Q_index[1].append(jj)\n",
    "                break\n",
    "    #\n",
    "    ## add last (highest-mass) bin edge\n",
    "    num_bins_SF_index[0].append(len(SF_pos)-1)\n",
    "    num_bins_SF_index[1].append(len(SF_neg)-1)\n",
    "    num_bins_Q_index[0].append(len(Q_pos)-1)\n",
    "    num_bins_Q_index[1].append(len(Q_neg)-1)\n",
    "    ## convert to arrays\n",
    "    num_bins_SF_index = np.array(num_bins_SF_index)\n",
    "    num_bins_Q_index = np.array(num_bins_Q_index)\n",
    "    #print('# bins: %s'%(num_bins_to_try[number]-1))\n",
    "    #print('length of num_bins_* array: %s'%len(num_bins_SF_index[0]),'\\nlength of SF array: %s'%len(SF_pos),'\\nlength of Q array: %s'%len(Q_pos))\n",
    "    #print('indices corresponding to bin edges\\nSF: %s'%num_bins_SF_index,'\\nQ: %s'%num_bins_Q_index)\n",
    "    #\n",
    "    ## convert to arrays\n",
    "    num_bins_SF = np.empty_like(num_bins_SF_index,dtype='float32')\n",
    "    num_bins_Q = np.empty_like(num_bins_Q_index,dtype='float32')\n",
    "    #\n",
    "    ## SF: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "    # \n",
    "    try:\n",
    "        for ii in range(len(num_bins_SF[0])):\n",
    "            num_bins_SF[0][ii] = SF_pos[num_bins_SF_index[0][ii]]\n",
    "            num_bins_SF[1][ii] = SF_neg[num_bins_SF_index[1][ii]]\n",
    "        #\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        num_bins_SF[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        num_bins_SF[1][0] = range2[0]\n",
    "        num_bins_SF[0][-1] = range2[-1] \n",
    "        num_bins_SF[1][-1] = range2[-1]\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "        #\n",
    "        ## build new histograms\n",
    "        SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "        SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "        for jj in range(len(SF_pos_hist)):\n",
    "            if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                SF_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    except:\n",
    "        print('# bins exceeds length of SF false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "        SF_ratio = 'n/a'\n",
    "        SF_var = 'n/a'\n",
    "    \n",
    "    ## Q: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "    try:\n",
    "        for ii in range(len(num_bins_Q[0])):\n",
    "            num_bins_Q[0][ii] = Q_pos[num_bins_Q_index[0][ii]]\n",
    "            num_bins_Q[1][ii] = Q_neg[num_bins_Q_index[1][ii]]\n",
    "        #\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        num_bins_Q[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        num_bins_Q[1][0] = range2[0]\n",
    "        num_bins_Q[0][-1] = range2[-1]\n",
    "        num_bins_Q[1][-1] = range2[-1]\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "        #\n",
    "        ## build new histograms\n",
    "        Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "        Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "        for jj in range(len(Q_pos_hist)):\n",
    "            if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                Q_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    except:\n",
    "        print('# bins exceeds length of Q false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "        Q_ratio = 'n/a'\n",
    "        Q_var = 'n/a'\n",
    "    #\n",
    "    if SF_ratio == 'n/a':\n",
    "        total_var = Q_var\n",
    "    elif Q_ratio == 'n/a':\n",
    "        total_var = SF_var\n",
    "    else: \n",
    "        total_var = np.round((SF_var + Q_var),decimals=3)\n",
    "        SF_var = np.round(SF_var,decimals=3)\n",
    "        Q_var = np.round(Q_var,decimals=3)\n",
    "    #\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%SF_var+space+'%s'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%Q_var+space+'%s'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "    #\n",
    "#\n",
    "#\n",
    "## close the file       \n",
    "f.close()\n",
    "#\n",
    "#\n",
    "#\n",
    "## TIME_FLAG END\n",
    "#\n",
    "if time_flag == 1:\n",
    "    print('Program \"spec_completeness_binning.py\" took: %s seconds to run.\\n\\n' % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#                      \n",
    "###### PROGRAM END ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program \"spec_completeness_binning.py\" took: 1.2085890769958496 seconds to run.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:101: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:101: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:102: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:102: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:171: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:324: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:326: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:281: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "## SECTION (3.2): calculate SPECTROSCOPIC COMPLETENESS correction. basically, look at all the false positives/false negatives, and sort them by type (i.e. SF/Q). then bin them (i.e. make histograms of false pos/neg for each of SF/Q). take their ratio of false pos to false neg, and plot that ratio. it is the correction factor to be applied to the photometric subsample\n",
    "#\n",
    "## TIME_FLAG: START\n",
    "## superior time_flag which supercedes all others and times the entire program\n",
    "time_flag = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag == 1:\n",
    "    start_time = time.time()\n",
    "#\n",
    "#\n",
    "## MODULES\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "#\n",
    "##\n",
    "limiting_mass = [7.5,7.8,8.0,7.5,7.4,7.3] # clusters 1,2,3,4,5,6, see IDs below\n",
    "range2 = [7.3,12.3]\n",
    "#\n",
    "SF_pos = []\n",
    "SF_neg = []\n",
    "Q_pos = []\n",
    "Q_neg = []\n",
    "pos_by_cluster = np.array([[0]*6]*2)    #for tracking false pos/neg by cluster; row_1=SF, row_2=Q\n",
    "neg_by_cluster = np.array([[0]*6]*2)\n",
    "objects_below_lim_mass = np.array([0]*6)    # for tracking objects below the limiting mass of each cluster\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    for ii in range(len(limiting_mass)):\n",
    "        if master_cat['cluster'][counter] == (ii+1):           # only look at objects above the limiting mass for each cluster\n",
    "            if master_cat['lmass'][counter] > limiting_mass[ii]:      \n",
    "                if master_cat['type'][counter] == 1:      # type=1 for SF\n",
    "                    if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                        SF_pos.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[0])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                pos_by_cluster[0]+=1           # track false pos for SF\n",
    "                    elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                        SF_neg.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[0])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                neg_by_cluster[0]+=1           # track false neg for SF\n",
    "                elif master_cat['type'][counter] == 2:     # type=2 for Q\n",
    "                    if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                        Q_pos.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(pos_by_cluster[1])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                pos_by_cluster[1]+=1           # track false pos for Q\n",
    "                    elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                        Q_neg.append(master_cat['lmass'][counter])\n",
    "                        for ii in range(len(neg_by_cluster[1])):\n",
    "                            if master_cat['cluster'][ii] == (ii+1):\n",
    "                                neg_by_cluster[1]+=1           # track false neg for Q\n",
    "            else: \n",
    "                objects_below_lim_mass[ii]+=1\n",
    "#\n",
    "#\n",
    "#\n",
    "## sort false pos/neg lists in ascending order\n",
    "SF_pos = np.sort(SF_pos)\n",
    "SF_neg = np.sort(SF_neg)\n",
    "Q_pos = np.sort(Q_pos)\n",
    "Q_neg = np.sort(Q_neg)\n",
    "#\n",
    "#\n",
    "#\n",
    "## open a file to print to\n",
    "f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/binning_%s'%z_cutoff[0]+'_spec_cutoff_%s'%z_cutoff[1]+'_phot_cutoff.txt','w+')\n",
    "#\n",
    "## to be used in building strings throughout program\n",
    "space = ' '   \n",
    "## write a header for the file, start with hashtag to identify comment\n",
    "header1 = \"### COLS:\\n###(1)z_spec_cutoff  (2)z_phot_cutoff  (3)type[SF/Q]  (4)binning_method  (5)#_of_bins variance[SF/Q]  (6)total_variance[SF+Q]\\n\"\n",
    "#\n",
    "f.write(header1)\n",
    "#\n",
    "#\n",
    "# SPEC. BINNING: iterate through different number of histogram bins to see which yields a set of corrections closest in general to ~1; this has now been expanded to test: method = 1, SYMMETRIC binning; method = 2, ASYMMETRIC binning, EQUAL NUMBER of objects in each bin; method = 2, ASYMMETRIC binning, equal MASS in each bin;\n",
    "#\n",
    "#\n",
    "### METHOD 1: bin SF & Q in SYMMETRIC BINS, then compute false pos/neg fractions by mass bin for correction factors. \n",
    "#\n",
    "## number of histogram mass bins to try for spec. completeness correction\n",
    "num_bins_to_try = [2,3,4,5,6,7,8]   \n",
    "# write a loop that interatively uses a different number of bins in the histrogram, to isolate the largest number for which all bins have at least one entry; NOTE: the lines that stop the loop have been commented out, to investigate the relative fraction of false pos/neg for each different # of bins\n",
    "#\n",
    "# \n",
    "method = 1\n",
    "for number in range(len(num_bins_to_try)):\n",
    "    #\n",
    "    # make histograms\n",
    "    SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=num_bins_to_try[number], range=range2)\n",
    "    SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=num_bins_to_try[number], range=range2)\n",
    "    Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=num_bins_to_try[number], range=range2)\n",
    "    Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=num_bins_to_try[number], range=range2)\n",
    "    #\n",
    "    SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "    Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "    for jj in range(len(SF_pos_hist)):\n",
    "        if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            SF_ratio[jj] = 1\n",
    "    for jj in range(len(Q_pos_hist)):\n",
    "        if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            Q_ratio[jj] = 1\n",
    "    #\n",
    "    ## compute variance of SF/Q ratios from 1\n",
    "    SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    total_var = SF_var + Q_var\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "#\n",
    "#\n",
    "#\n",
    "### METHOD 2: ASYMMETRIC BINS for bins with ~EQUAL NUMBER OF OBJECTS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "#\n",
    "method = 2\n",
    "#\n",
    "##\n",
    "for number in range(len(num_bins_to_try)):    #number of bin EDGES (i.e. # of bins + 1)\n",
    "    ## compute the index corresponding to the first evenly-space bin edge\n",
    "    SF_pos_index = int(np.ceil(len(SF_pos))/(num_bins_to_try[number]))\n",
    "    SF_neg_index = int(np.ceil(len(SF_neg))/(num_bins_to_try[number]))\n",
    "    Q_pos_index = int(np.ceil(len(Q_pos))/(num_bins_to_try[number]))\n",
    "    Q_neg_index = int(np.ceil(len(Q_neg))/(num_bins_to_try[number]))\n",
    "    ## build arrays over range [7.3,12.3] with \"num_bins_to_try[number]\" bins, where each bin has ~equal # of objects in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "    num_bins_SF = [[],[]]     # [pos, neg]  i.e. bin edges of mass bins\n",
    "    num_bins_Q = [[],[]]     # [pos, neg]\n",
    "    #a=0\n",
    "    #b=0\n",
    "    for ii in range(num_bins_to_try[number]):   # -1 b/c there are 1 fewer bins than bin edges\n",
    "        num_bins_SF[0].append(SF_pos[(ii*SF_pos_index)])\n",
    "        num_bins_SF[1].append(SF_neg[(ii*SF_neg_index)])\n",
    "        num_bins_Q[0].append(Q_pos[(ii*Q_pos_index)])\n",
    "        num_bins_Q[1].append(Q_neg[(ii*Q_neg_index)])\n",
    "    #\n",
    "    num_bins_SF[0].append(SF_pos[-1])\n",
    "    num_bins_SF[1].append(SF_neg[-1])\n",
    "    num_bins_Q[0].append(Q_pos[-1])\n",
    "    num_bins_Q[1].append(Q_neg[-1])\n",
    "    #\n",
    "    num_bins_SF = np.array(num_bins_SF)\n",
    "    num_bins_Q = np.array(num_bins_Q)\n",
    "    #print('# bins: %s'%(num_bins_to_try[number]))\n",
    "    #print('length of num_bins_* array (which stores bin edges): %s'%len(num_bins_SF[0]))\n",
    "    #print(('num_bins_SF: %s'%num_bins_SF)\n",
    "    #\n",
    "    ## compute midpoints between false pos/neg bin edges\n",
    "    bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "    bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "    ## set first/last entry as limits of mass range for smf\n",
    "    bin_edge_means_SF[0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "    bin_edge_means_SF[-1] = range2[-1]\n",
    "    bin_edge_means_Q[0] = range2[0]\n",
    "    bin_edge_means_Q[-1] = range2[-1]\n",
    "    #print('length of bin_edge_means_* array: %s'%len(bin_edge_means_SF))\n",
    "    #print('bin_edge_means_SF: %s'%bin_edge_means_SF)\n",
    "    ## build new histograms\n",
    "    SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "    SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "    Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "    Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "    ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "    SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "    Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "    for jj in range(len(SF_pos_hist)):\n",
    "        if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            SF_ratio[jj] = 1\n",
    "    for jj in range(len(Q_pos_hist)):\n",
    "        if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "            Q_ratio[jj] = 1\n",
    "    #\n",
    "    ## compute variance of SF/Q ratios from 1\n",
    "    SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    total_var = SF_var + Q_var\n",
    "    #\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "#\n",
    "#\n",
    "#\n",
    "### METHOD 3: ASYMMETRIC BINS for bins with ~EQUAL AMOUNTS OF MASS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "#\n",
    "method = 3\n",
    "#\n",
    "## \n",
    "for number in range(len(num_bins_to_try)):\n",
    "    SF_pos_sum_index = np.ceil(np.sum(SF_pos)/num_bins_to_try[number]) \n",
    "    SF_neg_sum_index = np.ceil(np.sum(SF_neg)/num_bins_to_try[number])\n",
    "    Q_pos_sum_index = np.ceil(np.sum(Q_pos)/num_bins_to_try[number])\n",
    "    Q_neg_sum_index = np.ceil(np.sum(Q_neg)/num_bins_to_try[number])\n",
    "    ## build arrays over range [7.3,12.3] with num_bins_to_try[number] bins, where each bin has ~equal amounts of mass in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "    num_bins_SF_index = [[],[]]     # [pos, neg]\n",
    "    num_bins_Q_index = [[],[]]     # [pos, neg]\n",
    "    # look through SF/Q false pos/neg lists one galaxy at a time, summing their mass until you reach the amount stored in *_sum_index (e.g. SF_pos_sum_index for SF_pos list), then record that index as a bin edge\n",
    "    #num_bins_SF[0].append(SF_pos[0])\n",
    "    ## SF_posfor ii in range(num_bins_to_try[number]):\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(SF_pos)):\n",
    "            mass_sum = mass_sum + SF_pos[jj]\n",
    "            if mass_sum >= ii*SF_pos_sum_index:\n",
    "                #print('\\nSF_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_pos_sum_index),'jj: %s'%jj)\n",
    "                num_bins_SF_index[0].append(jj)\n",
    "                break\n",
    "    ## SF_neg\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(SF_neg)):\n",
    "            mass_sum = mass_sum + SF_neg[jj]\n",
    "            if mass_sum >= ii*SF_neg_sum_index:\n",
    "                #print('\\nSF_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_neg_sum_index),'jj: %s'%jj)\n",
    "                num_bins_SF_index[1].append(jj)\n",
    "                break\n",
    "    ## Q_pos\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(Q_pos)):\n",
    "            mass_sum = mass_sum + Q_pos[jj]\n",
    "            if mass_sum >= ii*Q_pos_sum_index:\n",
    "                #print('\\nQ_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_pos_sum_index),'jj: %s'%jj)\n",
    "                num_bins_Q_index[0].append(jj)\n",
    "                break\n",
    "    ## Q_neg\n",
    "    for ii in range(num_bins_to_try[number]):\n",
    "        mass_sum = 0\n",
    "        for jj in range(len(Q_neg)):\n",
    "            mass_sum = mass_sum + Q_neg[jj]\n",
    "            if mass_sum >= ii*Q_neg_sum_index:\n",
    "                #print('\\nQ_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_neg_sum_index),'jj: %s'%jj)\n",
    "                num_bins_Q_index[1].append(jj)\n",
    "                break\n",
    "    #\n",
    "    ## add last (highest-mass) bin edge\n",
    "    num_bins_SF_index[0].append(len(SF_pos)-1)\n",
    "    num_bins_SF_index[1].append(len(SF_neg)-1)\n",
    "    num_bins_Q_index[0].append(len(Q_pos)-1)\n",
    "    num_bins_Q_index[1].append(len(Q_neg)-1)\n",
    "    ## convert to arrays\n",
    "    num_bins_SF_index = np.array(num_bins_SF_index)\n",
    "    num_bins_Q_index = np.array(num_bins_Q_index)\n",
    "    #print('# bins: %s'%(num_bins_to_try[number]-1))\n",
    "    #print('length of num_bins_* array: %s'%len(num_bins_SF_index[0]),'\\nlength of SF array: %s'%len(SF_pos),'\\nlength of Q array: %s'%len(Q_pos))\n",
    "    #print('indices corresponding to bin edges\\nSF: %s'%num_bins_SF_index,'\\nQ: %s'%num_bins_Q_index)\n",
    "    #\n",
    "    ## convert to arrays\n",
    "    num_bins_SF = np.empty_like(num_bins_SF_index,dtype='float32')\n",
    "    num_bins_Q = np.empty_like(num_bins_Q_index,dtype='float32')\n",
    "    #\n",
    "    ## SF: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "    # \n",
    "    try:\n",
    "        for ii in range(len(num_bins_SF[0])):\n",
    "            num_bins_SF[0][ii] = SF_pos[num_bins_SF_index[0][ii]]\n",
    "            num_bins_SF[1][ii] = SF_neg[num_bins_SF_index[1][ii]]\n",
    "        #\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        num_bins_SF[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        num_bins_SF[1][0] = range2[0]\n",
    "        num_bins_SF[0][-1] = range2[-1] \n",
    "        num_bins_SF[1][-1] = range2[-1]\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "        #\n",
    "        ## build new histograms\n",
    "        SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "        SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "        for jj in range(len(SF_pos_hist)):\n",
    "            if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                SF_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        SF_var = np.sum((1 - SF_ratio)**2)\n",
    "    except:\n",
    "        print('# bins exceeds length of SF false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "        SF_ratio = 'n/a'\n",
    "        SF_var = 'n/a'\n",
    "    \n",
    "    ## Q: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "    try:\n",
    "        for ii in range(len(num_bins_Q[0])):\n",
    "            num_bins_Q[0][ii] = Q_pos[num_bins_Q_index[0][ii]]\n",
    "            num_bins_Q[1][ii] = Q_neg[num_bins_Q_index[1][ii]]\n",
    "        #\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        num_bins_Q[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        num_bins_Q[1][0] = range2[0]\n",
    "        num_bins_Q[0][-1] = range2[-1]\n",
    "        num_bins_Q[1][-1] = range2[-1]\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "        #\n",
    "        ## build new histograms\n",
    "        Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "        Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "        for jj in range(len(Q_pos_hist)):\n",
    "            if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                Q_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        Q_var = np.sum((1 - Q_ratio)**2)\n",
    "    except:\n",
    "        print('# bins exceeds length of Q false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "        Q_ratio = 'n/a'\n",
    "        Q_var = 'n/a'\n",
    "    #\n",
    "    if SF_ratio == 'n/a':\n",
    "        total_var = Q_var\n",
    "    elif Q_ratio == 'n/a':\n",
    "        total_var = SF_var\n",
    "    else: \n",
    "        total_var = np.round((SF_var + Q_var),decimals=3)\n",
    "        SF_var = np.round(SF_var,decimals=3)\n",
    "        Q_var = np.round(Q_var,decimals=3)\n",
    "    #\n",
    "    ## prepare what to write to file\n",
    "    bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%SF_var+space+'%s'%total_var\n",
    "    bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%Q_var+space+'%s'%total_var\n",
    "    writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "    f.write(writer)\n",
    "    #\n",
    "#\n",
    "#\n",
    "## close the file       \n",
    "f.close()\n",
    "#\n",
    "#\n",
    "#\n",
    "## TIME_FLAG END\n",
    "#\n",
    "if time_flag == 1:\n",
    "    print('Program \"spec_completeness_binning.py\" took: %s seconds to run.\\n\\n' % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#                      \n",
    "###### PROGRAM END ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SECTION (3.2): calculate SPECTROSCOPIC COMPLETENESS correction. basically, look at all the false positives/false negatives, and sort them by type (i.e. SF/Q). then bin them (i.e. make histograms of false pos/neg for each of SF/Q). take their ratio of false pos to false neg, and plot that ratio. it is the correction factor to be applied to the photometric subsample\n",
    "#\n",
    "#####\n",
    "def binning(z_cutoff):\n",
    "#####\n",
    "    #\n",
    "    ## TIME_FLAG: START\n",
    "    ## superior time_flag which supercedes all others and times the entire program\n",
    "    time_flag = 1     # track & print time to execute current section\n",
    "    #\n",
    "    if time_flag == 1:\n",
    "        start_time = time.time()\n",
    "    #\n",
    "    #\n",
    "    ## MODULES\n",
    "    import numpy as np\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    import astropy\n",
    "    from astropy.table import Table\n",
    "    from astropy.table import Column\n",
    "    import time\n",
    "    #\n",
    "    ##\n",
    "    limiting_mass = [7.5,7.8,8.0,7.5,7.4,7.3] # clusters 1,2,3,4,5,6, see IDs below\n",
    "    range2 = [7.3,12.3]\n",
    "    #\n",
    "    SF_pos = []\n",
    "    SF_neg = []\n",
    "    Q_pos = []\n",
    "    Q_neg = []\n",
    "    pos_by_cluster = np.array([[0]*6]*2)    #for tracking false pos/neg by cluster; row_1=SF, row_2=Q\n",
    "    neg_by_cluster = np.array([[0]*6]*2)\n",
    "    objects_below_lim_mass = np.array([0]*6)    # for tracking objects below the limiting mass of each cluster\n",
    "    #\n",
    "    for counter in range(len(master_cat)):\n",
    "        for ii in range(len(limiting_mass)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):           # only look at objects above the limiting mass for each cluster\n",
    "                if master_cat['lmass'][counter] > limiting_mass[ii]:      \n",
    "                    if master_cat['type'][counter] == 1:      # type=1 for SF\n",
    "                        if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                            SF_pos.append(master_cat['lmass'][counter])\n",
    "                            for ii in range(len(pos_by_cluster[0])):\n",
    "                                if master_cat['cluster'][ii] == (ii+1):\n",
    "                                    pos_by_cluster[0]+=1           # track false pos for SF\n",
    "                        elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                            SF_neg.append(master_cat['lmass'][counter])\n",
    "                            for ii in range(len(pos_by_cluster[0])):\n",
    "                                if master_cat['cluster'][ii] == (ii+1):\n",
    "                                    neg_by_cluster[0]+=1           # track false neg for SF\n",
    "                    elif master_cat['type'][counter] == 2:     # type=2 for Q\n",
    "                        if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                            Q_pos.append(master_cat['lmass'][counter])\n",
    "                            for ii in range(len(pos_by_cluster[1])):\n",
    "                                if master_cat['cluster'][ii] == (ii+1):\n",
    "                                    pos_by_cluster[1]+=1           # track false pos for Q\n",
    "                        elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                            Q_neg.append(master_cat['lmass'][counter])\n",
    "                            for ii in range(len(neg_by_cluster[1])):\n",
    "                                if master_cat['cluster'][ii] == (ii+1):\n",
    "                                    neg_by_cluster[1]+=1           # track false neg for Q\n",
    "                else: \n",
    "                    objects_below_lim_mass[ii]+=1\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ## sort false pos/neg lists in ascending order\n",
    "    SF_pos = np.sort(SF_pos)\n",
    "    SF_neg = np.sort(SF_neg)\n",
    "    Q_pos = np.sort(Q_pos)\n",
    "    Q_neg = np.sort(Q_neg)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ## open a file to print to\n",
    "    f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/binning_%s'%z_cutoff[0]+'_spec_cutoff_%s'%z_cutoff[1]+'_phot_cutoff.txt','w+')\n",
    "    #\n",
    "    ## to be used in building strings throughout program\n",
    "    space = ' '   \n",
    "    ## write a header for the file, start with hashtag to identify comment\n",
    "    header1 = \"### COLS:\\n###(1)z_spec_cutoff  (2)z_phot_cutoff  (3)type[SF/Q]  (4)binning_method  (5)#_of_bins variance[SF/Q]  (6)total_variance[SF+Q]\\n\"\n",
    "    #\n",
    "    f.write(header1)\n",
    "    #\n",
    "    #\n",
    "    # SPEC. BINNING: iterate through different number of histogram bins to see which yields a set of corrections closest in general to ~1; this has now been expanded to test: method = 1, SYMMETRIC binning; method = 2, ASYMMETRIC binning, EQUAL NUMBER of objects in each bin; method = 2, ASYMMETRIC binning, equal MASS in each bin;\n",
    "    #\n",
    "    #\n",
    "    ### METHOD 1: bin SF & Q in SYMMETRIC BINS, then compute false pos/neg fractions by mass bin for correction factors. \n",
    "    #\n",
    "    ## number of histogram mass bins to try for spec. completeness correction\n",
    "    num_bins_to_try = [2,3,4,5,6,7,8]   \n",
    "    # write a loop that interatively uses a different number of bins in the histrogram, to isolate the largest number for which all bins have at least one entry; NOTE: the lines that stop the loop have been commented out, to investigate the relative fraction of false pos/neg for each different # of bins\n",
    "    #\n",
    "    # \n",
    "    method = 1\n",
    "    for number in range(len(num_bins_to_try)):\n",
    "        #\n",
    "        # make histograms\n",
    "        SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=num_bins_to_try[number], range=range2)\n",
    "        SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=num_bins_to_try[number], range=range2)\n",
    "        Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=num_bins_to_try[number], range=range2)\n",
    "        Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=num_bins_to_try[number], range=range2)\n",
    "        #\n",
    "        SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "        Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "        for jj in range(len(SF_pos_hist)):\n",
    "            if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                SF_ratio[jj] = 1\n",
    "        for jj in range(len(Q_pos_hist)):\n",
    "            if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                Q_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        SF_var = np.sum((1 - SF_ratio)**2)\n",
    "        Q_var = np.sum((1 - Q_ratio)**2)\n",
    "        total_var = SF_var + Q_var\n",
    "        ## prepare what to write to file\n",
    "        bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "        bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "        writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "        f.write(writer)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ### METHOD 2: ASYMMETRIC BINS for bins with ~EQUAL NUMBER OF OBJECTS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "    #\n",
    "    method = 2\n",
    "    #\n",
    "    ##\n",
    "    for number in range(len(num_bins_to_try)):    #number of bin EDGES (i.e. # of bins + 1)\n",
    "        ## compute the index corresponding to the first evenly-space bin edge\n",
    "        SF_pos_index = int(np.ceil(len(SF_pos))/(num_bins_to_try[number]))\n",
    "        SF_neg_index = int(np.ceil(len(SF_neg))/(num_bins_to_try[number]))\n",
    "        Q_pos_index = int(np.ceil(len(Q_pos))/(num_bins_to_try[number]))\n",
    "        Q_neg_index = int(np.ceil(len(Q_neg))/(num_bins_to_try[number]))\n",
    "        ## build arrays over range [7.3,12.3] with \"num_bins_to_try[number]\" bins, where each bin has ~equal # of objects in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "        num_bins_SF = [[],[]]     # [pos, neg]  i.e. bin edges of mass bins\n",
    "        num_bins_Q = [[],[]]     # [pos, neg]\n",
    "        #a=0\n",
    "        #b=0\n",
    "        for ii in range(num_bins_to_try[number]):   # -1 b/c there are 1 fewer bins than bin edges\n",
    "            num_bins_SF[0].append(SF_pos[(ii*SF_pos_index)])\n",
    "            num_bins_SF[1].append(SF_neg[(ii*SF_neg_index)])\n",
    "            num_bins_Q[0].append(Q_pos[(ii*Q_pos_index)])\n",
    "            num_bins_Q[1].append(Q_neg[(ii*Q_neg_index)])\n",
    "        #\n",
    "        num_bins_SF[0].append(SF_pos[-1])\n",
    "        num_bins_SF[1].append(SF_neg[-1])\n",
    "        num_bins_Q[0].append(Q_pos[-1])\n",
    "        num_bins_Q[1].append(Q_neg[-1])\n",
    "        #\n",
    "        num_bins_SF = np.array(num_bins_SF)\n",
    "        num_bins_Q = np.array(num_bins_Q)\n",
    "        #print('# bins: %s'%(num_bins_to_try[number]))\n",
    "        #print('length of num_bins_* array (which stores bin edges): %s'%len(num_bins_SF[0]))\n",
    "        #print(('num_bins_SF: %s'%num_bins_SF)\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "        bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        bin_edge_means_SF[0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        bin_edge_means_SF[-1] = range2[-1]\n",
    "        bin_edge_means_Q[0] = range2[0]\n",
    "        bin_edge_means_Q[-1] = range2[-1]\n",
    "        #print('length of bin_edge_means_* array: %s'%len(bin_edge_means_SF))\n",
    "        #print('bin_edge_means_SF: %s'%bin_edge_means_SF)\n",
    "        ## build new histograms\n",
    "        SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "        SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "        Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "        Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "        Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "        for jj in range(len(SF_pos_hist)):\n",
    "            if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                SF_ratio[jj] = 1\n",
    "        for jj in range(len(Q_pos_hist)):\n",
    "            if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                Q_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        SF_var = np.sum((1 - SF_ratio)**2)\n",
    "        Q_var = np.sum((1 - Q_ratio)**2)\n",
    "        total_var = SF_var + Q_var\n",
    "        #\n",
    "        ## prepare what to write to file\n",
    "        bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "        bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "        writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "        f.write(writer)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ### METHOD 3: ASYMMETRIC BINS for bins with ~EQUAL AMOUNTS OF MASS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "    #\n",
    "    method = 3\n",
    "    #\n",
    "    ## \n",
    "    for number in range(len(num_bins_to_try)):\n",
    "        SF_pos_sum_index = np.ceil(np.sum(SF_pos)/num_bins_to_try[number]) \n",
    "        SF_neg_sum_index = np.ceil(np.sum(SF_neg)/num_bins_to_try[number])\n",
    "        Q_pos_sum_index = np.ceil(np.sum(Q_pos)/num_bins_to_try[number])\n",
    "        Q_neg_sum_index = np.ceil(np.sum(Q_neg)/num_bins_to_try[number])\n",
    "        ## build arrays over range [7.3,12.3] with num_bins_to_try[number] bins, where each bin has ~equal amounts of mass in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "        num_bins_SF_index = [[],[]]     # [pos, neg]\n",
    "        num_bins_Q_index = [[],[]]     # [pos, neg]\n",
    "        # look through SF/Q false pos/neg lists one galaxy at a time, summing their mass until you reach the amount stored in *_sum_index (e.g. SF_pos_sum_index for SF_pos list), then record that index as a bin edge\n",
    "        #num_bins_SF[0].append(SF_pos[0])\n",
    "        ## SF_posfor ii in range(num_bins_to_try[number]):\n",
    "        for ii in range(num_bins_to_try[number]):\n",
    "            mass_sum = 0\n",
    "            for jj in range(len(SF_pos)):\n",
    "                mass_sum = mass_sum + SF_pos[jj]\n",
    "                if mass_sum >= ii*SF_pos_sum_index:\n",
    "                    #print('\\nSF_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_pos_sum_index),'jj: %s'%jj)\n",
    "                    num_bins_SF_index[0].append(jj)\n",
    "                    break\n",
    "        ## SF_neg\n",
    "        for ii in range(num_bins_to_try[number]):\n",
    "            mass_sum = 0\n",
    "            for jj in range(len(SF_neg)):\n",
    "                mass_sum = mass_sum + SF_neg[jj]\n",
    "                if mass_sum >= ii*SF_neg_sum_index:\n",
    "                    #print('\\nSF_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_neg_sum_index),'jj: %s'%jj)\n",
    "                    num_bins_SF_index[1].append(jj)\n",
    "                    break\n",
    "        ## Q_pos\n",
    "        for ii in range(num_bins_to_try[number]):\n",
    "            mass_sum = 0\n",
    "            for jj in range(len(Q_pos)):\n",
    "                mass_sum = mass_sum + Q_pos[jj]\n",
    "                if mass_sum >= ii*Q_pos_sum_index:\n",
    "                    #print('\\nQ_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_pos_sum_index),'jj: %s'%jj)\n",
    "                    num_bins_Q_index[0].append(jj)\n",
    "                    break\n",
    "        ## Q_neg\n",
    "        for ii in range(num_bins_to_try[number]):\n",
    "            mass_sum = 0\n",
    "            for jj in range(len(Q_neg)):\n",
    "                mass_sum = mass_sum + Q_neg[jj]\n",
    "                if mass_sum >= ii*Q_neg_sum_index:\n",
    "                    #print('\\nQ_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_neg_sum_index),'jj: %s'%jj)\n",
    "                    num_bins_Q_index[1].append(jj)\n",
    "                    break\n",
    "        #\n",
    "        ## add last (highest-mass) bin edge\n",
    "        num_bins_SF_index[0].append(len(SF_pos)-1)\n",
    "        num_bins_SF_index[1].append(len(SF_neg)-1)\n",
    "        num_bins_Q_index[0].append(len(Q_pos)-1)\n",
    "        num_bins_Q_index[1].append(len(Q_neg)-1)\n",
    "        ## convert to arrays\n",
    "        num_bins_SF_index = np.array(num_bins_SF_index)\n",
    "        num_bins_Q_index = np.array(num_bins_Q_index)\n",
    "        #print('# bins: %s'%(num_bins_to_try[number]-1))\n",
    "        #print('length of num_bins_* array: %s'%len(num_bins_SF_index[0]),'\\nlength of SF array: %s'%len(SF_pos),'\\nlength of Q array: %s'%len(Q_pos))\n",
    "        #print('indices corresponding to bin edges\\nSF: %s'%num_bins_SF_index,'\\nQ: %s'%num_bins_Q_index)\n",
    "        #\n",
    "        ## convert to arrays\n",
    "        num_bins_SF = np.empty_like(num_bins_SF_index,dtype='float32')\n",
    "        num_bins_Q = np.empty_like(num_bins_Q_index,dtype='float32')\n",
    "        #\n",
    "        ## SF: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "        # \n",
    "        try:\n",
    "            for ii in range(len(num_bins_SF[0])):\n",
    "                num_bins_SF[0][ii] = SF_pos[num_bins_SF_index[0][ii]]\n",
    "                num_bins_SF[1][ii] = SF_neg[num_bins_SF_index[1][ii]]\n",
    "            #\n",
    "            ## set first/last entry as limits of mass range for smf\n",
    "            num_bins_SF[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "            num_bins_SF[1][0] = range2[0]\n",
    "            num_bins_SF[0][-1] = range2[-1] \n",
    "            num_bins_SF[1][-1] = range2[-1]\n",
    "            #\n",
    "            ## compute midpoints between false pos/neg bin edges\n",
    "            bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "            #\n",
    "            ## build new histograms\n",
    "            SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "            SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "            ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "            SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "            for jj in range(len(SF_pos_hist)):\n",
    "                if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                    SF_ratio[jj] = 1\n",
    "            #\n",
    "            ## compute variance of SF/Q ratios from 1\n",
    "            SF_var = np.sum((1 - SF_ratio)**2)\n",
    "        except:\n",
    "            print('# bins exceeds length of SF false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "            SF_ratio = 'n/a'\n",
    "            SF_var = 'n/a'\n",
    "\n",
    "        ## Q: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "        try:\n",
    "            for ii in range(len(num_bins_Q[0])):\n",
    "                num_bins_Q[0][ii] = Q_pos[num_bins_Q_index[0][ii]]\n",
    "                num_bins_Q[1][ii] = Q_neg[num_bins_Q_index[1][ii]]\n",
    "            #\n",
    "            ## set first/last entry as limits of mass range for smf\n",
    "            num_bins_Q[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "            num_bins_Q[1][0] = range2[0]\n",
    "            num_bins_Q[0][-1] = range2[-1]\n",
    "            num_bins_Q[1][-1] = range2[-1]\n",
    "            #\n",
    "            ## compute midpoints between false pos/neg bin edges\n",
    "            bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "            #\n",
    "            ## build new histograms\n",
    "            Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "            Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "            ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "            Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "            for jj in range(len(Q_pos_hist)):\n",
    "                if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                    Q_ratio[jj] = 1\n",
    "            #\n",
    "            ## compute variance of SF/Q ratios from 1\n",
    "            Q_var = np.sum((1 - Q_ratio)**2)\n",
    "        except:\n",
    "            print('# bins exceeds length of Q false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "            Q_ratio = 'n/a'\n",
    "            Q_var = 'n/a'\n",
    "        #\n",
    "        if SF_ratio == 'n/a':\n",
    "            total_var = Q_var\n",
    "        elif Q_ratio == 'n/a':\n",
    "            total_var = SF_var\n",
    "        else: \n",
    "            total_var = np.round((SF_var + Q_var),decimals=3)\n",
    "            SF_var = np.round(SF_var,decimals=3)\n",
    "            Q_var = np.round(Q_var,decimals=3)\n",
    "        #\n",
    "        ## prepare what to write to file\n",
    "        bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%SF_var+space+'%s'%total_var\n",
    "        bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%Q_var+space+'%s'%total_var\n",
    "        writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "        f.write(writer)\n",
    "        #\n",
    "    #\n",
    "    #\n",
    "    ## close the file       \n",
    "    f.close()\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ## TIME_FLAG END\n",
    "    #\n",
    "    if time_flag == 1:\n",
    "        print('Program \"spec_completeness_binning.py\" for z_spec < %s'%z_cutoff[0],' and z_phot < %s'%z_cutoff[1],' took: %s seconds to run.\\n\\n' % (time.time() - start_time))\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "#\n",
    "#                      \n",
    "###### PROGRAM END ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.015, 0.08]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_cutoff = [0.02,0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'time' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c22d0a543f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-ac9fe2eb4b9a>\u001b[0m in \u001b[0;36mbinning\u001b[0;34m(z_cutoff)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtime_flag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'time' referenced before assignment"
     ]
    }
   ],
   "source": [
    "binning(z_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SECTION (3.2): calculate SPECTROSCOPIC COMPLETENESS correction. basically, look at all the false positives/false negatives, and sort them by type (i.e. SF/Q). then bin them (i.e. make histograms of false pos/neg for each of SF/Q). take their ratio of false pos to false neg, and plot that ratio. it is the correction factor to be applied to the photometric subsample\n",
    "#\n",
    "#####\n",
    "def binning(z_cutoff):\n",
    "#####\n",
    "    #\n",
    "    #\n",
    "    ## MODULES\n",
    "    import numpy as np\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    import astropy\n",
    "    from astropy.table import Table\n",
    "    from astropy.table import Column\n",
    "    import time\n",
    "    #\n",
    "    #\n",
    "    ## TIME_FLAG: START\n",
    "    ## superior time_flag which supercedes all others and times the entire program\n",
    "    time_flag = 1     # track & print time to execute current section\n",
    "    #\n",
    "    if time_flag == 1:\n",
    "        start_time = time.time()\n",
    "    #\n",
    "    ##\n",
    "    limiting_mass = [7.5,7.8,8.0,7.5,7.4,7.3] # clusters 1,2,3,4,5,6, see IDs below\n",
    "    range2 = [7.3,12.3]\n",
    "    #\n",
    "    SF_pos = []\n",
    "    SF_neg = []\n",
    "    Q_pos = []\n",
    "    Q_neg = []\n",
    "    pos_by_cluster = np.array([[0]*6]*2)    #for tracking false pos/neg by cluster; row_1=SF, row_2=Q\n",
    "    neg_by_cluster = np.array([[0]*6]*2)\n",
    "    objects_below_lim_mass = np.array([0]*6)    # for tracking objects below the limiting mass of each cluster\n",
    "    #\n",
    "    for counter in range(len(master_cat)):\n",
    "        for ii in range(len(limiting_mass)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):           # only look at objects above the limiting mass for each cluster\n",
    "                if master_cat['lmass'][counter] > limiting_mass[ii]:      \n",
    "                    if master_cat['type'][counter] == 1:      # type=1 for SF\n",
    "                        if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                            SF_pos.append(master_cat['lmass'][counter])\n",
    "                            for ii in range(len(pos_by_cluster[0])):\n",
    "                                if master_cat['cluster'][ii] == (ii+1):\n",
    "                                    pos_by_cluster[0]+=1           # track false pos for SF\n",
    "                        elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                            SF_neg.append(master_cat['lmass'][counter])\n",
    "                            for ii in range(len(pos_by_cluster[0])):\n",
    "                                if master_cat['cluster'][ii] == (ii+1):\n",
    "                                    neg_by_cluster[0]+=1           # track false neg for SF\n",
    "                    elif master_cat['type'][counter] == 2:     # type=2 for Q\n",
    "                        if master_cat['member'][counter] == 2:     # member=2 for false pos\n",
    "                            Q_pos.append(master_cat['lmass'][counter])\n",
    "                            for ii in range(len(pos_by_cluster[1])):\n",
    "                                if master_cat['cluster'][ii] == (ii+1):\n",
    "                                    pos_by_cluster[1]+=1           # track false pos for Q\n",
    "                        elif master_cat['member'][counter] == 3:   # member=3 for false neg\n",
    "                            Q_neg.append(master_cat['lmass'][counter])\n",
    "                            for ii in range(len(neg_by_cluster[1])):\n",
    "                                if master_cat['cluster'][ii] == (ii+1):\n",
    "                                    neg_by_cluster[1]+=1           # track false neg for Q\n",
    "                else: \n",
    "                    objects_below_lim_mass[ii]+=1\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ## sort false pos/neg lists in ascending order\n",
    "    SF_pos = np.sort(SF_pos)\n",
    "    SF_neg = np.sort(SF_neg)\n",
    "    Q_pos = np.sort(Q_pos)\n",
    "    Q_neg = np.sort(Q_neg)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ## open a file to print to\n",
    "    f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/binning_%s'%z_cutoff[0]+'_spec_cutoff_%s'%z_cutoff[1]+'_phot_cutoff.txt','w+')\n",
    "    #\n",
    "    ## to be used in building strings throughout program\n",
    "    space = ' '   \n",
    "    ## write a header for the file, start with hashtag to identify comment\n",
    "    header1 = \"### COLS:\\n###(1)z_spec_cutoff  (2)z_phot_cutoff  (3)type[SF/Q]  (4)binning_method  (5)#_of_bins variance[SF/Q]  (6)total_variance[SF+Q]\\n\"\n",
    "    #\n",
    "    f.write(header1)\n",
    "    #\n",
    "    #\n",
    "    # SPEC. BINNING: iterate through different number of histogram bins to see which yields a set of corrections closest in general to ~1; this has now been expanded to test: method = 1, SYMMETRIC binning; method = 2, ASYMMETRIC binning, EQUAL NUMBER of objects in each bin; method = 2, ASYMMETRIC binning, equal MASS in each bin;\n",
    "    #\n",
    "    #\n",
    "    ### METHOD 1: bin SF & Q in SYMMETRIC BINS, then compute false pos/neg fractions by mass bin for correction factors. \n",
    "    #\n",
    "    ## number of histogram mass bins to try for spec. completeness correction\n",
    "    num_bins_to_try = [2,3,4,5,6,7,8]   \n",
    "    # write a loop that interatively uses a different number of bins in the histrogram, to isolate the largest number for which all bins have at least one entry; NOTE: the lines that stop the loop have been commented out, to investigate the relative fraction of false pos/neg for each different # of bins\n",
    "    #\n",
    "    # \n",
    "    method = 1\n",
    "    for number in range(len(num_bins_to_try)):\n",
    "        #\n",
    "        # make histograms\n",
    "        SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=num_bins_to_try[number], range=range2)\n",
    "        SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=num_bins_to_try[number], range=range2)\n",
    "        Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=num_bins_to_try[number], range=range2)\n",
    "        Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=num_bins_to_try[number], range=range2)\n",
    "        #\n",
    "        SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "        Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "        for jj in range(len(SF_pos_hist)):\n",
    "            if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                SF_ratio[jj] = 1\n",
    "        for jj in range(len(Q_pos_hist)):\n",
    "            if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                Q_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        SF_var = np.sum((1 - SF_ratio)**2)\n",
    "        Q_var = np.sum((1 - Q_ratio)**2)\n",
    "        total_var = SF_var + Q_var\n",
    "        ## prepare what to write to file\n",
    "        bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "        bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "        writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "        f.write(writer)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ### METHOD 2: ASYMMETRIC BINS for bins with ~EQUAL NUMBER OF OBJECTS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "    #\n",
    "    method = 2\n",
    "    #\n",
    "    ##\n",
    "    for number in range(len(num_bins_to_try)):    #number of bin EDGES (i.e. # of bins + 1)\n",
    "        ## compute the index corresponding to the first evenly-space bin edge\n",
    "        SF_pos_index = int(np.ceil(len(SF_pos))/(num_bins_to_try[number]))\n",
    "        SF_neg_index = int(np.ceil(len(SF_neg))/(num_bins_to_try[number]))\n",
    "        Q_pos_index = int(np.ceil(len(Q_pos))/(num_bins_to_try[number]))\n",
    "        Q_neg_index = int(np.ceil(len(Q_neg))/(num_bins_to_try[number]))\n",
    "        ## build arrays over range [7.3,12.3] with \"num_bins_to_try[number]\" bins, where each bin has ~equal # of objects in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "        num_bins_SF = [[],[]]     # [pos, neg]  i.e. bin edges of mass bins\n",
    "        num_bins_Q = [[],[]]     # [pos, neg]\n",
    "        #a=0\n",
    "        #b=0\n",
    "        for ii in range(num_bins_to_try[number]):   # -1 b/c there are 1 fewer bins than bin edges\n",
    "            num_bins_SF[0].append(SF_pos[(ii*SF_pos_index)])\n",
    "            num_bins_SF[1].append(SF_neg[(ii*SF_neg_index)])\n",
    "            num_bins_Q[0].append(Q_pos[(ii*Q_pos_index)])\n",
    "            num_bins_Q[1].append(Q_neg[(ii*Q_neg_index)])\n",
    "        #\n",
    "        num_bins_SF[0].append(SF_pos[-1])\n",
    "        num_bins_SF[1].append(SF_neg[-1])\n",
    "        num_bins_Q[0].append(Q_pos[-1])\n",
    "        num_bins_Q[1].append(Q_neg[-1])\n",
    "        #\n",
    "        num_bins_SF = np.array(num_bins_SF)\n",
    "        num_bins_Q = np.array(num_bins_Q)\n",
    "        #print('# bins: %s'%(num_bins_to_try[number]))\n",
    "        #print('length of num_bins_* array (which stores bin edges): %s'%len(num_bins_SF[0]))\n",
    "        #print(('num_bins_SF: %s'%num_bins_SF)\n",
    "        #\n",
    "        ## compute midpoints between false pos/neg bin edges\n",
    "        bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "        bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "        ## set first/last entry as limits of mass range for smf\n",
    "        bin_edge_means_SF[0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "        bin_edge_means_SF[-1] = range2[-1]\n",
    "        bin_edge_means_Q[0] = range2[0]\n",
    "        bin_edge_means_Q[-1] = range2[-1]\n",
    "        #print('length of bin_edge_means_* array: %s'%len(bin_edge_means_SF))\n",
    "        #print('bin_edge_means_SF: %s'%bin_edge_means_SF)\n",
    "        ## build new histograms\n",
    "        SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "        SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "        Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "        Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "        ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "        SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "        Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "        for jj in range(len(SF_pos_hist)):\n",
    "            if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                SF_ratio[jj] = 1\n",
    "        for jj in range(len(Q_pos_hist)):\n",
    "            if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                Q_ratio[jj] = 1\n",
    "        #\n",
    "        ## compute variance of SF/Q ratios from 1\n",
    "        SF_var = np.sum((1 - SF_ratio)**2)\n",
    "        Q_var = np.sum((1 - Q_ratio)**2)\n",
    "        total_var = SF_var + Q_var\n",
    "        #\n",
    "        ## prepare what to write to file\n",
    "        bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%SF_var+space+'%.3f'%total_var\n",
    "        bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%.3f'%Q_var+space+'%.3f'%total_var\n",
    "        writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "        f.write(writer)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ### METHOD 3: ASYMMETRIC BINS for bins with ~EQUAL AMOUNTS OF MASS in each bin (for each of the SF/Q false pos/neg pairs), return the asymmetric bin edges and compute the midpoints b/w the *_pos/*_neg bin edges. Use these midpoints as the bin edges for a new histogram for the *_pos/*_neg lists, and re-compute the false pos/neg ratio for each of SF/Q. Then print relevant data to a file.\n",
    "    #\n",
    "    method = 3\n",
    "    #\n",
    "    ## \n",
    "    for number in range(len(num_bins_to_try)):\n",
    "        SF_pos_sum_index = np.ceil(np.sum(SF_pos)/num_bins_to_try[number]) \n",
    "        SF_neg_sum_index = np.ceil(np.sum(SF_neg)/num_bins_to_try[number])\n",
    "        Q_pos_sum_index = np.ceil(np.sum(Q_pos)/num_bins_to_try[number])\n",
    "        Q_neg_sum_index = np.ceil(np.sum(Q_neg)/num_bins_to_try[number])\n",
    "        ## build arrays over range [7.3,12.3] with num_bins_to_try[number] bins, where each bin has ~equal amounts of mass in it; then compute the midpoints between the false pos bin edges and the false neg bin edges\n",
    "        num_bins_SF_index = [[],[]]     # [pos, neg]\n",
    "        num_bins_Q_index = [[],[]]     # [pos, neg]\n",
    "        # look through SF/Q false pos/neg lists one galaxy at a time, summing their mass until you reach the amount stored in *_sum_index (e.g. SF_pos_sum_index for SF_pos list), then record that index as a bin edge\n",
    "        #num_bins_SF[0].append(SF_pos[0])\n",
    "        ## SF_posfor ii in range(num_bins_to_try[number]):\n",
    "        for ii in range(num_bins_to_try[number]):\n",
    "            mass_sum = 0\n",
    "            for jj in range(len(SF_pos)):\n",
    "                mass_sum = mass_sum + SF_pos[jj]\n",
    "                if mass_sum >= ii*SF_pos_sum_index:\n",
    "                    #print('\\nSF_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_pos_sum_index),'jj: %s'%jj)\n",
    "                    num_bins_SF_index[0].append(jj)\n",
    "                    break\n",
    "        ## SF_neg\n",
    "        for ii in range(num_bins_to_try[number]):\n",
    "            mass_sum = 0\n",
    "            for jj in range(len(SF_neg)):\n",
    "                mass_sum = mass_sum + SF_neg[jj]\n",
    "                if mass_sum >= ii*SF_neg_sum_index:\n",
    "                    #print('\\nSF_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*SF_neg_sum_index),'jj: %s'%jj)\n",
    "                    num_bins_SF_index[1].append(jj)\n",
    "                    break\n",
    "        ## Q_pos\n",
    "        for ii in range(num_bins_to_try[number]):\n",
    "            mass_sum = 0\n",
    "            for jj in range(len(Q_pos)):\n",
    "                mass_sum = mass_sum + Q_pos[jj]\n",
    "                if mass_sum >= ii*Q_pos_sum_index:\n",
    "                    #print('\\nQ_pos\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_pos_sum_index),'jj: %s'%jj)\n",
    "                    num_bins_Q_index[0].append(jj)\n",
    "                    break\n",
    "        ## Q_neg\n",
    "        for ii in range(num_bins_to_try[number]):\n",
    "            mass_sum = 0\n",
    "            for jj in range(len(Q_neg)):\n",
    "                mass_sum = mass_sum + Q_neg[jj]\n",
    "                if mass_sum >= ii*Q_neg_sum_index:\n",
    "                    #print('\\nQ_neg\\nmass sum : %s'%mass_sum,'\\nmass limit index equals: %s'%(ii*Q_neg_sum_index),'jj: %s'%jj)\n",
    "                    num_bins_Q_index[1].append(jj)\n",
    "                    break\n",
    "        #\n",
    "        ## add last (highest-mass) bin edge\n",
    "        num_bins_SF_index[0].append(len(SF_pos)-1)\n",
    "        num_bins_SF_index[1].append(len(SF_neg)-1)\n",
    "        num_bins_Q_index[0].append(len(Q_pos)-1)\n",
    "        num_bins_Q_index[1].append(len(Q_neg)-1)\n",
    "        ## convert to arrays\n",
    "        num_bins_SF_index = np.array(num_bins_SF_index)\n",
    "        num_bins_Q_index = np.array(num_bins_Q_index)\n",
    "        #print('# bins: %s'%(num_bins_to_try[number]-1))\n",
    "        #print('length of num_bins_* array: %s'%len(num_bins_SF_index[0]),'\\nlength of SF array: %s'%len(SF_pos),'\\nlength of Q array: %s'%len(Q_pos))\n",
    "        #print('indices corresponding to bin edges\\nSF: %s'%num_bins_SF_index,'\\nQ: %s'%num_bins_Q_index)\n",
    "        #\n",
    "        ## convert to arrays\n",
    "        num_bins_SF = np.empty_like(num_bins_SF_index,dtype='float32')\n",
    "        num_bins_Q = np.empty_like(num_bins_Q_index,dtype='float32')\n",
    "        #\n",
    "        ## SF: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "        # \n",
    "        try:\n",
    "            for ii in range(len(num_bins_SF[0])):\n",
    "                num_bins_SF[0][ii] = SF_pos[num_bins_SF_index[0][ii]]\n",
    "                num_bins_SF[1][ii] = SF_neg[num_bins_SF_index[1][ii]]\n",
    "            #\n",
    "            ## set first/last entry as limits of mass range for smf\n",
    "            num_bins_SF[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "            num_bins_SF[1][0] = range2[0]\n",
    "            num_bins_SF[0][-1] = range2[-1] \n",
    "            num_bins_SF[1][-1] = range2[-1]\n",
    "            #\n",
    "            ## compute midpoints between false pos/neg bin edges\n",
    "            bin_edge_means_SF = np.mean(num_bins_SF,axis=0)\n",
    "            #\n",
    "            ## build new histograms\n",
    "            SF_pos_hist, bins_SF = np.histogram(SF_pos, bins=bin_edge_means_SF, range=range2)\n",
    "            SF_neg_hist, bins_SF = np.histogram(SF_neg, bins=bin_edge_means_SF, range=range2)\n",
    "            ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "            SF_ratio = SF_pos_hist / SF_neg_hist\n",
    "            for jj in range(len(SF_pos_hist)):\n",
    "                if SF_pos_hist[jj] == 0 and SF_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                    SF_ratio[jj] = 1\n",
    "            #\n",
    "            ## compute variance of SF/Q ratios from 1\n",
    "            SF_var = np.sum((1 - SF_ratio)**2)\n",
    "        except:\n",
    "            print('# bins exceeds length of SF false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "            SF_ratio = 'n/a'\n",
    "            SF_var = 'n/a'\n",
    "\n",
    "        ## Q: embed in a 'try - except' loop, to handle TypeErrors which arise due to the number of bins being tried exceeding the length of the false pos/neg list\n",
    "        try:\n",
    "            for ii in range(len(num_bins_Q[0])):\n",
    "                num_bins_Q[0][ii] = Q_pos[num_bins_Q_index[0][ii]]\n",
    "                num_bins_Q[1][ii] = Q_neg[num_bins_Q_index[1][ii]]\n",
    "            #\n",
    "            ## set first/last entry as limits of mass range for smf\n",
    "            num_bins_Q[0][0] = range2[0]         # reminder: row [0] = false pos; row [1] = false neg\n",
    "            num_bins_Q[1][0] = range2[0]\n",
    "            num_bins_Q[0][-1] = range2[-1]\n",
    "            num_bins_Q[1][-1] = range2[-1]\n",
    "            #\n",
    "            ## compute midpoints between false pos/neg bin edges\n",
    "            bin_edge_means_Q = np.mean(num_bins_Q,axis=0)\n",
    "            #\n",
    "            ## build new histograms\n",
    "            Q_pos_hist, bins_Q = np.histogram(Q_pos, bins=bin_edge_means_Q, range=range2)\n",
    "            Q_neg_hist, bins_Q = np.histogram(Q_neg, bins=bin_edge_means_Q, range=range2)\n",
    "            ## find ratios, set ratio==1 for bins with no false pos or false neg\n",
    "            Q_ratio = Q_pos_hist / Q_neg_hist\n",
    "            for jj in range(len(Q_pos_hist)):\n",
    "                if Q_pos_hist[jj] == 0 and Q_neg_hist[jj] == 0:      # if both lists = 0 for the same bin, that's fine!\n",
    "                    Q_ratio[jj] = 1\n",
    "            #\n",
    "            ## compute variance of SF/Q ratios from 1\n",
    "            Q_var = np.sum((1 - Q_ratio)**2)\n",
    "        except:\n",
    "            print('# bins exceeds length of Q false pos/neg list for %s bins'%num_bins_to_try[number])\n",
    "            Q_ratio = 'n/a'\n",
    "            Q_var = 'n/a'\n",
    "        #\n",
    "        if SF_ratio == 'n/a':\n",
    "            total_var = Q_var\n",
    "        elif Q_ratio == 'n/a':\n",
    "            total_var = SF_var\n",
    "        else: \n",
    "            total_var = np.round((SF_var + Q_var),decimals=3)\n",
    "            SF_var = np.round(SF_var,decimals=3)\n",
    "            Q_var = np.round(Q_var,decimals=3)\n",
    "        #\n",
    "        ## prepare what to write to file\n",
    "        bin_entry1 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'SF'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%SF_var+space+'%s'%total_var\n",
    "        bin_entry2 = str(z_cutoff[0])+space+str(z_cutoff[1])+space+'Q'+space+str(method)+space+str(num_bins_to_try[number])+space+'%s'%Q_var+space+'%s'%total_var\n",
    "        writer = '%s'%str(bin_entry1)+'\\n'+'%s'%str(bin_entry2)+'\\n'\n",
    "        f.write(writer)\n",
    "        #\n",
    "    #\n",
    "    #\n",
    "    ## close the file       \n",
    "    f.close()\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ## TIME_FLAG END\n",
    "    #\n",
    "    if time_flag == 1:\n",
    "        print('Program \"spec_completeness_binning.py\" for z_spec < %s'%z_cutoff[0],' and z_phot < %s'%z_cutoff[1],' took: %s seconds to run.\\n\\n' % (time.time() - start_time))\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "#\n",
    "#                      \n",
    "###### PROGRAM END ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program \"spec_completeness_binning.py\" for z_spec < 0.02  and z_phot < 0.05  took: 1.0761148929595947 seconds to run.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:106: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:106: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:107: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:107: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:176: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:329: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:331: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:286: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "binning(z_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.02.txt\n"
     ]
    }
   ],
   "source": [
    "print('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.02\n"
     ]
    }
   ],
   "source": [
    "print('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02, 0.05]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#\n",
    "## check it directories to store outputs exist. if not, create them\n",
    "output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]\n",
    "check_folder = os.path.isdir(output_dir)\n",
    "#\n",
    "## If folder doesn't exist, then create it.\n",
    "if not check_folder:\n",
    "    os.makedirs(output_dir)\n",
    "    print(\"created folder : \"+output_dir)\n",
    "else:\n",
    "    print(output_dir, \"folder already exists.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " inf\n"
     ]
    }
   ],
   "source": [
    "Q_var = float('inf')\n",
    "print(space+'%s'%Q_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.02/binning_0.02_spec_cutoff_0.05_phot_cutoff.txt\n"
     ]
    }
   ],
   "source": [
    "print('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_%s'%z_cutoff[0]+'/binning_%s'%z_cutoff[0]+'_spec_cutoff_%s'%z_cutoff[1]+'_phot_cutoff.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 16.51864504814148 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.656925916671753 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.7035019397735596 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 24 10:23:11 2020\n",
    "\n",
    "@author: gsarrouh\n",
    "\"\"\"\n",
    "#### UPDATE 06/24/20 ####\n",
    "## The previous versions of this file all used HFF DR v3.5, a preliminary data release from the summer of 2017. The paper Shipley et al. 2018 (which I reference extensively in my work) corresponds to the finished data release, v3.9. That final, most up-tp-date data release is what is implemented in the following work. \n",
    "#\n",
    "#\n",
    "### WHAT THIS PROGRAM DOES:\n",
    "### This script reads in all data for the Hubble Frontier Fields images and prepares data for plotting and analysis. Key information is summarized in the tables: \n",
    "###     **\"sub_stats\",\"type_stats\",\"SF_spec_stats\",\"Q_spec_stats\",\"SF_phot_stats\",\"Q_phot_stats\"**\n",
    "#\n",
    "### Data is organized in a single catalogue (\"master_cat\"), and objects are identified through applying a series of \"FILTERS\" to designate key populations using a numerical designation for ease of writing code.\n",
    "#\n",
    "#\n",
    "## FILTER 1 - 'cluster':  cluster catalogues are designated as follows: \n",
    "## 1: macs0416\n",
    "## 2: macs1149\n",
    "## 3: macs0717\n",
    "## 4: abell370\n",
    "## 5: abell1063\n",
    "## 6: abell2744\n",
    "#\n",
    "## FILTER 2 - 'sub': :   identifies sub-type of data each object has\n",
    "## 0: no data (no photometry or spectroscopy)\n",
    "## 1: spectroscopy & photometry\n",
    "## 2: photometry only \n",
    "## 3: spectroscopy only  (there's just 3 in macs0717) \n",
    "## 4: star\n",
    "#\n",
    "## FILTER 3 - 'type': :   identifies type of data each object has\n",
    "## 0: star\n",
    "## 1: star-forming (SF)\n",
    "## 2: quiescent (Q)  \n",
    "## 3: outliers (defined as |del_z\\ > 0.15)\n",
    "#\n",
    "## FILTER 4 - 'member': :   identifies type of data each object has\n",
    "## NOTE: this designation is for objects with phot only (sub =2) and spec&phot (sub=1) only, as membership determinaion requires a good 'z_phot' estimate. as such, member=2 & =3 are for spec&phot (sub=1) subsample only, as only they can be classified as false pos/neg\n",
    "## 0: secure cluster member\n",
    "## 1: secure field    <-- this comprises the sample of field galaxies to be \n",
    "##                        compared with cluster, at similar redshifts\n",
    "## 2: false positive\n",
    "## 3: false negative\n",
    "## 4: field outlier   <-- objects well outside the redshift range of the clusters (e.g. z > 0.55)\n",
    "## 5: BCGs            <-- identified in the last section of the program, over-writing MEMBER assignment from section 4\n",
    "#\n",
    "#\n",
    "#\n",
    "### Section summary:\n",
    "#\n",
    "### PROGRAM START\n",
    "#\n",
    "### (1) import data into single table, creating KEY TABLE: \"master_cat\" \n",
    "### (1.1)  add filter (\"sieves\") columns, apply SUB-TYPE FILTER in each \n",
    "###        cluster [\"nodata\", \"phot_only\",\"spec_only\",\"both\"], \n",
    "### (1.2)  add DIAG_FLAG_1: summarize in table \"sub_stats\"\n",
    "### (1.3)  convert flux to mag.,\n",
    "### (2) calculate various del_z's, \n",
    "### (2.1)  identify outliers\n",
    "### (2.2)  compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "### (3) distinguish b/w SF/Q: apply TYPE FILTER\n",
    "### (3.1)  add DIAG_FLAG_2: summarize in table \"type_stats\"\n",
    "### (4) make membership cuts to spec samples (i.e. apply MEMBER FILTER), add DIAG_FLAG_3: apply diagnostic to test different redshift cutoff (OUTPUT FILE: /Documents/Programs/Python/nserc17/HFF_ToAdamFinal/working_data/section_4_false_pos_neg_redshift_cuts_*.txt) \n",
    "### (4.1) add DIAG_FLAG_4: summarize in table \"SF_spec_stats\" & \"Q_spec_stats\"\n",
    "### (5) make membership cuts to phot samples\n",
    "### (5.1) add DIAG_FLAG_4: summarize in table \"SF_phot_stats\" & \"Q_phot_stats\"\n",
    "#\n",
    "### PROGRAM END\n",
    "#\n",
    "#\n",
    "#\n",
    "###################     PROGRAM START\n",
    "#\n",
    "#\n",
    "## MODULES\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "import spec_completeness_binning\n",
    "#\n",
    "#\n",
    "## TIME_FLAG: START\n",
    "## superior time_flag which supercedes all others and times the entire program\n",
    "time_flag = 0     # track & print time to execute current section\n",
    "#\n",
    "if time_flag == 1:\n",
    "    start_time = time.time()\n",
    "#\n",
    "#\n",
    "## MASTER diagnostic flag:   0=all flags off;   1=all flags on;    2=individual flags may be turned on\n",
    "diag_flag_master = 2\n",
    "#\n",
    "#\n",
    "# Read in ALL data from WORKING DIRECTORY: NSERC17/HFFtoAdam/working_data\n",
    "#\n",
    "##SECTION 1: import all data from HFF team, convert flux to luminosity & gather full \n",
    "#\n",
    "## TIME_FLAG_1 START\n",
    "time_flag_1 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "## import catalogues into single table \"master_cat\"; separate objects for which there is no redshift data (both photo & spec) as \"nodata\"\n",
    "#\n",
    "##create table from EAZY output redshift \".zout\" file\n",
    "z_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.zout',format='ascii')\n",
    "z_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.zout',format='ascii')\n",
    "z_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.zout',format='ascii')\n",
    "z_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.zout',format='ascii')\n",
    "z_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.zout',format='ascii')   \n",
    "z_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.zout',format='ascii') \n",
    "#   \n",
    "#create table from FAST \".fout\" file (contains mass estimates)\n",
    "f_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.fout',format='ascii')\n",
    "f_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.fout',format='ascii')\n",
    "f_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.fout',format='ascii')\n",
    "f_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.fout',format='ascii')\n",
    "f_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.fout',format='ascii')\n",
    "f_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.fout',format='ascii')\n",
    "#\n",
    "# rename columns of the .fout files because for some reason the column names didn't register\n",
    "col_names_old = ['col1','col2','col3','col4','col5','col6','col7','col8','col9','col10','col11']\n",
    "col_names_new = ['id','z','ltau','metal','lage','Av','lmass','lsfr','lssfr','la2t','chi2']\n",
    "for ii in range(len(col_names_new)):\n",
    "    f_macs0416.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs1149.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs0717.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell370.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell1063.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell2744.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "#\n",
    "##read in the whole bloody catalogue\n",
    "cat_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/hffds_macs0416clu_v3.9.cat',format='ascii')\n",
    "cat_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/hffds_macs1149clu_v3.9.cat',format='ascii')\n",
    "cat_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/hffds_macs0717clu_v3.9.cat',format='ascii')\n",
    "cat_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/hffds_abell370clu_v3.9.cat',format='ascii')\n",
    "cat_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/hffds_abell1063clu_v3.9.cat',format='ascii')\n",
    "cat_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/hffds_abell2744clu_v3.9.cat',format='ascii')\n",
    "#\n",
    "##creat table for colours\n",
    "#macs0416\n",
    "F0416_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.153.rf',format='ascii')\n",
    "F0416_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.155.rf',format='ascii')\n",
    "F0416_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.161.rf',format='ascii')\n",
    "#macs1149\n",
    "F1149_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.153.rf',format='ascii')\n",
    "F1149_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.155.rf',format='ascii')\n",
    "F1149_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.161.rf',format='ascii')\n",
    "#macs0717\n",
    "F0717_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.153.rf',format='ascii')\n",
    "F0717_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.155.rf',format='ascii')   \n",
    "F0717_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.161.rf',format='ascii')\n",
    "#abell370\n",
    "F370_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.153.rf',format='ascii')\n",
    "F370_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.155.rf',format='ascii')\n",
    "F370_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.161.rf',format='ascii')\n",
    "#abell1063\n",
    "F1063_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.153.rf',format='ascii')\n",
    "F1063_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.155.rf',format='ascii')\n",
    "F1063_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.161.rf',format='ascii')\n",
    "#abell2744\n",
    "F2744_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.153.rf',format='ascii')\n",
    "F2744_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.155.rf',format='ascii')\n",
    "F2744_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.161.rf',format='ascii')\n",
    "##aggregate into a single table\n",
    "macs0416 = Table([z_macs0416['id'],z_macs0416['z_peak'],z_macs0416['z_spec'],F0416_u['L153'],F0416_v['L155'],F0416_j['L161'],F0416_u['DM'],f_macs0416['lmass'],f_macs0416['lsfr'],f_macs0416['lssfr'],cat_macs0416['flux_radius'],cat_macs0416['star_flag'],cat_macs0416['use_phot'],cat_macs0416['f_F160W'],cat_macs0416['e_F160W'],cat_macs0416['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs1149 = Table([z_macs1149['id'],z_macs1149['z_peak'],z_macs1149['z_spec'],F1149_u['L153'],F1149_v['L155'],F1149_j['L161'],F1149_u['DM'],f_macs1149['lmass'],f_macs1149['lsfr'],f_macs1149['lssfr'],cat_macs1149['flux_radius'],cat_macs1149['star_flag'],cat_macs1149['use_phot'],cat_macs1149['f_F160W'],cat_macs1149['e_F160W'],cat_macs1149['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs0717 = Table([z_macs0717['id'],z_macs0717['z_peak'],z_macs0717['z_spec'],F0717_u['L153'],F0717_v['L155'],F0717_j['L161'],F0717_u['DM'],f_macs0717['lmass'],f_macs0717['lsfr'],f_macs0717['lssfr'],cat_macs0717['flux_radius'],cat_macs0717['star_flag'],cat_macs0717['use_phot'],cat_macs0717['f_F160W'],cat_macs0717['e_F160W'],cat_macs0717['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell370 = Table([z_abell370['id'],z_abell370['z_peak'],z_abell370['z_spec'],F370_u['L153'],F370_v['L155'],F370_j['L161'],F370_u['DM'],f_abell370['lmass'],f_abell370['lsfr'],f_abell370['lssfr'],cat_abell370['flux_radius'],cat_abell370['star_flag'],cat_abell370['use_phot'],cat_abell370['f_F160W'],cat_abell370['e_F160W'],cat_abell370['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell1063 = Table([z_abell1063['id'],z_abell1063['z_peak'],z_abell1063['z_spec'],F1063_u['L153'],F1063_v['L155'],F1063_j['L161'],F1063_u['DM'],f_abell1063['lmass'],f_abell1063['lsfr'],f_abell1063['lssfr'],cat_abell1063['flux_radius'],cat_abell1063['star_flag'],cat_abell1063['use_phot'],cat_abell1063['f_F160W'],cat_abell1063['e_F160W'],cat_abell1063['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell2744 = Table([z_abell2744['id'],z_abell2744['z_peak'],z_abell2744['z_spec'],F2744_u['L153'],F2744_v['L155'],F2744_j['L161'],F2744_u['DM'],f_abell2744['lmass'],f_abell2744['lsfr'],f_abell2744['lssfr'],cat_abell2744['flux_radius'],cat_abell2744['star_flag'],cat_abell2744['use_phot'],cat_abell2744['f_F160W'],cat_abell2744['e_F160W'],cat_abell2744['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "#\n",
    "#\n",
    "## NOTE: cat_*['flag_F160W'] identifies BCGs IN EACH FILTER. ***** CONFIRM w/ AM ***** that I'm using the right filter; BCGs are identified as ['flag_F160W']==4, see Shipley et al 2018. Section 3.9\n",
    "#\n",
    "## create columns and append to master_cat to identify sub-sample, type, \n",
    "## and fraction for catalogue: \n",
    "##   type: 0 = stars,  1 = SF,  2 = Q\n",
    "##   member:  0 = not in spec sub-sample,  1 = secure in cluster,  2 = secure in field\n",
    "##            3 = false positive,  4 = false negative\n",
    "## Note: \"member\" only applies to the spec sub-sample\n",
    "#\n",
    "D1 = Column([1]*len(macs0416),name='cluster')\n",
    "D2 = Column([2]*len(macs1149),name='cluster')        #cluster designation columns\n",
    "D3 = Column([3]*len(macs0717),name='cluster')\n",
    "D4 = Column([4]*len(abell370),name='cluster')\n",
    "D5 = Column([5]*len(abell1063),name='cluster')\n",
    "D6 = Column([6]*len(abell2744),name='cluster')\n",
    "#\n",
    "macs0416.add_column(D1)       \n",
    "macs1149.add_column(D2)\n",
    "macs0717.add_column(D3)\n",
    "abell370.add_column(D4)\n",
    "abell1063.add_column(D5)\n",
    "abell2744.add_column(D6)\n",
    "#\n",
    "global master_cat\n",
    "master_cat = Table(np.concatenate((macs0416,macs1149,macs0717,abell370,abell1063,abell2744), axis=0))  #create a master catalogue of all clusters\n",
    "#\n",
    "## add \"empty\" columns (with value set = 99) for the remaining sieves: sub, type, member for [phot or spec],[SF or Q],[cluster member, field, false pos/neg] respectively\n",
    "E1 = Column([-99]*len(master_cat), name='sub', dtype=np.int8)    # create columns\n",
    "E2 = Column([-99]*len(master_cat), name='type', dtype=np.int8)\n",
    "E3 = Column([-99]*len(master_cat), name='member', dtype=np.int8)\n",
    "master_cat.add_columns([E1,E2,E3],[-1,-1,-1])                   # add columns to the end of table\n",
    "#\n",
    "#\n",
    "## SECTION (1.1) - SUB-TYPE FILTER: this section classifies all objects as either:\n",
    "##  sub = 0: no data (neither spec. nor phot.)\n",
    "##  sub = 1: both\n",
    "##  sub = 2: phot only\n",
    "##  sub = 3: spec only\n",
    "##  sub = 4: stars\n",
    "#\n",
    "# sift for targets without no data, spec only, phot only, and both\n",
    "spec_only = np.array([0]*6)    # to keep track by cluster\n",
    "phot_only = np.array([0]*6)\n",
    "error = 0\n",
    "other = 0\n",
    "both = np.array([0]*6)\n",
    "no_data = np.array([0]*6)\n",
    "stars_sub = np.array([0]*6)\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] > 0:  #entries w/ both spectroscopy and photometry  (SPECTROSCOPIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:     # use_phot = 0 means bad photometry\n",
    "            for jj in range(len(spec_only)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        spec_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "        elif master_cat['use_phot'][counter] ==1:     # use_phot = 1 means good photometry\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of (spec & phot) objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        both[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 1          # APPLY FILTER: sub=1 for objects w/ BOTH SPEC & PHOT\n",
    "        else: error+=1                              # just to keep track of erroneous objects\n",
    "    elif master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] < 0:  #entries w/ spectroscopy alone\n",
    "        for jj in range(len(spec_only)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    spec_only[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] > 0:  #entries w/ photometry alone (PHOTOMETRIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        no_data[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "        elif master_cat['use_phot'][counter] ==1:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of phot only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        phot_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 2          # APPLY FILTER: sub=2 for objects w/ PHOT ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] < 0:  #entries w/ no z estimates at all\n",
    "        for jj in range(len(both)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    no_data[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "    else: other+=1\n",
    "#\n",
    "#\n",
    "## SECTION (1.2): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_1\n",
    "##  summarize data population as segregated above, and display in a table\n",
    "diag_flag_1 = 1             # 0=off (don't display diagnostic); 1=on (display diagnostic table)\n",
    "#\n",
    "if (diag_flag_1 == 1 and diag_flag_master == 2) or diag_flag_master ==1:\n",
    "    ## Summarize initial data stats in table\n",
    "    sub_names = Column(['total','spec & phot','only phot','spec only','no data','stars'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    sub0 = Column([np.sum([np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)]),np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)],name='Total')  # total column\n",
    "    sub_stats = Table([sub_names,sub0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        sub_col = Column([np.sum([both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]]),both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]],name=col_names[ii])  # add columns to table one cluster at a time\n",
    "        sub_stats.add_column(sub_col)\n",
    "    #\n",
    "    print('Catalogue by SUB-type:')\n",
    "    print(sub_stats)\n",
    "    print('Other skipped objects: %s'%other)\n",
    "#\n",
    "#\n",
    "## SECTION (1.3): convert FLUX TO MAGNITUDE; using well-known mag = -2.5*log_10(flux) + zero_pt. zero_pt = 25\n",
    "#\n",
    "# add columns for luminosity calculations\n",
    "empty_u = Column([99]*len(master_cat), name='L_u', dtype=np.float64)\n",
    "empty_v = Column([99]*len(master_cat), name='L_v', dtype=np.float64)\n",
    "empty_j = Column([99]*len(master_cat), name='L_j', dtype=np.float64)\n",
    "empty_uv = Column([99]*len(master_cat), name='uv', dtype=np.float64)\n",
    "empty_vj = Column([99]*len(master_cat), name='vj', dtype=np.float64)\n",
    "master_cat.add_columns([empty_u,empty_v,empty_j,empty_uv,empty_vj])\n",
    "#\n",
    "##convert flux to magnitude (erroneously labelled as luminosity, e.g. L_u for magnitude in UV), get color indices U-V, V-J, add to table\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat[counter]['sub'] ==0 or master_cat[counter]['sub'] ==3 or master_cat[counter]['sub'] ==4:      # skip objects w/ \"no data\" (sub=0); \"spec only\" (sub=3); \"stars\" (sub=4)\n",
    "        pass\n",
    "    else:\n",
    "        master_cat['L_u'][counter] = -2.5*np.log10(master_cat['u'][counter]) + 25\n",
    "        master_cat['L_v'][counter] = -2.5*np.log10(master_cat['v'][counter]) + 25\n",
    "        master_cat['L_j'][counter] = -2.5*np.log10(master_cat['j'][counter]) + 25\n",
    "        master_cat['uv'][counter] = master_cat['L_u'][counter] - master_cat['L_v'][counter]\n",
    "        master_cat['vj'][counter] = master_cat['L_v'][counter] - master_cat['L_j'][counter]\n",
    "#\n",
    "## TIME_FLAG_1 END\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    print(\"Section 1 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (2): calulate DEL_Z's & separate OUTLIERS\n",
    "#\n",
    "## TIME_FLAG_2 START\n",
    "time_flag_2 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "#####Note: the photometric redshift used is 'z_peak' column from data\n",
    "#\n",
    "#(i) calculate delta_z for targets w/ both z_spec & z_phot\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='del_z', dtype=np.float64))           # del_z = (z_phot - z_spec) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterspec', dtype=np.float64))   # del_z = (z_spec - z_cl) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterphot', dtype=np.float64))   # del_z = (z_phot - z_cl) / (1 + z_phot)\n",
    "#\n",
    "# store cluster redshifts; obtained from https://archive.stsci.edu/prepds/frontier/\n",
    "z_cluster = [0.396,0.543,0.545,0.375,0.348,0.308]\n",
    "#\n",
    "#calucalte del_z, z_clusterspec, z_clusterphot for outlier cut (defined above); these will be used to make cuts (member, field, false pos/neg) to spec sample, from which we will use relative fractions by mass to correct the photometric sample for completeness.\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:   # sub=1 identifies spec&phot subsample\n",
    "        master_cat['del_z'][counter] = ((master_cat['z_peak'][counter] - master_cat['z_spec'][counter]) / (1 + master_cat['z_spec'][counter]))\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterspec'][counter] = ((master_cat['z_spec'][counter] - z_cluster[ii]) / (1 + master_cat['z_spec'][counter]))\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "    elif master_cat['sub'][counter] == 2:   # sub=2 identifies phot-only subsample\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "#\n",
    "#\n",
    "## SECTION (2.1): separate OUTLIERS from both phot & spec sub-sample, defined as |del_z| < 0.15. apply FILTER TYPE = 3 for outliers;   \n",
    "#\n",
    "outliers = np.array([0]*6)      # initialize array to track outliers by cluster, for computing outlier fraction later\n",
    "sum_delz = []                   # for computing mean |del_z|\n",
    "count_stars = 0\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:                        # sub=1 for objects with both spec & phot; total # of such objects tracked by cluster above in the array called \"both\"\n",
    "        if np.abs(master_cat['del_z'][counter]) > 0.15:        # |del_z| > 0.15 for outliers, threshold chosen for historical reasons to facilitate comparison with other studies\n",
    "            master_cat['type'][counter] = 3                  # type=3 identifies outliers\n",
    "            for ii in range(len(outliers)):\n",
    "                if master_cat['cluster'][counter] == (ii+1):   # keep track of outliers by cluster\n",
    "                    outliers[ii]+=1\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))    # keep track of all |del_z| measurements for stats computation\n",
    "        else:\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))\n",
    "        if master_cat['type'][counter] == 3 and master_cat['star_flag'][counter] == 1:                  # overwrite designation for stars\n",
    "            master_cat['type'][counter] = 0                        # type=0 for stars\n",
    "            outliers-=1\n",
    "            count_stars+=1\n",
    "#\n",
    "#\n",
    "## SECTION (2.2): compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "#\n",
    "delz_mean = np.mean(sum_delz)\n",
    "delz_scatter = np.std(sum_delz)\n",
    "print('OUTLIERS total: %s' % np.sum(outliers))\n",
    "print('Outlier fraction: %s' % (np.sum(outliers)/np.sum(both)))\n",
    "print('|del_z| mean: %s'%delz_mean)\n",
    "print('|del_z| scatter: %s\\n'%delz_scatter)\n",
    "#\n",
    "## TIME_FLAG_2 END\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    print(\"Section 2 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#  \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (3): add FILTER TYPE: separate SF/Q for both subsamples based on van der Burg (2013) \n",
    "## colour criteria;    filter name: 'type'  IDs below\n",
    "##   0 = stars;  1 = SF (star-forming);    2 = Q (quiscient);    3 = outliers\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_3 START\n",
    "time_flag_3 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "SF_type = np.array([0]*6)                             # initialize arrays\n",
    "Q_type = np.array([0]*6)\n",
    "stars_type = np.array([0]*6)                          # count # of stars by cluster\n",
    "lost_type = np.array([0]*6)                           # objects lost due no data (sub=0), spec only (sub=3), \n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['star_flag'][counter] == 1:          # identify STARS, filter type=0\n",
    "        master_cat['type'][counter] = 0              \n",
    "        for ii in range(len(stars_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                stars_type[ii]+=1\n",
    "    elif master_cat['sub'][counter]==1 or master_cat['sub'][counter]==2:    # sub=1 for (spec & phot) subsample, sub=2 for phot subsample; i.e. look at all objects with photometry\n",
    "        if master_cat['uv'][counter] > 1.3 and master_cat['vj'][counter] < 1.6 and master_cat['uv'][counter] > ((0.88*master_cat[counter]['vj']) + 0.6): \n",
    "            if master_cat['type'][counter] !=3:             # skip outliers\n",
    "                master_cat['type'][counter] = 2             # identify passive (QUIESCENT) galaxies, type=2\n",
    "                for ii in range(len(Q_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        Q_type[ii]+=1\n",
    "        else:\n",
    "            if master_cat['type'][counter] !=3:             # skip outliers    \n",
    "                master_cat['type'][counter] = 1             # identify STAR-FORMING galaxies, type=1\n",
    "                for ii in range(len(SF_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        SF_type[ii]+=1\n",
    "    else:\n",
    "        for ii in range(len(lost_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                lost_type[ii]+=1      # objects lost due to spec only (sub=3),no data (sub=0), and possibly outliers (type=3) \n",
    "#        \n",
    "#\n",
    "## SECTION (3.1): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_2\n",
    "##  summarize data TYPE population as segregated above, and display in a table\n",
    "diag_flag_2 = 1\n",
    "#\n",
    "if (diag_flag_2 == 1 and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## Summarize initial data stats in table\n",
    "    type_names = Column(['Total','SF','Q','Outliers','Other'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    type0 = Column([np.sum([np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type),np.sum(stars_type)]),np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type+stars_type)],name='Total')  # total column\n",
    "    type_stats = Table([type_names,type0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        type_col = Column([np.sum([SF_type[ii],Q_type[ii],outliers[ii],lost_type[ii],stars_type[ii]]),SF_type[ii],Q_type[ii],outliers[ii],(lost_type[ii]+stars_type[ii])],name=col_names[ii])\n",
    "        type_stats.add_column(type_col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    print('Catalogue by TYPE:')\n",
    "    print(type_stats)\n",
    "    print('NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\\n')\n",
    "#\n",
    "## TIME_FLAG_3 END\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    print(\"Section 3 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION 4: apply MEMBER FILTER based on cuts discussed with AM in 2017 (see comments below), based on cuts made in VDB2013. MEMBER isolates: 0=cluster member (secure); 1=field (secure); 2=false pos; 3=false neg; write an interative loop which test varying values for redshift membership cutoffs, and print result to an output document. Then INSPECT BY EYE and pick the one you want, and hard code the cuts after the diag_flag_ loop\n",
    "#\n",
    "## CRITERIA:\n",
    "#\n",
    "## SF: cluster = 0: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) < 0.03; \n",
    "##      field = 1: abs(z_clusterspec) > 0.02 & abs(z_cluster phot) > 0.1; \n",
    "## false pos = 2: abs(z_clusterspec) > 0.01 & abs(z_cluster phot) < 0.03;\n",
    "## false neg = 3: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) > 0.03;\n",
    "## Q: same cutoff for z_clusterspec, cutoff for z_clusterphot > 0.07\n",
    "#\n",
    "## Note: this is only done for spec sample; results used to correct photo sample for completeness at end of analysis in file \"master_smf_8.py\"\n",
    "#\n",
    "### SF sub-sample: SF_spec into secure member, field, false pos/neg\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'master_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e8be0261bec9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mspec_completeness_binning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/spec_completeness_binning.py\u001b[0m in \u001b[0;36mbinning\u001b[0;34m(z_cutoff)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mobjects_below_lim_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# for tracking objects below the limiting mass of each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimiting_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m           \u001b[0;31m# only look at objects above the limiting mass for each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'master_cat' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "## TIME_FLAG_4 START\n",
    "time_flag_4 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_4 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#\n",
    "### MAY NEED TO EDIT ### diag_flag_3\n",
    "##  test different redshift cutoffs and print result to output document\n",
    "diag_flag_3 = 1\n",
    "#\n",
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "        spec_completeness_binning.binning(z_cutoff)\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## END of DIAGNOSTIC loop\n",
    "#\n",
    "else:\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff = [0.015,0.08]\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "    ##\n",
    "    ## open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/HFF_ToAdamFinal/working_data/section_4_false_pos_neg_redshift_cuts_001.txt','w+')\n",
    "    #\n",
    "    #for cutoff in range(len(z_cutoff)):\n",
    "    ##\n",
    "    ## INDENT HERE for diagnostic \n",
    "    mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "    field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "    pos = np.array([[0]*6]*2)\n",
    "    neg = np.array([[0]*6]*2)\n",
    "    other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "    lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "    #\n",
    "    ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "    for counter in range(len(master_cat)):\n",
    "        if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "            if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                    master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                    for ii in range(len(field[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                            field[0][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                    for ii in range(len(pos[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                            pos[0][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                    for ii in range(len(neg[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                            neg[0][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                    for ii in range(len(mem[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                            mem[0][ii]+=1\n",
    "                else: \n",
    "                    for ii in range(len(lost_due_to_buffer[0])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                            lost_due_to_buffer[0][ii]+=1\n",
    "            elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                    master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                    for ii in range(len(field[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                            field[1][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                    for ii in range(len(pos[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                            pos[1][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                    for ii in range(len(neg[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                            neg[1][ii]+=1\n",
    "                elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                    master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                    for ii in range(len(mem[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                            mem[1][ii]+=1\n",
    "                else: \n",
    "                    for ii in range(len(lost_due_to_buffer[1])):\n",
    "                        if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                            lost_due_to_buffer[1][ii]+=1\n",
    "        else: other_member+=1\n",
    "#\n",
    "zcut = str(np.round(z_cutoff[0]*1000)/1000)+space+str(np.round(z_cutoff[1]*100)/100)\n",
    "SF_1 = str(np.sum(mem[0]))      # cluster members\n",
    "SF_2 = str(np.sum(pos[0]))      # false pos\n",
    "SF_3 = str(np.sum(neg[0]))      # false neg\n",
    "SF_4 = str(mem_fraction[0])     # cluster membership fraction\n",
    "SF_5 = str((np.sum(pos[0])/np.sum(neg[0])))    # overall false pos/neg ratio\n",
    "entry_1 = zcut+space+'SF'+space+SF_1+space+SF_2+space+SF_3+space+SF_4+space+SF_5\n",
    "Q_1 = str(np.sum(mem[1]))\n",
    "Q_2 = str(np.sum(pos[1]))\n",
    "Q_3 = str(np.sum(neg[1]))\n",
    "Q_4 = str(mem_fraction[1])\n",
    "Q_5 = str((np.sum(pos[1])/np.sum(neg[1])))\n",
    "entry_2 = zcut+space+' Q'+space+Q_1+space+Q_2+space+Q_3+space+Q_4+space+Q_5            \n",
    "# print\n",
    "print(entry1+'\\n'+entry2+'\\n')\n",
    "#    \n",
    "## SECTION (4.1): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_4\n",
    "##  summarize data population as segregated above, and display in a table\n",
    "diag_flag_4 = 1\n",
    "#\n",
    "if (diag_flag_4 == 1 and diag_flag_master ==2) or diag_flag_master ==1:\n",
    "    ## Summarize initial data stats in table\n",
    "    member_names = Column(['Total','Secure member','Secure field','Fasle pos','False neg'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    # SF table\n",
    "    member0 = Column([np.sum(both),np.sum(mem[0]),np.sum(field[0]),np.sum(pos[0]),np.sum(neg[0])],name='Total')  # total column\n",
    "    SF_spec_stats = Table([member_names,member0])\n",
    "    for ii in range(len(mem[0])):\n",
    "        col = Column([both[ii],mem[0][ii],field[0][ii],pos[0][ii],neg[0][ii]],name=col_names[ii])\n",
    "        SF_spec_stats.add_column(col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    # Q table\n",
    "    member0 = Column([np.sum(both),np.sum(mem[1]),np.sum(field[1]),np.sum(pos[1]),np.sum(neg[1])],name='Total')  # total column\n",
    "    Q_spec_stats = Table([member_names,member0])\n",
    "    for ii in range(len(mem[1])):\n",
    "        col = Column([both[ii],mem[1][ii],field[1][ii],pos[1][ii],neg[1][ii]],name=col_names[ii])\n",
    "        Q_spec_stats.add_column(col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    print('(SPEC+PHOT) Subsample\\nCatalogue by MEMBER - Star-forming:')\n",
    "    print(SF_spec_stats)\n",
    "    print('NOTE: Total (row) reported under each cluster is sum of SF+Q.\\n')\n",
    "    print('Catalogue by MEMBER - Quiescent:')\n",
    "    print(Q_spec_stats)\n",
    "    print('NOTE: Total reported under each cluster is sum of SF+Q.')\n",
    "    print('NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\\n')\n",
    "#\n",
    "SF_specphot = np.sum([np.sum(mem[0]),np.sum(field[0]),np.sum(pos[0]),np.sum(neg[0])])\n",
    "Q_specphot = np.sum([np.sum(mem[1]),np.sum(field[1]),np.sum(pos[1]),np.sum(neg[1])])\n",
    "print('\\nOverall membership fraction: \\nSF: %s'%(np.sum(mem[0])/SF_specphot),' & Q: %s'%(np.sum(mem[1])/Q_specphot),'   for cutoff:\\n%s'%str(z_cutoff))\n",
    "#\n",
    "print('\\nTotal catalogue length: %s'%len(master_cat))\n",
    "print('SPEC+PHOT sub-sample: %s' % np.sum(both))\n",
    "print('SF: %s' % np.sum([mem[0],field[0],pos[0],neg[0]]))\n",
    "print('Q: %s' % np.sum([mem[1],field[1],pos[1],neg[1]]))\n",
    "print('Lost due to buffer b/w member & field\\nSF: %s'%np.sum(lost_due_to_buffer[0]),';    Q: %s'%np.sum(lost_due_to_buffer[1]))\n",
    "print('Other (not in (spec + phot) subsample): %s'%other_member)\n",
    "print('NOTE: Differences b/w Total row and sum of other rows might arise due to the \"buffer\" zone built in between classifying objects as secure member vs field.\\n')                        \n",
    "#\n",
    "## TIME_FLAG_4 END\n",
    "#\n",
    "if time_flag_4 == 1 and time_flag == 0:\n",
    "    print(\"Section 4 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'master_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-39efc0895380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mspec_completeness_binning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/spec_completeness_binning.py\u001b[0m in \u001b[0;36mbinning\u001b[0;34m(z_cutoff)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mobjects_below_lim_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# for tracking objects below the limiting mass of each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimiting_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m           \u001b[0;31m# only look at objects above the limiting mass for each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'master_cat' is not defined"
     ]
    }
   ],
   "source": [
    "##  test different redshift cutoffs and print result to output document\n",
    "diag_flag_3 = 1\n",
    "#\n",
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "        spec_completeness_binning.binning(z_cutoff)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'master_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-39efc0895380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mspec_completeness_binning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/spec_completeness_binning.py\u001b[0m in \u001b[0;36mbinning\u001b[0;34m(z_cutoff)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mneg_by_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mobjects_below_lim_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# for tracking objects below the limiting mass of each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimiting_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'master_cat' is not defined"
     ]
    }
   ],
   "source": [
    "##  test different redshift cutoffs and print result to output document\n",
    "diag_flag_3 = 1\n",
    "#\n",
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "        spec_completeness_binning.binning(z_cutoff)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (loading_test_file.py, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-3c9d96e9be25>\"\u001b[0;36m, line \u001b[0;32m88\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import loading_test_file\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/loading_test_file.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    false pos to false neg, and plot that ratio. it is the correction factor to be applied to the photometric subsample\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 24 10:23:11 2020\n",
    "\n",
    "@author: gsarrouh\n",
    "\"\"\"\n",
    "#### UPDATE 06/24/20 ####\n",
    "## The previous versions of this file all used HFF DR v3.5, a preliminary data release from the summer of 2017. The paper Shipley et al. 2018 (which I reference extensively in my work) corresponds to the finished data release, v3.9. That final, most up-tp-date data release is what is implemented in the following work. \n",
    "#\n",
    "#\n",
    "### WHAT THIS PROGRAM DOES:\n",
    "### This script reads in all data for the Hubble Frontier Fields images and prepares data for plotting and analysis. Key information is summarized in the tables: \n",
    "###     **\"sub_stats\",\"type_stats\",\"SF_spec_stats\",\"Q_spec_stats\",\"SF_phot_stats\",\"Q_phot_stats\"**\n",
    "#\n",
    "### Data is organized in a single catalogue (\"master_cat\"), and objects are identified through applying a series of \"FILTERS\" to designate key populations using a numerical designation for ease of writing code.\n",
    "#\n",
    "#\n",
    "## FILTER 1 - 'cluster':  cluster catalogues are designated as follows: \n",
    "## 1: macs0416\n",
    "## 2: macs1149\n",
    "## 3: macs0717\n",
    "## 4: abell370\n",
    "## 5: abell1063\n",
    "## 6: abell2744\n",
    "#\n",
    "## FILTER 2 - 'sub': :   identifies sub-type of data each object has\n",
    "## 0: no data (no photometry or spectroscopy)\n",
    "## 1: spectroscopy & photometry\n",
    "## 2: photometry only \n",
    "## 3: spectroscopy only  (there's just 3 in macs0717) \n",
    "## 4: star\n",
    "#\n",
    "## FILTER 3 - 'type': :   identifies type of data each object has\n",
    "## 0: star\n",
    "## 1: star-forming (SF)\n",
    "## 2: quiescent (Q)  \n",
    "## 3: outliers (defined as |del_z\\ > 0.15)\n",
    "#\n",
    "## FILTER 4 - 'member': :   identifies type of data each object has\n",
    "## NOTE: this designation is for objects with phot only (sub =2) and spec&phot (sub=1) only, as membership determinaion requires a good 'z_phot' estimate. as such, member=2 & =3 are for spec&phot (sub=1) subsample only, as only they can be classified as false pos/neg\n",
    "## 0: secure cluster member\n",
    "## 1: secure field    <-- this comprises the sample of field galaxies to be \n",
    "##                        compared with cluster, at similar redshifts\n",
    "## 2: false positive\n",
    "## 3: false negative\n",
    "## 4: field outlier   <-- objects well outside the redshift range of the clusters (e.g. z > 0.55)\n",
    "## 5: BCGs            <-- identified in the last section of the program, over-writing MEMBER assignment from section 4\n",
    "#\n",
    "#\n",
    "#\n",
    "### Section summary:\n",
    "#\n",
    "### PROGRAM START\n",
    "#\n",
    "### (1) import data into single table, creating KEY TABLE: \"master_cat\" \n",
    "### (1.1)  add filter (\"sieves\") columns, apply SUB-TYPE FILTER in each \n",
    "###        cluster [\"nodata\", \"phot_only\",\"spec_only\",\"both\"], \n",
    "### (1.2)  add DIAG_FLAG_1: summarize in table \"sub_stats\"\n",
    "### (1.3)  convert flux to mag.,\n",
    "### (2) calculate various del_z's, \n",
    "### (2.1)  identify outliers\n",
    "### (2.2)  compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "### (3) distinguish b/w SF/Q: apply TYPE FILTER\n",
    "### (3.1)  add DIAG_FLAG_2: summarize in table \"type_stats\"\n",
    "### (4) make membership cuts to spec samples (i.e. apply MEMBER FILTER), add DIAG_FLAG_3: apply diagnostic to test different redshift cutoff (OUTPUT FILE: /Documents/Programs/Python/nserc17/HFF_ToAdamFinal/working_data/section_4_false_pos_neg_redshift_cuts_*.txt) \n",
    "### (4.1) add DIAG_FLAG_4: summarize in table \"SF_spec_stats\" & \"Q_spec_stats\"\n",
    "### (5) make membership cuts to phot samples\n",
    "### (5.1) add DIAG_FLAG_4: summarize in table \"SF_phot_stats\" & \"Q_phot_stats\"\n",
    "#\n",
    "### PROGRAM END\n",
    "#\n",
    "#\n",
    "#\n",
    "###################     PROGRAM START\n",
    "#\n",
    "#\n",
    "## MODULES\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "import spec_completeness_binning\n",
    "import loading_test_file\n",
    "#\n",
    "#\n",
    "## TIME_FLAG: START\n",
    "## superior time_flag which supercedes all others and times the entire program\n",
    "time_flag = 0     # track & print time to execute current section\n",
    "#\n",
    "if time_flag == 1:\n",
    "    start_time = time.time()\n",
    "#\n",
    "#\n",
    "## MASTER diagnostic flag:   0=all flags off;   1=all flags on;    2=individual flags may be turned on\n",
    "diag_flag_master = 2\n",
    "#\n",
    "#\n",
    "# Read in ALL data from WORKING DIRECTORY: NSERC17/HFFtoAdam/working_data\n",
    "#\n",
    "##SECTION 1: import all data from HFF team, convert flux to luminosity & gather full \n",
    "#\n",
    "## TIME_FLAG_1 START\n",
    "time_flag_1 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "## import catalogues into single table \"master_cat\"; separate objects for which there is no redshift data (both photo & spec) as \"nodata\"\n",
    "#\n",
    "##create table from EAZY output redshift \".zout\" file\n",
    "z_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.zout',format='ascii')\n",
    "z_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.zout',format='ascii')\n",
    "z_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.zout',format='ascii')\n",
    "z_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.zout',format='ascii')\n",
    "z_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.zout',format='ascii')   \n",
    "z_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.zout',format='ascii') \n",
    "#   \n",
    "#create table from FAST \".fout\" file (contains mass estimates)\n",
    "f_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.fout',format='ascii')\n",
    "f_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.fout',format='ascii')\n",
    "f_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.fout',format='ascii')\n",
    "f_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.fout',format='ascii')\n",
    "f_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.fout',format='ascii')\n",
    "f_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.fout',format='ascii')\n",
    "#\n",
    "# rename columns of the .fout files because for some reason the column names didn't register\n",
    "col_names_old = ['col1','col2','col3','col4','col5','col6','col7','col8','col9','col10','col11']\n",
    "col_names_new = ['id','z','ltau','metal','lage','Av','lmass','lsfr','lssfr','la2t','chi2']\n",
    "for ii in range(len(col_names_new)):\n",
    "    f_macs0416.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs1149.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs0717.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell370.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell1063.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell2744.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "#\n",
    "##read in the whole bloody catalogue\n",
    "cat_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/hffds_macs0416clu_v3.9.cat',format='ascii')\n",
    "cat_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/hffds_macs1149clu_v3.9.cat',format='ascii')\n",
    "cat_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/hffds_macs0717clu_v3.9.cat',format='ascii')\n",
    "cat_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/hffds_abell370clu_v3.9.cat',format='ascii')\n",
    "cat_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/hffds_abell1063clu_v3.9.cat',format='ascii')\n",
    "cat_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/hffds_abell2744clu_v3.9.cat',format='ascii')\n",
    "#\n",
    "##creat table for colours\n",
    "#macs0416\n",
    "F0416_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.153.rf',format='ascii')\n",
    "F0416_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.155.rf',format='ascii')\n",
    "F0416_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.161.rf',format='ascii')\n",
    "#macs1149\n",
    "F1149_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.153.rf',format='ascii')\n",
    "F1149_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.155.rf',format='ascii')\n",
    "F1149_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.161.rf',format='ascii')\n",
    "#macs0717\n",
    "F0717_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.153.rf',format='ascii')\n",
    "F0717_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.155.rf',format='ascii')   \n",
    "F0717_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.161.rf',format='ascii')\n",
    "#abell370\n",
    "F370_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.153.rf',format='ascii')\n",
    "F370_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.155.rf',format='ascii')\n",
    "F370_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.161.rf',format='ascii')\n",
    "#abell1063\n",
    "F1063_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.153.rf',format='ascii')\n",
    "F1063_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.155.rf',format='ascii')\n",
    "F1063_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.161.rf',format='ascii')\n",
    "#abell2744\n",
    "F2744_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.153.rf',format='ascii')\n",
    "F2744_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.155.rf',format='ascii')\n",
    "F2744_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.161.rf',format='ascii')\n",
    "##aggregate into a single table\n",
    "macs0416 = Table([z_macs0416['id'],z_macs0416['z_peak'],z_macs0416['z_spec'],F0416_u['L153'],F0416_v['L155'],F0416_j['L161'],F0416_u['DM'],f_macs0416['lmass'],f_macs0416['lsfr'],f_macs0416['lssfr'],cat_macs0416['flux_radius'],cat_macs0416['star_flag'],cat_macs0416['use_phot'],cat_macs0416['f_F160W'],cat_macs0416['e_F160W'],cat_macs0416['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs1149 = Table([z_macs1149['id'],z_macs1149['z_peak'],z_macs1149['z_spec'],F1149_u['L153'],F1149_v['L155'],F1149_j['L161'],F1149_u['DM'],f_macs1149['lmass'],f_macs1149['lsfr'],f_macs1149['lssfr'],cat_macs1149['flux_radius'],cat_macs1149['star_flag'],cat_macs1149['use_phot'],cat_macs1149['f_F160W'],cat_macs1149['e_F160W'],cat_macs1149['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs0717 = Table([z_macs0717['id'],z_macs0717['z_peak'],z_macs0717['z_spec'],F0717_u['L153'],F0717_v['L155'],F0717_j['L161'],F0717_u['DM'],f_macs0717['lmass'],f_macs0717['lsfr'],f_macs0717['lssfr'],cat_macs0717['flux_radius'],cat_macs0717['star_flag'],cat_macs0717['use_phot'],cat_macs0717['f_F160W'],cat_macs0717['e_F160W'],cat_macs0717['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell370 = Table([z_abell370['id'],z_abell370['z_peak'],z_abell370['z_spec'],F370_u['L153'],F370_v['L155'],F370_j['L161'],F370_u['DM'],f_abell370['lmass'],f_abell370['lsfr'],f_abell370['lssfr'],cat_abell370['flux_radius'],cat_abell370['star_flag'],cat_abell370['use_phot'],cat_abell370['f_F160W'],cat_abell370['e_F160W'],cat_abell370['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell1063 = Table([z_abell1063['id'],z_abell1063['z_peak'],z_abell1063['z_spec'],F1063_u['L153'],F1063_v['L155'],F1063_j['L161'],F1063_u['DM'],f_abell1063['lmass'],f_abell1063['lsfr'],f_abell1063['lssfr'],cat_abell1063['flux_radius'],cat_abell1063['star_flag'],cat_abell1063['use_phot'],cat_abell1063['f_F160W'],cat_abell1063['e_F160W'],cat_abell1063['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell2744 = Table([z_abell2744['id'],z_abell2744['z_peak'],z_abell2744['z_spec'],F2744_u['L153'],F2744_v['L155'],F2744_j['L161'],F2744_u['DM'],f_abell2744['lmass'],f_abell2744['lsfr'],f_abell2744['lssfr'],cat_abell2744['flux_radius'],cat_abell2744['star_flag'],cat_abell2744['use_phot'],cat_abell2744['f_F160W'],cat_abell2744['e_F160W'],cat_abell2744['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "#\n",
    "#\n",
    "## NOTE: cat_*['flag_F160W'] identifies BCGs IN EACH FILTER. ***** CONFIRM w/ AM ***** that I'm using the right filter; BCGs are identified as ['flag_F160W']==4, see Shipley et al 2018. Section 3.9\n",
    "#\n",
    "## create columns and append to master_cat to identify sub-sample, type, \n",
    "## and fraction for catalogue: \n",
    "##   type: 0 = stars,  1 = SF,  2 = Q\n",
    "##   member:  0 = not in spec sub-sample,  1 = secure in cluster,  2 = secure in field\n",
    "##            3 = false positive,  4 = false negative\n",
    "## Note: \"member\" only applies to the spec sub-sample\n",
    "#\n",
    "D1 = Column([1]*len(macs0416),name='cluster')\n",
    "D2 = Column([2]*len(macs1149),name='cluster')        #cluster designation columns\n",
    "D3 = Column([3]*len(macs0717),name='cluster')\n",
    "D4 = Column([4]*len(abell370),name='cluster')\n",
    "D5 = Column([5]*len(abell1063),name='cluster')\n",
    "D6 = Column([6]*len(abell2744),name='cluster')\n",
    "#\n",
    "macs0416.add_column(D1)       \n",
    "macs1149.add_column(D2)\n",
    "macs0717.add_column(D3)\n",
    "abell370.add_column(D4)\n",
    "abell1063.add_column(D5)\n",
    "abell2744.add_column(D6)\n",
    "#\n",
    "global master_cat\n",
    "master_cat = Table(np.concatenate((macs0416,macs1149,macs0717,abell370,abell1063,abell2744), axis=0))  #create a master catalogue of all clusters\n",
    "#\n",
    "## add \"empty\" columns (with value set = 99) for the remaining sieves: sub, type, member for [phot or spec],[SF or Q],[cluster member, field, false pos/neg] respectively\n",
    "E1 = Column([-99]*len(master_cat), name='sub', dtype=np.int8)    # create columns\n",
    "E2 = Column([-99]*len(master_cat), name='type', dtype=np.int8)\n",
    "E3 = Column([-99]*len(master_cat), name='member', dtype=np.int8)\n",
    "master_cat.add_columns([E1,E2,E3],[-1,-1,-1])                   # add columns to the end of table\n",
    "#\n",
    "#\n",
    "## SECTION (1.1) - SUB-TYPE FILTER: this section classifies all objects as either:\n",
    "##  sub = 0: no data (neither spec. nor phot.)\n",
    "##  sub = 1: both\n",
    "##  sub = 2: phot only\n",
    "##  sub = 3: spec only\n",
    "##  sub = 4: stars\n",
    "#\n",
    "# sift for targets without no data, spec only, phot only, and both\n",
    "spec_only = np.array([0]*6)    # to keep track by cluster\n",
    "phot_only = np.array([0]*6)\n",
    "error = 0\n",
    "other = 0\n",
    "both = np.array([0]*6)\n",
    "no_data = np.array([0]*6)\n",
    "stars_sub = np.array([0]*6)\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] > 0:  #entries w/ both spectroscopy and photometry  (SPECTROSCOPIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:     # use_phot = 0 means bad photometry\n",
    "            for jj in range(len(spec_only)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        spec_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "        elif master_cat['use_phot'][counter] ==1:     # use_phot = 1 means good photometry\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of (spec & phot) objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        both[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 1          # APPLY FILTER: sub=1 for objects w/ BOTH SPEC & PHOT\n",
    "        else: error+=1                              # just to keep track of erroneous objects\n",
    "    elif master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] < 0:  #entries w/ spectroscopy alone\n",
    "        for jj in range(len(spec_only)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    spec_only[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] > 0:  #entries w/ photometry alone (PHOTOMETRIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        no_data[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "        elif master_cat['use_phot'][counter] ==1:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of phot only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        phot_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 2          # APPLY FILTER: sub=2 for objects w/ PHOT ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] < 0:  #entries w/ no z estimates at all\n",
    "        for jj in range(len(both)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    no_data[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "    else: other+=1\n",
    "#\n",
    "#\n",
    "## SECTION (1.2): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_1\n",
    "##  summarize data population as segregated above, and display in a table\n",
    "diag_flag_1 = 1             # 0=off (don't display diagnostic); 1=on (display diagnostic table)\n",
    "#\n",
    "if (diag_flag_1 == 1 and diag_flag_master == 2) or diag_flag_master ==1:\n",
    "    ## Summarize initial data stats in table\n",
    "    sub_names = Column(['total','spec & phot','only phot','spec only','no data','stars'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    sub0 = Column([np.sum([np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)]),np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)],name='Total')  # total column\n",
    "    sub_stats = Table([sub_names,sub0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        sub_col = Column([np.sum([both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]]),both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]],name=col_names[ii])  # add columns to table one cluster at a time\n",
    "        sub_stats.add_column(sub_col)\n",
    "    #\n",
    "    print('Catalogue by SUB-type:')\n",
    "    print(sub_stats)\n",
    "    print('Other skipped objects: %s'%other)\n",
    "#\n",
    "#\n",
    "## SECTION (1.3): convert FLUX TO MAGNITUDE; using well-known mag = -2.5*log_10(flux) + zero_pt. zero_pt = 25\n",
    "#\n",
    "# add columns for luminosity calculations\n",
    "empty_u = Column([99]*len(master_cat), name='L_u', dtype=np.float64)\n",
    "empty_v = Column([99]*len(master_cat), name='L_v', dtype=np.float64)\n",
    "empty_j = Column([99]*len(master_cat), name='L_j', dtype=np.float64)\n",
    "empty_uv = Column([99]*len(master_cat), name='uv', dtype=np.float64)\n",
    "empty_vj = Column([99]*len(master_cat), name='vj', dtype=np.float64)\n",
    "master_cat.add_columns([empty_u,empty_v,empty_j,empty_uv,empty_vj])\n",
    "#\n",
    "##convert flux to magnitude (erroneously labelled as luminosity, e.g. L_u for magnitude in UV), get color indices U-V, V-J, add to table\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat[counter]['sub'] ==0 or master_cat[counter]['sub'] ==3 or master_cat[counter]['sub'] ==4:      # skip objects w/ \"no data\" (sub=0); \"spec only\" (sub=3); \"stars\" (sub=4)\n",
    "        pass\n",
    "    else:\n",
    "        master_cat['L_u'][counter] = -2.5*np.log10(master_cat['u'][counter]) + 25\n",
    "        master_cat['L_v'][counter] = -2.5*np.log10(master_cat['v'][counter]) + 25\n",
    "        master_cat['L_j'][counter] = -2.5*np.log10(master_cat['j'][counter]) + 25\n",
    "        master_cat['uv'][counter] = master_cat['L_u'][counter] - master_cat['L_v'][counter]\n",
    "        master_cat['vj'][counter] = master_cat['L_v'][counter] - master_cat['L_j'][counter]\n",
    "#\n",
    "## TIME_FLAG_1 END\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    print(\"Section 1 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (2): calulate DEL_Z's & separate OUTLIERS\n",
    "#\n",
    "## TIME_FLAG_2 START\n",
    "time_flag_2 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "#####Note: the photometric redshift used is 'z_peak' column from data\n",
    "#\n",
    "#(i) calculate delta_z for targets w/ both z_spec & z_phot\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='del_z', dtype=np.float64))           # del_z = (z_phot - z_spec) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterspec', dtype=np.float64))   # del_z = (z_spec - z_cl) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterphot', dtype=np.float64))   # del_z = (z_phot - z_cl) / (1 + z_phot)\n",
    "#\n",
    "# store cluster redshifts; obtained from https://archive.stsci.edu/prepds/frontier/\n",
    "z_cluster = [0.396,0.543,0.545,0.375,0.348,0.308]\n",
    "#\n",
    "#calucalte del_z, z_clusterspec, z_clusterphot for outlier cut (defined above); these will be used to make cuts (member, field, false pos/neg) to spec sample, from which we will use relative fractions by mass to correct the photometric sample for completeness.\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:   # sub=1 identifies spec&phot subsample\n",
    "        master_cat['del_z'][counter] = ((master_cat['z_peak'][counter] - master_cat['z_spec'][counter]) / (1 + master_cat['z_spec'][counter]))\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterspec'][counter] = ((master_cat['z_spec'][counter] - z_cluster[ii]) / (1 + master_cat['z_spec'][counter]))\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "    elif master_cat['sub'][counter] == 2:   # sub=2 identifies phot-only subsample\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "#\n",
    "#\n",
    "## SECTION (2.1): separate OUTLIERS from both phot & spec sub-sample, defined as |del_z| < 0.15. apply FILTER TYPE = 3 for outliers;   \n",
    "#\n",
    "outliers = np.array([0]*6)      # initialize array to track outliers by cluster, for computing outlier fraction later\n",
    "sum_delz = []                   # for computing mean |del_z|\n",
    "count_stars = 0\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:                        # sub=1 for objects with both spec & phot; total # of such objects tracked by cluster above in the array called \"both\"\n",
    "        if np.abs(master_cat['del_z'][counter]) > 0.15:        # |del_z| > 0.15 for outliers, threshold chosen for historical reasons to facilitate comparison with other studies\n",
    "            master_cat['type'][counter] = 3                  # type=3 identifies outliers\n",
    "            for ii in range(len(outliers)):\n",
    "                if master_cat['cluster'][counter] == (ii+1):   # keep track of outliers by cluster\n",
    "                    outliers[ii]+=1\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))    # keep track of all |del_z| measurements for stats computation\n",
    "        else:\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))\n",
    "        if master_cat['type'][counter] == 3 and master_cat['star_flag'][counter] == 1:                  # overwrite designation for stars\n",
    "            master_cat['type'][counter] = 0                        # type=0 for stars\n",
    "            outliers-=1\n",
    "            count_stars+=1\n",
    "#\n",
    "#\n",
    "## SECTION (2.2): compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "#\n",
    "delz_mean = np.mean(sum_delz)\n",
    "delz_scatter = np.std(sum_delz)\n",
    "print('OUTLIERS total: %s' % np.sum(outliers))\n",
    "print('Outlier fraction: %s' % (np.sum(outliers)/np.sum(both)))\n",
    "print('|del_z| mean: %s'%delz_mean)\n",
    "print('|del_z| scatter: %s\\n'%delz_scatter)\n",
    "#\n",
    "## TIME_FLAG_2 END\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    print(\"Section 2 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#  \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (3): add FILTER TYPE: separate SF/Q for both subsamples based on van der Burg (2013) \n",
    "## colour criteria;    filter name: 'type'  IDs below\n",
    "##   0 = stars;  1 = SF (star-forming);    2 = Q (quiscient);    3 = outliers\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_3 START\n",
    "time_flag_3 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "SF_type = np.array([0]*6)                             # initialize arrays\n",
    "Q_type = np.array([0]*6)\n",
    "stars_type = np.array([0]*6)                          # count # of stars by cluster\n",
    "lost_type = np.array([0]*6)                           # objects lost due no data (sub=0), spec only (sub=3), \n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['star_flag'][counter] == 1:          # identify STARS, filter type=0\n",
    "        master_cat['type'][counter] = 0              \n",
    "        for ii in range(len(stars_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                stars_type[ii]+=1\n",
    "    elif master_cat['sub'][counter]==1 or master_cat['sub'][counter]==2:    # sub=1 for (spec & phot) subsample, sub=2 for phot subsample; i.e. look at all objects with photometry\n",
    "        if master_cat['uv'][counter] > 1.3 and master_cat['vj'][counter] < 1.6 and master_cat['uv'][counter] > ((0.88*master_cat[counter]['vj']) + 0.6): \n",
    "            if master_cat['type'][counter] !=3:             # skip outliers\n",
    "                master_cat['type'][counter] = 2             # identify passive (QUIESCENT) galaxies, type=2\n",
    "                for ii in range(len(Q_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        Q_type[ii]+=1\n",
    "        else:\n",
    "            if master_cat['type'][counter] !=3:             # skip outliers    \n",
    "                master_cat['type'][counter] = 1             # identify STAR-FORMING galaxies, type=1\n",
    "                for ii in range(len(SF_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        SF_type[ii]+=1\n",
    "    else:\n",
    "        for ii in range(len(lost_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                lost_type[ii]+=1      # objects lost due to spec only (sub=3),no data (sub=0), and possibly outliers (type=3) \n",
    "#        \n",
    "#\n",
    "## SECTION (3.1): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_2\n",
    "##  summarize data TYPE population as segregated above, and display in a table\n",
    "diag_flag_2 = 1\n",
    "#\n",
    "if (diag_flag_2 == 1 and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## Summarize initial data stats in table\n",
    "    type_names = Column(['Total','SF','Q','Outliers','Other'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    type0 = Column([np.sum([np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type),np.sum(stars_type)]),np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type+stars_type)],name='Total')  # total column\n",
    "    type_stats = Table([type_names,type0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        type_col = Column([np.sum([SF_type[ii],Q_type[ii],outliers[ii],lost_type[ii],stars_type[ii]]),SF_type[ii],Q_type[ii],outliers[ii],(lost_type[ii]+stars_type[ii])],name=col_names[ii])\n",
    "        type_stats.add_column(type_col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    print('Catalogue by TYPE:')\n",
    "    print(type_stats)\n",
    "    print('NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\\n')\n",
    "#\n",
    "## TIME_FLAG_3 END\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    print(\"Section 3 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION 4: apply MEMBER FILTER based on cuts discussed with AM in 2017 (see comments below), based on cuts made in VDB2013. MEMBER isolates: 0=cluster member (secure); 1=field (secure); 2=false pos; 3=false neg; write an interative loop which test varying values for redshift membership cutoffs, and print result to an output document. Then INSPECT BY EYE and pick the one you want, and hard code the cuts after the diag_flag_ loop\n",
    "#\n",
    "## CRITERIA:\n",
    "#\n",
    "## SF: cluster = 0: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) < 0.03; \n",
    "##      field = 1: abs(z_clusterspec) > 0.02 & abs(z_cluster phot) > 0.1; \n",
    "## false pos = 2: abs(z_clusterspec) > 0.01 & abs(z_cluster phot) < 0.03;\n",
    "## false neg = 3: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) > 0.03;\n",
    "## Q: same cutoff for z_clusterspec, cutoff for z_clusterphot > 0.07\n",
    "#\n",
    "## Note: this is only done for spec sample; results used to correct photo sample for completeness at end of analysis in file \"master_smf_8.py\"\n",
    "#\n",
    "### SF sub-sample: SF_spec into secure member, field, false pos/neg\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_4 START\n",
    "time_flag_4 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_4 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#\n",
    "### MAY NEED TO EDIT ### diag_flag_3\n",
    "##  test different redshift cutoffs and print result to output document\n",
    "diag_flag_3 = 1\n",
    "#\n",
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "        #spec_completeness_binning.binning(z_cutoff)\n",
    "        loading_test_file.binning(z_cutoff)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (loading_test_file.py, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/gsarrouh/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-3c9d96e9be25>\"\u001b[0;36m, line \u001b[0;32m88\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import loading_test_file\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/loading_test_file.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    false pos to false neg, and plot that ratio. it is the correction factor to be applied to the photometric subsample\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 24 10:23:11 2020\n",
    "\n",
    "@author: gsarrouh\n",
    "\"\"\"\n",
    "#### UPDATE 06/24/20 ####\n",
    "## The previous versions of this file all used HFF DR v3.5, a preliminary data release from the summer of 2017. The paper Shipley et al. 2018 (which I reference extensively in my work) corresponds to the finished data release, v3.9. That final, most up-tp-date data release is what is implemented in the following work. \n",
    "#\n",
    "#\n",
    "### WHAT THIS PROGRAM DOES:\n",
    "### This script reads in all data for the Hubble Frontier Fields images and prepares data for plotting and analysis. Key information is summarized in the tables: \n",
    "###     **\"sub_stats\",\"type_stats\",\"SF_spec_stats\",\"Q_spec_stats\",\"SF_phot_stats\",\"Q_phot_stats\"**\n",
    "#\n",
    "### Data is organized in a single catalogue (\"master_cat\"), and objects are identified through applying a series of \"FILTERS\" to designate key populations using a numerical designation for ease of writing code.\n",
    "#\n",
    "#\n",
    "## FILTER 1 - 'cluster':  cluster catalogues are designated as follows: \n",
    "## 1: macs0416\n",
    "## 2: macs1149\n",
    "## 3: macs0717\n",
    "## 4: abell370\n",
    "## 5: abell1063\n",
    "## 6: abell2744\n",
    "#\n",
    "## FILTER 2 - 'sub': :   identifies sub-type of data each object has\n",
    "## 0: no data (no photometry or spectroscopy)\n",
    "## 1: spectroscopy & photometry\n",
    "## 2: photometry only \n",
    "## 3: spectroscopy only  (there's just 3 in macs0717) \n",
    "## 4: star\n",
    "#\n",
    "## FILTER 3 - 'type': :   identifies type of data each object has\n",
    "## 0: star\n",
    "## 1: star-forming (SF)\n",
    "## 2: quiescent (Q)  \n",
    "## 3: outliers (defined as |del_z\\ > 0.15)\n",
    "#\n",
    "## FILTER 4 - 'member': :   identifies type of data each object has\n",
    "## NOTE: this designation is for objects with phot only (sub =2) and spec&phot (sub=1) only, as membership determinaion requires a good 'z_phot' estimate. as such, member=2 & =3 are for spec&phot (sub=1) subsample only, as only they can be classified as false pos/neg\n",
    "## 0: secure cluster member\n",
    "## 1: secure field    <-- this comprises the sample of field galaxies to be \n",
    "##                        compared with cluster, at similar redshifts\n",
    "## 2: false positive\n",
    "## 3: false negative\n",
    "## 4: field outlier   <-- objects well outside the redshift range of the clusters (e.g. z > 0.55)\n",
    "## 5: BCGs            <-- identified in the last section of the program, over-writing MEMBER assignment from section 4\n",
    "#\n",
    "#\n",
    "#\n",
    "### Section summary:\n",
    "#\n",
    "### PROGRAM START\n",
    "#\n",
    "### (1) import data into single table, creating KEY TABLE: \"master_cat\" \n",
    "### (1.1)  add filter (\"sieves\") columns, apply SUB-TYPE FILTER in each \n",
    "###        cluster [\"nodata\", \"phot_only\",\"spec_only\",\"both\"], \n",
    "### (1.2)  add DIAG_FLAG_1: summarize in table \"sub_stats\"\n",
    "### (1.3)  convert flux to mag.,\n",
    "### (2) calculate various del_z's, \n",
    "### (2.1)  identify outliers\n",
    "### (2.2)  compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "### (3) distinguish b/w SF/Q: apply TYPE FILTER\n",
    "### (3.1)  add DIAG_FLAG_2: summarize in table \"type_stats\"\n",
    "### (4) make membership cuts to spec samples (i.e. apply MEMBER FILTER), add DIAG_FLAG_3: apply diagnostic to test different redshift cutoff (OUTPUT FILE: /Documents/Programs/Python/nserc17/HFF_ToAdamFinal/working_data/section_4_false_pos_neg_redshift_cuts_*.txt) \n",
    "### (4.1) add DIAG_FLAG_4: summarize in table \"SF_spec_stats\" & \"Q_spec_stats\"\n",
    "### (5) make membership cuts to phot samples\n",
    "### (5.1) add DIAG_FLAG_4: summarize in table \"SF_phot_stats\" & \"Q_phot_stats\"\n",
    "#\n",
    "### PROGRAM END\n",
    "#\n",
    "#\n",
    "#\n",
    "###################     PROGRAM START\n",
    "#\n",
    "#\n",
    "## MODULES\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "import spec_completeness_binning\n",
    "import loading_test_file\n",
    "#\n",
    "#\n",
    "## TIME_FLAG: START\n",
    "## superior time_flag which supercedes all others and times the entire program\n",
    "time_flag = 0     # track & print time to execute current section\n",
    "#\n",
    "if time_flag == 1:\n",
    "    start_time = time.time()\n",
    "#\n",
    "#\n",
    "## MASTER diagnostic flag:   0=all flags off;   1=all flags on;    2=individual flags may be turned on\n",
    "diag_flag_master = 2\n",
    "#\n",
    "#\n",
    "# Read in ALL data from WORKING DIRECTORY: NSERC17/HFFtoAdam/working_data\n",
    "#\n",
    "##SECTION 1: import all data from HFF team, convert flux to luminosity & gather full \n",
    "#\n",
    "## TIME_FLAG_1 START\n",
    "time_flag_1 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "## import catalogues into single table \"master_cat\"; separate objects for which there is no redshift data (both photo & spec) as \"nodata\"\n",
    "#\n",
    "##create table from EAZY output redshift \".zout\" file\n",
    "z_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.zout',format='ascii')\n",
    "z_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.zout',format='ascii')\n",
    "z_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.zout',format='ascii')\n",
    "z_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.zout',format='ascii')\n",
    "z_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.zout',format='ascii')   \n",
    "z_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.zout',format='ascii') \n",
    "#   \n",
    "#create table from FAST \".fout\" file (contains mass estimates)\n",
    "f_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.fout',format='ascii')\n",
    "f_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.fout',format='ascii')\n",
    "f_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.fout',format='ascii')\n",
    "f_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.fout',format='ascii')\n",
    "f_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.fout',format='ascii')\n",
    "f_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.fout',format='ascii')\n",
    "#\n",
    "# rename columns of the .fout files because for some reason the column names didn't register\n",
    "col_names_old = ['col1','col2','col3','col4','col5','col6','col7','col8','col9','col10','col11']\n",
    "col_names_new = ['id','z','ltau','metal','lage','Av','lmass','lsfr','lssfr','la2t','chi2']\n",
    "for ii in range(len(col_names_new)):\n",
    "    f_macs0416.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs1149.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs0717.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell370.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell1063.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell2744.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "#\n",
    "##read in the whole bloody catalogue\n",
    "cat_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/hffds_macs0416clu_v3.9.cat',format='ascii')\n",
    "cat_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/hffds_macs1149clu_v3.9.cat',format='ascii')\n",
    "cat_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/hffds_macs0717clu_v3.9.cat',format='ascii')\n",
    "cat_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/hffds_abell370clu_v3.9.cat',format='ascii')\n",
    "cat_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/hffds_abell1063clu_v3.9.cat',format='ascii')\n",
    "cat_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/hffds_abell2744clu_v3.9.cat',format='ascii')\n",
    "#\n",
    "##creat table for colours\n",
    "#macs0416\n",
    "F0416_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.153.rf',format='ascii')\n",
    "F0416_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.155.rf',format='ascii')\n",
    "F0416_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.161.rf',format='ascii')\n",
    "#macs1149\n",
    "F1149_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.153.rf',format='ascii')\n",
    "F1149_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.155.rf',format='ascii')\n",
    "F1149_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.161.rf',format='ascii')\n",
    "#macs0717\n",
    "F0717_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.153.rf',format='ascii')\n",
    "F0717_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.155.rf',format='ascii')   \n",
    "F0717_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.161.rf',format='ascii')\n",
    "#abell370\n",
    "F370_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.153.rf',format='ascii')\n",
    "F370_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.155.rf',format='ascii')\n",
    "F370_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.161.rf',format='ascii')\n",
    "#abell1063\n",
    "F1063_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.153.rf',format='ascii')\n",
    "F1063_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.155.rf',format='ascii')\n",
    "F1063_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.161.rf',format='ascii')\n",
    "#abell2744\n",
    "F2744_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.153.rf',format='ascii')\n",
    "F2744_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.155.rf',format='ascii')\n",
    "F2744_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.161.rf',format='ascii')\n",
    "##aggregate into a single table\n",
    "macs0416 = Table([z_macs0416['id'],z_macs0416['z_peak'],z_macs0416['z_spec'],F0416_u['L153'],F0416_v['L155'],F0416_j['L161'],F0416_u['DM'],f_macs0416['lmass'],f_macs0416['lsfr'],f_macs0416['lssfr'],cat_macs0416['flux_radius'],cat_macs0416['star_flag'],cat_macs0416['use_phot'],cat_macs0416['f_F160W'],cat_macs0416['e_F160W'],cat_macs0416['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs1149 = Table([z_macs1149['id'],z_macs1149['z_peak'],z_macs1149['z_spec'],F1149_u['L153'],F1149_v['L155'],F1149_j['L161'],F1149_u['DM'],f_macs1149['lmass'],f_macs1149['lsfr'],f_macs1149['lssfr'],cat_macs1149['flux_radius'],cat_macs1149['star_flag'],cat_macs1149['use_phot'],cat_macs1149['f_F160W'],cat_macs1149['e_F160W'],cat_macs1149['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs0717 = Table([z_macs0717['id'],z_macs0717['z_peak'],z_macs0717['z_spec'],F0717_u['L153'],F0717_v['L155'],F0717_j['L161'],F0717_u['DM'],f_macs0717['lmass'],f_macs0717['lsfr'],f_macs0717['lssfr'],cat_macs0717['flux_radius'],cat_macs0717['star_flag'],cat_macs0717['use_phot'],cat_macs0717['f_F160W'],cat_macs0717['e_F160W'],cat_macs0717['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell370 = Table([z_abell370['id'],z_abell370['z_peak'],z_abell370['z_spec'],F370_u['L153'],F370_v['L155'],F370_j['L161'],F370_u['DM'],f_abell370['lmass'],f_abell370['lsfr'],f_abell370['lssfr'],cat_abell370['flux_radius'],cat_abell370['star_flag'],cat_abell370['use_phot'],cat_abell370['f_F160W'],cat_abell370['e_F160W'],cat_abell370['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell1063 = Table([z_abell1063['id'],z_abell1063['z_peak'],z_abell1063['z_spec'],F1063_u['L153'],F1063_v['L155'],F1063_j['L161'],F1063_u['DM'],f_abell1063['lmass'],f_abell1063['lsfr'],f_abell1063['lssfr'],cat_abell1063['flux_radius'],cat_abell1063['star_flag'],cat_abell1063['use_phot'],cat_abell1063['f_F160W'],cat_abell1063['e_F160W'],cat_abell1063['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell2744 = Table([z_abell2744['id'],z_abell2744['z_peak'],z_abell2744['z_spec'],F2744_u['L153'],F2744_v['L155'],F2744_j['L161'],F2744_u['DM'],f_abell2744['lmass'],f_abell2744['lsfr'],f_abell2744['lssfr'],cat_abell2744['flux_radius'],cat_abell2744['star_flag'],cat_abell2744['use_phot'],cat_abell2744['f_F160W'],cat_abell2744['e_F160W'],cat_abell2744['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "#\n",
    "#\n",
    "## NOTE: cat_*['flag_F160W'] identifies BCGs IN EACH FILTER. ***** CONFIRM w/ AM ***** that I'm using the right filter; BCGs are identified as ['flag_F160W']==4, see Shipley et al 2018. Section 3.9\n",
    "#\n",
    "## create columns and append to master_cat to identify sub-sample, type, \n",
    "## and fraction for catalogue: \n",
    "##   type: 0 = stars,  1 = SF,  2 = Q\n",
    "##   member:  0 = not in spec sub-sample,  1 = secure in cluster,  2 = secure in field\n",
    "##            3 = false positive,  4 = false negative\n",
    "## Note: \"member\" only applies to the spec sub-sample\n",
    "#\n",
    "D1 = Column([1]*len(macs0416),name='cluster')\n",
    "D2 = Column([2]*len(macs1149),name='cluster')        #cluster designation columns\n",
    "D3 = Column([3]*len(macs0717),name='cluster')\n",
    "D4 = Column([4]*len(abell370),name='cluster')\n",
    "D5 = Column([5]*len(abell1063),name='cluster')\n",
    "D6 = Column([6]*len(abell2744),name='cluster')\n",
    "#\n",
    "macs0416.add_column(D1)       \n",
    "macs1149.add_column(D2)\n",
    "macs0717.add_column(D3)\n",
    "abell370.add_column(D4)\n",
    "abell1063.add_column(D5)\n",
    "abell2744.add_column(D6)\n",
    "#\n",
    "global master_cat\n",
    "master_cat = Table(np.concatenate((macs0416,macs1149,macs0717,abell370,abell1063,abell2744), axis=0))  #create a master catalogue of all clusters\n",
    "#\n",
    "## add \"empty\" columns (with value set = 99) for the remaining sieves: sub, type, member for [phot or spec],[SF or Q],[cluster member, field, false pos/neg] respectively\n",
    "E1 = Column([-99]*len(master_cat), name='sub', dtype=np.int8)    # create columns\n",
    "E2 = Column([-99]*len(master_cat), name='type', dtype=np.int8)\n",
    "E3 = Column([-99]*len(master_cat), name='member', dtype=np.int8)\n",
    "master_cat.add_columns([E1,E2,E3],[-1,-1,-1])                   # add columns to the end of table\n",
    "#\n",
    "#\n",
    "## SECTION (1.1) - SUB-TYPE FILTER: this section classifies all objects as either:\n",
    "##  sub = 0: no data (neither spec. nor phot.)\n",
    "##  sub = 1: both\n",
    "##  sub = 2: phot only\n",
    "##  sub = 3: spec only\n",
    "##  sub = 4: stars\n",
    "#\n",
    "# sift for targets without no data, spec only, phot only, and both\n",
    "spec_only = np.array([0]*6)    # to keep track by cluster\n",
    "phot_only = np.array([0]*6)\n",
    "error = 0\n",
    "other = 0\n",
    "both = np.array([0]*6)\n",
    "no_data = np.array([0]*6)\n",
    "stars_sub = np.array([0]*6)\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] > 0:  #entries w/ both spectroscopy and photometry  (SPECTROSCOPIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:     # use_phot = 0 means bad photometry\n",
    "            for jj in range(len(spec_only)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        spec_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "        elif master_cat['use_phot'][counter] ==1:     # use_phot = 1 means good photometry\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of (spec & phot) objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        both[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 1          # APPLY FILTER: sub=1 for objects w/ BOTH SPEC & PHOT\n",
    "        else: error+=1                              # just to keep track of erroneous objects\n",
    "    elif master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] < 0:  #entries w/ spectroscopy alone\n",
    "        for jj in range(len(spec_only)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    spec_only[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] > 0:  #entries w/ photometry alone (PHOTOMETRIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        no_data[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "        elif master_cat['use_phot'][counter] ==1:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of phot only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        phot_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 2          # APPLY FILTER: sub=2 for objects w/ PHOT ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] < 0:  #entries w/ no z estimates at all\n",
    "        for jj in range(len(both)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    no_data[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "    else: other+=1\n",
    "#\n",
    "#\n",
    "## SECTION (1.2): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_1\n",
    "##  summarize data population as segregated above, and display in a table\n",
    "diag_flag_1 = 1             # 0=off (don't display diagnostic); 1=on (display diagnostic table)\n",
    "#\n",
    "if (diag_flag_1 == 1 and diag_flag_master == 2) or diag_flag_master ==1:\n",
    "    ## Summarize initial data stats in table\n",
    "    sub_names = Column(['total','spec & phot','only phot','spec only','no data','stars'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    sub0 = Column([np.sum([np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)]),np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)],name='Total')  # total column\n",
    "    sub_stats = Table([sub_names,sub0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        sub_col = Column([np.sum([both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]]),both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]],name=col_names[ii])  # add columns to table one cluster at a time\n",
    "        sub_stats.add_column(sub_col)\n",
    "    #\n",
    "    print('Catalogue by SUB-type:')\n",
    "    print(sub_stats)\n",
    "    print('Other skipped objects: %s'%other)\n",
    "#\n",
    "#\n",
    "## SECTION (1.3): convert FLUX TO MAGNITUDE; using well-known mag = -2.5*log_10(flux) + zero_pt. zero_pt = 25\n",
    "#\n",
    "# add columns for luminosity calculations\n",
    "empty_u = Column([99]*len(master_cat), name='L_u', dtype=np.float64)\n",
    "empty_v = Column([99]*len(master_cat), name='L_v', dtype=np.float64)\n",
    "empty_j = Column([99]*len(master_cat), name='L_j', dtype=np.float64)\n",
    "empty_uv = Column([99]*len(master_cat), name='uv', dtype=np.float64)\n",
    "empty_vj = Column([99]*len(master_cat), name='vj', dtype=np.float64)\n",
    "master_cat.add_columns([empty_u,empty_v,empty_j,empty_uv,empty_vj])\n",
    "#\n",
    "##convert flux to magnitude (erroneously labelled as luminosity, e.g. L_u for magnitude in UV), get color indices U-V, V-J, add to table\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat[counter]['sub'] ==0 or master_cat[counter]['sub'] ==3 or master_cat[counter]['sub'] ==4:      # skip objects w/ \"no data\" (sub=0); \"spec only\" (sub=3); \"stars\" (sub=4)\n",
    "        pass\n",
    "    else:\n",
    "        master_cat['L_u'][counter] = -2.5*np.log10(master_cat['u'][counter]) + 25\n",
    "        master_cat['L_v'][counter] = -2.5*np.log10(master_cat['v'][counter]) + 25\n",
    "        master_cat['L_j'][counter] = -2.5*np.log10(master_cat['j'][counter]) + 25\n",
    "        master_cat['uv'][counter] = master_cat['L_u'][counter] - master_cat['L_v'][counter]\n",
    "        master_cat['vj'][counter] = master_cat['L_v'][counter] - master_cat['L_j'][counter]\n",
    "#\n",
    "## TIME_FLAG_1 END\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    print(\"Section 1 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (2): calulate DEL_Z's & separate OUTLIERS\n",
    "#\n",
    "## TIME_FLAG_2 START\n",
    "time_flag_2 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "#####Note: the photometric redshift used is 'z_peak' column from data\n",
    "#\n",
    "#(i) calculate delta_z for targets w/ both z_spec & z_phot\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='del_z', dtype=np.float64))           # del_z = (z_phot - z_spec) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterspec', dtype=np.float64))   # del_z = (z_spec - z_cl) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterphot', dtype=np.float64))   # del_z = (z_phot - z_cl) / (1 + z_phot)\n",
    "#\n",
    "# store cluster redshifts; obtained from https://archive.stsci.edu/prepds/frontier/\n",
    "z_cluster = [0.396,0.543,0.545,0.375,0.348,0.308]\n",
    "#\n",
    "#calucalte del_z, z_clusterspec, z_clusterphot for outlier cut (defined above); these will be used to make cuts (member, field, false pos/neg) to spec sample, from which we will use relative fractions by mass to correct the photometric sample for completeness.\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:   # sub=1 identifies spec&phot subsample\n",
    "        master_cat['del_z'][counter] = ((master_cat['z_peak'][counter] - master_cat['z_spec'][counter]) / (1 + master_cat['z_spec'][counter]))\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterspec'][counter] = ((master_cat['z_spec'][counter] - z_cluster[ii]) / (1 + master_cat['z_spec'][counter]))\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "    elif master_cat['sub'][counter] == 2:   # sub=2 identifies phot-only subsample\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "#\n",
    "#\n",
    "## SECTION (2.1): separate OUTLIERS from both phot & spec sub-sample, defined as |del_z| < 0.15. apply FILTER TYPE = 3 for outliers;   \n",
    "#\n",
    "outliers = np.array([0]*6)      # initialize array to track outliers by cluster, for computing outlier fraction later\n",
    "sum_delz = []                   # for computing mean |del_z|\n",
    "count_stars = 0\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:                        # sub=1 for objects with both spec & phot; total # of such objects tracked by cluster above in the array called \"both\"\n",
    "        if np.abs(master_cat['del_z'][counter]) > 0.15:        # |del_z| > 0.15 for outliers, threshold chosen for historical reasons to facilitate comparison with other studies\n",
    "            master_cat['type'][counter] = 3                  # type=3 identifies outliers\n",
    "            for ii in range(len(outliers)):\n",
    "                if master_cat['cluster'][counter] == (ii+1):   # keep track of outliers by cluster\n",
    "                    outliers[ii]+=1\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))    # keep track of all |del_z| measurements for stats computation\n",
    "        else:\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))\n",
    "        if master_cat['type'][counter] == 3 and master_cat['star_flag'][counter] == 1:                  # overwrite designation for stars\n",
    "            master_cat['type'][counter] = 0                        # type=0 for stars\n",
    "            outliers-=1\n",
    "            count_stars+=1\n",
    "#\n",
    "#\n",
    "## SECTION (2.2): compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "#\n",
    "delz_mean = np.mean(sum_delz)\n",
    "delz_scatter = np.std(sum_delz)\n",
    "print('OUTLIERS total: %s' % np.sum(outliers))\n",
    "print('Outlier fraction: %s' % (np.sum(outliers)/np.sum(both)))\n",
    "print('|del_z| mean: %s'%delz_mean)\n",
    "print('|del_z| scatter: %s\\n'%delz_scatter)\n",
    "#\n",
    "## TIME_FLAG_2 END\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    print(\"Section 2 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#  \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (3): add FILTER TYPE: separate SF/Q for both subsamples based on van der Burg (2013) \n",
    "## colour criteria;    filter name: 'type'  IDs below\n",
    "##   0 = stars;  1 = SF (star-forming);    2 = Q (quiscient);    3 = outliers\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_3 START\n",
    "time_flag_3 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "SF_type = np.array([0]*6)                             # initialize arrays\n",
    "Q_type = np.array([0]*6)\n",
    "stars_type = np.array([0]*6)                          # count # of stars by cluster\n",
    "lost_type = np.array([0]*6)                           # objects lost due no data (sub=0), spec only (sub=3), \n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['star_flag'][counter] == 1:          # identify STARS, filter type=0\n",
    "        master_cat['type'][counter] = 0              \n",
    "        for ii in range(len(stars_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                stars_type[ii]+=1\n",
    "    elif master_cat['sub'][counter]==1 or master_cat['sub'][counter]==2:    # sub=1 for (spec & phot) subsample, sub=2 for phot subsample; i.e. look at all objects with photometry\n",
    "        if master_cat['uv'][counter] > 1.3 and master_cat['vj'][counter] < 1.6 and master_cat['uv'][counter] > ((0.88*master_cat[counter]['vj']) + 0.6): \n",
    "            if master_cat['type'][counter] !=3:             # skip outliers\n",
    "                master_cat['type'][counter] = 2             # identify passive (QUIESCENT) galaxies, type=2\n",
    "                for ii in range(len(Q_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        Q_type[ii]+=1\n",
    "        else:\n",
    "            if master_cat['type'][counter] !=3:             # skip outliers    \n",
    "                master_cat['type'][counter] = 1             # identify STAR-FORMING galaxies, type=1\n",
    "                for ii in range(len(SF_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        SF_type[ii]+=1\n",
    "    else:\n",
    "        for ii in range(len(lost_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                lost_type[ii]+=1      # objects lost due to spec only (sub=3),no data (sub=0), and possibly outliers (type=3) \n",
    "#        \n",
    "#\n",
    "## SECTION (3.1): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_2\n",
    "##  summarize data TYPE population as segregated above, and display in a table\n",
    "diag_flag_2 = 1\n",
    "#\n",
    "if (diag_flag_2 == 1 and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## Summarize initial data stats in table\n",
    "    type_names = Column(['Total','SF','Q','Outliers','Other'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    type0 = Column([np.sum([np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type),np.sum(stars_type)]),np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type+stars_type)],name='Total')  # total column\n",
    "    type_stats = Table([type_names,type0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        type_col = Column([np.sum([SF_type[ii],Q_type[ii],outliers[ii],lost_type[ii],stars_type[ii]]),SF_type[ii],Q_type[ii],outliers[ii],(lost_type[ii]+stars_type[ii])],name=col_names[ii])\n",
    "        type_stats.add_column(type_col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    print('Catalogue by TYPE:')\n",
    "    print(type_stats)\n",
    "    print('NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\\n')\n",
    "#\n",
    "## TIME_FLAG_3 END\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    print(\"Section 3 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION 4: apply MEMBER FILTER based on cuts discussed with AM in 2017 (see comments below), based on cuts made in VDB2013. MEMBER isolates: 0=cluster member (secure); 1=field (secure); 2=false pos; 3=false neg; write an interative loop which test varying values for redshift membership cutoffs, and print result to an output document. Then INSPECT BY EYE and pick the one you want, and hard code the cuts after the diag_flag_ loop\n",
    "#\n",
    "## CRITERIA:\n",
    "#\n",
    "## SF: cluster = 0: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) < 0.03; \n",
    "##      field = 1: abs(z_clusterspec) > 0.02 & abs(z_cluster phot) > 0.1; \n",
    "## false pos = 2: abs(z_clusterspec) > 0.01 & abs(z_cluster phot) < 0.03;\n",
    "## false neg = 3: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) > 0.03;\n",
    "## Q: same cutoff for z_clusterspec, cutoff for z_clusterphot > 0.07\n",
    "#\n",
    "## Note: this is only done for spec sample; results used to correct photo sample for completeness at end of analysis in file \"master_smf_8.py\"\n",
    "#\n",
    "### SF sub-sample: SF_spec into secure member, field, false pos/neg\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_4 START\n",
    "time_flag_4 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_4 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#\n",
    "### MAY NEED TO EDIT ### diag_flag_3\n",
    "##  test different redshift cutoffs and print result to output document\n",
    "diag_flag_3 = 1\n",
    "#\n",
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "        #spec_completeness_binning.binning(z_cutoff)\n",
    "        loading_test_file.binning(z_cutoff)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.rtf                    master_data_6.py\r\n",
      "Untitled.ipynb                master_data_7_final.py\r\n",
      "Untitled1.ipynb               master_dataz.py\r\n",
      "Untitled2.ipynb               master_parallel.py\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m/                  master_scrap.py\r\n",
      "data_completeness.py          master_smfz.py\r\n",
      "data_completeness_2.py        master_smfz_1.py\r\n",
      "data_completeness_3.py        master_smfz_1b.py\r\n",
      "data_completeness_3b.py       master_smfz_2.py\r\n",
      "data_mass_completeness_4.py   master_smfz_2b.py\r\n",
      "emcee_chi2_final.py           master_smfz_3.py\r\n",
      "emcee_initial_attempt.py      master_smfz_4.py\r\n",
      "field_hist.py                 master_smfz_5.py\r\n",
      "loading_test_file.py          master_smfz_6.py\r\n",
      "macs0416_data.py              master_smfz_6cl.py\r\n",
      "macs0416_zplots.py            master_smfz_7.py\r\n",
      "mass_mag.py                   master_smfz_8_final.py\r\n",
      "master_data.py                master_zplots.py\r\n",
      "master_data_1.py              master_zplots_1.py\r\n",
      "master_data_2.py              master_zplots_2_final.py\r\n",
      "master_data_3.py              scrap.py\r\n",
      "master_data_4.py              spec_completeness_binning.py\r\n",
      "master_data_4cl.py            untitled.txt\r\n",
      "master_data_5.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 15.79345989227295 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.5564370155334473 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.7139382362365723 seconds.\n",
      "\n",
      "\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'master_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-897e316676c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0mspec_completeness_binning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;31m#loading_test_file.binning(z_cutoff)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/spec_completeness_binning.py\u001b[0m in \u001b[0;36mbinning\u001b[0;34m(z_cutoff)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mneg_by_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mobjects_below_lim_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# for tracking objects below the limiting mass of each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimiting_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'master_cat' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 24 10:23:11 2020\n",
    "\n",
    "@author: gsarrouh\n",
    "\"\"\"\n",
    "#### UPDATE 06/24/20 ####\n",
    "## The previous versions of this file all used HFF DR v3.5, a preliminary data release from the summer of 2017. The paper Shipley et al. 2018 (which I reference extensively in my work) corresponds to the finished data release, v3.9. That final, most up-tp-date data release is what is implemented in the following work. \n",
    "#\n",
    "#\n",
    "### WHAT THIS PROGRAM DOES:\n",
    "### This script reads in all data for the Hubble Frontier Fields images and prepares data for plotting and analysis. Key information is summarized in the tables: \n",
    "###     **\"sub_stats\",\"type_stats\",\"SF_spec_stats\",\"Q_spec_stats\",\"SF_phot_stats\",\"Q_phot_stats\"**\n",
    "#\n",
    "### Data is organized in a single catalogue (\"master_cat\"), and objects are identified through applying a series of \"FILTERS\" to designate key populations using a numerical designation for ease of writing code.\n",
    "#\n",
    "#\n",
    "## FILTER 1 - 'cluster':  cluster catalogues are designated as follows: \n",
    "## 1: macs0416\n",
    "## 2: macs1149\n",
    "## 3: macs0717\n",
    "## 4: abell370\n",
    "## 5: abell1063\n",
    "## 6: abell2744\n",
    "#\n",
    "## FILTER 2 - 'sub': :   identifies sub-type of data each object has\n",
    "## 0: no data (no photometry or spectroscopy)\n",
    "## 1: spectroscopy & photometry\n",
    "## 2: photometry only \n",
    "## 3: spectroscopy only  (there's just 3 in macs0717) \n",
    "## 4: star\n",
    "#\n",
    "## FILTER 3 - 'type': :   identifies type of data each object has\n",
    "## 0: star\n",
    "## 1: star-forming (SF)\n",
    "## 2: quiescent (Q)  \n",
    "## 3: outliers (defined as |del_z\\ > 0.15)\n",
    "#\n",
    "## FILTER 4 - 'member': :   identifies type of data each object has\n",
    "## NOTE: this designation is for objects with phot only (sub =2) and spec&phot (sub=1) only, as membership determinaion requires a good 'z_phot' estimate. as such, member=2 & =3 are for spec&phot (sub=1) subsample only, as only they can be classified as false pos/neg\n",
    "## 0: secure cluster member\n",
    "## 1: secure field    <-- this comprises the sample of field galaxies to be \n",
    "##                        compared with cluster, at similar redshifts\n",
    "## 2: false positive\n",
    "## 3: false negative\n",
    "## 4: field outlier   <-- objects well outside the redshift range of the clusters (e.g. z > 0.55)\n",
    "## 5: BCGs            <-- identified in the last section of the program, over-writing MEMBER assignment from section 4\n",
    "#\n",
    "#\n",
    "#\n",
    "### Section summary:\n",
    "#\n",
    "### PROGRAM START\n",
    "#\n",
    "### (1) import data into single table, creating KEY TABLE: \"master_cat\" \n",
    "### (1.1)  add filter (\"sieves\") columns, apply SUB-TYPE FILTER in each \n",
    "###        cluster [\"nodata\", \"phot_only\",\"spec_only\",\"both\"], \n",
    "### (1.2)  add DIAG_FLAG_1: summarize in table \"sub_stats\"\n",
    "### (1.3)  convert flux to mag.,\n",
    "### (2) calculate various del_z's, \n",
    "### (2.1)  identify outliers\n",
    "### (2.2)  compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "### (3) distinguish b/w SF/Q: apply TYPE FILTER\n",
    "### (3.1)  add DIAG_FLAG_2: summarize in table \"type_stats\"\n",
    "### (4) make membership cuts to spec samples (i.e. apply MEMBER FILTER), add DIAG_FLAG_3: apply diagnostic to test different redshift cutoff (OUTPUT FILE: /Documents/Programs/Python/nserc17/HFF_ToAdamFinal/working_data/section_4_false_pos_neg_redshift_cuts_*.txt) \n",
    "### (4.1) add DIAG_FLAG_4: summarize in table \"SF_spec_stats\" & \"Q_spec_stats\"\n",
    "### (5) make membership cuts to phot samples\n",
    "### (5.1) add DIAG_FLAG_4: summarize in table \"SF_phot_stats\" & \"Q_phot_stats\"\n",
    "#\n",
    "### PROGRAM END\n",
    "#\n",
    "#\n",
    "#\n",
    "###################     PROGRAM START\n",
    "#\n",
    "#\n",
    "## MODULES\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "import spec_completeness_binning\n",
    "#import loading_test_file\n",
    "#\n",
    "#\n",
    "## TIME_FLAG: START\n",
    "## superior time_flag which supercedes all others and times the entire program\n",
    "time_flag = 0     # track & print time to execute current section\n",
    "#\n",
    "if time_flag == 1:\n",
    "    start_time = time.time()\n",
    "#\n",
    "#\n",
    "## MASTER diagnostic flag:   0=all flags off;   1=all flags on;    2=individual flags may be turned on\n",
    "diag_flag_master = 2\n",
    "#\n",
    "#\n",
    "# Read in ALL data from WORKING DIRECTORY: NSERC17/HFFtoAdam/working_data\n",
    "#\n",
    "##SECTION 1: import all data from HFF team, convert flux to luminosity & gather full \n",
    "#\n",
    "## TIME_FLAG_1 START\n",
    "time_flag_1 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "## import catalogues into single table \"master_cat\"; separate objects for which there is no redshift data (both photo & spec) as \"nodata\"\n",
    "#\n",
    "##create table from EAZY output redshift \".zout\" file\n",
    "z_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.zout',format='ascii')\n",
    "z_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.zout',format='ascii')\n",
    "z_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.zout',format='ascii')\n",
    "z_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.zout',format='ascii')\n",
    "z_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.zout',format='ascii')   \n",
    "z_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.zout',format='ascii') \n",
    "#   \n",
    "#create table from FAST \".fout\" file (contains mass estimates)\n",
    "f_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.fout',format='ascii')\n",
    "f_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.fout',format='ascii')\n",
    "f_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.fout',format='ascii')\n",
    "f_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.fout',format='ascii')\n",
    "f_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.fout',format='ascii')\n",
    "f_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.fout',format='ascii')\n",
    "#\n",
    "# rename columns of the .fout files because for some reason the column names didn't register\n",
    "col_names_old = ['col1','col2','col3','col4','col5','col6','col7','col8','col9','col10','col11']\n",
    "col_names_new = ['id','z','ltau','metal','lage','Av','lmass','lsfr','lssfr','la2t','chi2']\n",
    "for ii in range(len(col_names_new)):\n",
    "    f_macs0416.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs1149.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_macs0717.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell370.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell1063.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "    f_abell2744.rename_column(col_names_old[ii],col_names_new[ii])\n",
    "#\n",
    "##read in the whole bloody catalogue\n",
    "cat_macs0416 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/hffds_macs0416clu_v3.9.cat',format='ascii')\n",
    "cat_macs1149 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/hffds_macs1149clu_v3.9.cat',format='ascii')\n",
    "cat_macs0717 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/hffds_macs0717clu_v3.9.cat',format='ascii')\n",
    "cat_abell370 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/hffds_abell370clu_v3.9.cat',format='ascii')\n",
    "cat_abell1063 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/hffds_abell1063clu_v3.9.cat',format='ascii')\n",
    "cat_abell2744 = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/hffds_abell2744clu_v3.9.cat',format='ascii')\n",
    "#\n",
    "##creat table for colours\n",
    "#macs0416\n",
    "F0416_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.153.rf',format='ascii')\n",
    "F0416_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.155.rf',format='ascii')\n",
    "F0416_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0416clu_catalogs/macs0416clu_v3.9.161.rf',format='ascii')\n",
    "#macs1149\n",
    "F1149_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.153.rf',format='ascii')\n",
    "F1149_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.155.rf',format='ascii')\n",
    "F1149_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs1149clu_catalogs/macs1149clu_v3.9.161.rf',format='ascii')\n",
    "#macs0717\n",
    "F0717_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.153.rf',format='ascii')\n",
    "F0717_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.155.rf',format='ascii')   \n",
    "F0717_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/macs0717clu_catalogs/macs0717clu_v3.9.161.rf',format='ascii')\n",
    "#abell370\n",
    "F370_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.153.rf',format='ascii')\n",
    "F370_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.155.rf',format='ascii')\n",
    "F370_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell370clu_catalogs/abell370clu_v3.9.161.rf',format='ascii')\n",
    "#abell1063\n",
    "F1063_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.153.rf',format='ascii')\n",
    "F1063_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.155.rf',format='ascii')\n",
    "F1063_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell1063clu_catalogs/abell1063clu_v3.9.161.rf',format='ascii')\n",
    "#abell2744\n",
    "F2744_u = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.153.rf',format='ascii')\n",
    "F2744_v = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.155.rf',format='ascii')\n",
    "F2744_j = Table.read('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/abell2744clu_catalogs/abell2744clu_v3.9.161.rf',format='ascii')\n",
    "##aggregate into a single table\n",
    "macs0416 = Table([z_macs0416['id'],z_macs0416['z_peak'],z_macs0416['z_spec'],F0416_u['L153'],F0416_v['L155'],F0416_j['L161'],F0416_u['DM'],f_macs0416['lmass'],f_macs0416['lsfr'],f_macs0416['lssfr'],cat_macs0416['flux_radius'],cat_macs0416['star_flag'],cat_macs0416['use_phot'],cat_macs0416['f_F160W'],cat_macs0416['e_F160W'],cat_macs0416['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs1149 = Table([z_macs1149['id'],z_macs1149['z_peak'],z_macs1149['z_spec'],F1149_u['L153'],F1149_v['L155'],F1149_j['L161'],F1149_u['DM'],f_macs1149['lmass'],f_macs1149['lsfr'],f_macs1149['lssfr'],cat_macs1149['flux_radius'],cat_macs1149['star_flag'],cat_macs1149['use_phot'],cat_macs1149['f_F160W'],cat_macs1149['e_F160W'],cat_macs1149['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "macs0717 = Table([z_macs0717['id'],z_macs0717['z_peak'],z_macs0717['z_spec'],F0717_u['L153'],F0717_v['L155'],F0717_j['L161'],F0717_u['DM'],f_macs0717['lmass'],f_macs0717['lsfr'],f_macs0717['lssfr'],cat_macs0717['flux_radius'],cat_macs0717['star_flag'],cat_macs0717['use_phot'],cat_macs0717['f_F160W'],cat_macs0717['e_F160W'],cat_macs0717['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell370 = Table([z_abell370['id'],z_abell370['z_peak'],z_abell370['z_spec'],F370_u['L153'],F370_v['L155'],F370_j['L161'],F370_u['DM'],f_abell370['lmass'],f_abell370['lsfr'],f_abell370['lssfr'],cat_abell370['flux_radius'],cat_abell370['star_flag'],cat_abell370['use_phot'],cat_abell370['f_F160W'],cat_abell370['e_F160W'],cat_abell370['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell1063 = Table([z_abell1063['id'],z_abell1063['z_peak'],z_abell1063['z_spec'],F1063_u['L153'],F1063_v['L155'],F1063_j['L161'],F1063_u['DM'],f_abell1063['lmass'],f_abell1063['lsfr'],f_abell1063['lssfr'],cat_abell1063['flux_radius'],cat_abell1063['star_flag'],cat_abell1063['use_phot'],cat_abell1063['f_F160W'],cat_abell1063['e_F160W'],cat_abell1063['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "abell2744 = Table([z_abell2744['id'],z_abell2744['z_peak'],z_abell2744['z_spec'],F2744_u['L153'],F2744_v['L155'],F2744_j['L161'],F2744_u['DM'],f_abell2744['lmass'],f_abell2744['lsfr'],f_abell2744['lssfr'],cat_abell2744['flux_radius'],cat_abell2744['star_flag'],cat_abell2744['use_phot'],cat_abell2744['f_F160W'],cat_abell2744['e_F160W'],cat_abell2744['flag_F160W']], names=('id','z_peak','z_spec','u','v','j','DM','lmass','lsfr','lssfr','flux_radius','star_flag','use_phot','f_F160W','e_F160W','flag_F160W'))\n",
    "#\n",
    "#\n",
    "## NOTE: cat_*['flag_F160W'] identifies BCGs IN EACH FILTER. ***** CONFIRM w/ AM ***** that I'm using the right filter; BCGs are identified as ['flag_F160W']==4, see Shipley et al 2018. Section 3.9\n",
    "#\n",
    "## create columns and append to master_cat to identify sub-sample, type, \n",
    "## and fraction for catalogue: \n",
    "##   type: 0 = stars,  1 = SF,  2 = Q\n",
    "##   member:  0 = not in spec sub-sample,  1 = secure in cluster,  2 = secure in field\n",
    "##            3 = false positive,  4 = false negative\n",
    "## Note: \"member\" only applies to the spec sub-sample\n",
    "#\n",
    "D1 = Column([1]*len(macs0416),name='cluster')\n",
    "D2 = Column([2]*len(macs1149),name='cluster')        #cluster designation columns\n",
    "D3 = Column([3]*len(macs0717),name='cluster')\n",
    "D4 = Column([4]*len(abell370),name='cluster')\n",
    "D5 = Column([5]*len(abell1063),name='cluster')\n",
    "D6 = Column([6]*len(abell2744),name='cluster')\n",
    "#\n",
    "macs0416.add_column(D1)       \n",
    "macs1149.add_column(D2)\n",
    "macs0717.add_column(D3)\n",
    "abell370.add_column(D4)\n",
    "abell1063.add_column(D5)\n",
    "abell2744.add_column(D6)\n",
    "#\n",
    "global master_cat\n",
    "master_cat = Table(np.concatenate((macs0416,macs1149,macs0717,abell370,abell1063,abell2744), axis=0))  #create a master catalogue of all clusters\n",
    "#\n",
    "## add \"empty\" columns (with value set = 99) for the remaining sieves: sub, type, member for [phot or spec],[SF or Q],[cluster member, field, false pos/neg] respectively\n",
    "E1 = Column([-99]*len(master_cat), name='sub', dtype=np.int8)    # create columns\n",
    "E2 = Column([-99]*len(master_cat), name='type', dtype=np.int8)\n",
    "E3 = Column([-99]*len(master_cat), name='member', dtype=np.int8)\n",
    "master_cat.add_columns([E1,E2,E3],[-1,-1,-1])                   # add columns to the end of table\n",
    "#\n",
    "#\n",
    "## SECTION (1.1) - SUB-TYPE FILTER: this section classifies all objects as either:\n",
    "##  sub = 0: no data (neither spec. nor phot.)\n",
    "##  sub = 1: both\n",
    "##  sub = 2: phot only\n",
    "##  sub = 3: spec only\n",
    "##  sub = 4: stars\n",
    "#\n",
    "# sift for targets without no data, spec only, phot only, and both\n",
    "spec_only = np.array([0]*6)    # to keep track by cluster\n",
    "phot_only = np.array([0]*6)\n",
    "error = 0\n",
    "other = 0\n",
    "both = np.array([0]*6)\n",
    "no_data = np.array([0]*6)\n",
    "stars_sub = np.array([0]*6)\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] > 0:  #entries w/ both spectroscopy and photometry  (SPECTROSCOPIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:     # use_phot = 0 means bad photometry\n",
    "            for jj in range(len(spec_only)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        spec_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "        elif master_cat['use_phot'][counter] ==1:     # use_phot = 1 means good photometry\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of (spec & phot) objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        both[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 1          # APPLY FILTER: sub=1 for objects w/ BOTH SPEC & PHOT\n",
    "        else: error+=1                              # just to keep track of erroneous objects\n",
    "    elif master_cat['z_spec'][counter] > 0 and master_cat['z_peak'][counter] < 0:  #entries w/ spectroscopy alone\n",
    "        for jj in range(len(spec_only)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of spec only objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    spec_only[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 3          # APPLY FILTER: sub=3 for objects w/ SPEC ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] > 0:  #entries w/ photometry alone (PHOTOMETRIC sub-sample)\n",
    "        if master_cat['use_phot'][counter] ==0:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        no_data[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "        elif master_cat['use_phot'][counter] ==1:\n",
    "            for jj in range(len(both)):\n",
    "                if master_cat['cluster'][counter] == (jj+1):      # identify # of phot only objects by cluster\n",
    "                    if master_cat['star_flag'][counter] == 1:\n",
    "                        master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                        stars_sub[jj]+=1\n",
    "                    else:\n",
    "                        phot_only[(jj)]+=1\n",
    "                        master_cat['sub'][counter] = 2          # APPLY FILTER: sub=2 for objects w/ PHOT ONLY\n",
    "    elif master_cat['z_spec'][counter] < 0 and master_cat['z_peak'][counter] < 0:  #entries w/ no z estimates at all\n",
    "        for jj in range(len(both)):\n",
    "            if master_cat['cluster'][counter] == (jj+1):      # identify # of NO DATA objects by cluster\n",
    "                if master_cat['star_flag'][counter] == 1:\n",
    "                    master_cat['sub'][counter] = 4          # APPLY FILTER: sub=4 for STARS\n",
    "                    stars_sub[jj]+=1\n",
    "                else:\n",
    "                    no_data[(jj)]+=1\n",
    "                    master_cat['sub'][counter] = 0          # APPLY FILTER: sub=0 for objects w/ NEITHER SPEC NOR PHOT\n",
    "    else: other+=1\n",
    "#\n",
    "#\n",
    "## SECTION (1.2): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_1\n",
    "##  summarize data population as segregated above, and display in a table\n",
    "diag_flag_1 = 1             # 0=off (don't display diagnostic); 1=on (display diagnostic table)\n",
    "#\n",
    "if (diag_flag_1 == 1 and diag_flag_master == 2) or diag_flag_master ==1:\n",
    "    ## Summarize initial data stats in table\n",
    "    sub_names = Column(['total','spec & phot','only phot','spec only','no data','stars'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    sub0 = Column([np.sum([np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)]),np.sum(both),np.sum(phot_only),np.sum(spec_only),np.sum(no_data),np.sum(stars_sub)],name='Total')  # total column\n",
    "    sub_stats = Table([sub_names,sub0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        sub_col = Column([np.sum([both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]]),both[ii],phot_only[ii],spec_only[ii],no_data[ii],stars_sub[ii]],name=col_names[ii])  # add columns to table one cluster at a time\n",
    "        sub_stats.add_column(sub_col)\n",
    "    #\n",
    "    print('Catalogue by SUB-type:')\n",
    "    print(sub_stats)\n",
    "    print('Other skipped objects: %s'%other)\n",
    "#\n",
    "#\n",
    "## SECTION (1.3): convert FLUX TO MAGNITUDE; using well-known mag = -2.5*log_10(flux) + zero_pt. zero_pt = 25\n",
    "#\n",
    "# add columns for luminosity calculations\n",
    "empty_u = Column([99]*len(master_cat), name='L_u', dtype=np.float64)\n",
    "empty_v = Column([99]*len(master_cat), name='L_v', dtype=np.float64)\n",
    "empty_j = Column([99]*len(master_cat), name='L_j', dtype=np.float64)\n",
    "empty_uv = Column([99]*len(master_cat), name='uv', dtype=np.float64)\n",
    "empty_vj = Column([99]*len(master_cat), name='vj', dtype=np.float64)\n",
    "master_cat.add_columns([empty_u,empty_v,empty_j,empty_uv,empty_vj])\n",
    "#\n",
    "##convert flux to magnitude (erroneously labelled as luminosity, e.g. L_u for magnitude in UV), get color indices U-V, V-J, add to table\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat[counter]['sub'] ==0 or master_cat[counter]['sub'] ==3 or master_cat[counter]['sub'] ==4:      # skip objects w/ \"no data\" (sub=0); \"spec only\" (sub=3); \"stars\" (sub=4)\n",
    "        pass\n",
    "    else:\n",
    "        master_cat['L_u'][counter] = -2.5*np.log10(master_cat['u'][counter]) + 25\n",
    "        master_cat['L_v'][counter] = -2.5*np.log10(master_cat['v'][counter]) + 25\n",
    "        master_cat['L_j'][counter] = -2.5*np.log10(master_cat['j'][counter]) + 25\n",
    "        master_cat['uv'][counter] = master_cat['L_u'][counter] - master_cat['L_v'][counter]\n",
    "        master_cat['vj'][counter] = master_cat['L_v'][counter] - master_cat['L_j'][counter]\n",
    "#\n",
    "## TIME_FLAG_1 END\n",
    "#\n",
    "if time_flag_1 == 1 and time_flag == 0:\n",
    "    print(\"Section 1 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (2): calulate DEL_Z's & separate OUTLIERS\n",
    "#\n",
    "## TIME_FLAG_2 START\n",
    "time_flag_2 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "#####Note: the photometric redshift used is 'z_peak' column from data\n",
    "#\n",
    "#(i) calculate delta_z for targets w/ both z_spec & z_phot\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='del_z', dtype=np.float64))           # del_z = (z_phot - z_spec) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterspec', dtype=np.float64))   # del_z = (z_spec - z_cl) / (1 + z_spec)\n",
    "master_cat.add_column(Column([-99]*len(master_cat),name='z_clusterphot', dtype=np.float64))   # del_z = (z_phot - z_cl) / (1 + z_phot)\n",
    "#\n",
    "# store cluster redshifts; obtained from https://archive.stsci.edu/prepds/frontier/\n",
    "z_cluster = [0.396,0.543,0.545,0.375,0.348,0.308]\n",
    "#\n",
    "#calucalte del_z, z_clusterspec, z_clusterphot for outlier cut (defined above); these will be used to make cuts (member, field, false pos/neg) to spec sample, from which we will use relative fractions by mass to correct the photometric sample for completeness.\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:   # sub=1 identifies spec&phot subsample\n",
    "        master_cat['del_z'][counter] = ((master_cat['z_peak'][counter] - master_cat['z_spec'][counter]) / (1 + master_cat['z_spec'][counter]))\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterspec'][counter] = ((master_cat['z_spec'][counter] - z_cluster[ii]) / (1 + master_cat['z_spec'][counter]))\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "    elif master_cat['sub'][counter] == 2:   # sub=2 identifies phot-only subsample\n",
    "        for ii in range(len(z_cluster)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):\n",
    "                master_cat['z_clusterphot'][counter] = ((master_cat['z_peak'][counter] - z_cluster[ii]) / (1 + master_cat['z_peak'][counter]))\n",
    "#\n",
    "#\n",
    "## SECTION (2.1): separate OUTLIERS from both phot & spec sub-sample, defined as |del_z| < 0.15. apply FILTER TYPE = 3 for outliers;   \n",
    "#\n",
    "outliers = np.array([0]*6)      # initialize array to track outliers by cluster, for computing outlier fraction later\n",
    "sum_delz = []                   # for computing mean |del_z|\n",
    "count_stars = 0\n",
    "#\n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['sub'][counter] == 1:                        # sub=1 for objects with both spec & phot; total # of such objects tracked by cluster above in the array called \"both\"\n",
    "        if np.abs(master_cat['del_z'][counter]) > 0.15:        # |del_z| > 0.15 for outliers, threshold chosen for historical reasons to facilitate comparison with other studies\n",
    "            master_cat['type'][counter] = 3                  # type=3 identifies outliers\n",
    "            for ii in range(len(outliers)):\n",
    "                if master_cat['cluster'][counter] == (ii+1):   # keep track of outliers by cluster\n",
    "                    outliers[ii]+=1\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))    # keep track of all |del_z| measurements for stats computation\n",
    "        else:\n",
    "            sum_delz.append(np.abs(master_cat['del_z'][counter]))\n",
    "        if master_cat['type'][counter] == 3 and master_cat['star_flag'][counter] == 1:                  # overwrite designation for stars\n",
    "            master_cat['type'][counter] = 0                        # type=0 for stars\n",
    "            outliers-=1\n",
    "            count_stars+=1\n",
    "#\n",
    "#\n",
    "## SECTION (2.2): compute & DISPLAY OUTLIER FRACTION, SCATTER (i.e. std dev), and MEAN of |del_z|.\n",
    "#\n",
    "delz_mean = np.mean(sum_delz)\n",
    "delz_scatter = np.std(sum_delz)\n",
    "print('OUTLIERS total: %s' % np.sum(outliers))\n",
    "print('Outlier fraction: %s' % (np.sum(outliers)/np.sum(both)))\n",
    "print('|del_z| mean: %s'%delz_mean)\n",
    "print('|del_z| scatter: %s\\n'%delz_scatter)\n",
    "#\n",
    "## TIME_FLAG_2 END\n",
    "#\n",
    "if time_flag_2 == 1 and time_flag == 0:\n",
    "    print(\"Section 2 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#  \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION (3): add FILTER TYPE: separate SF/Q for both subsamples based on van der Burg (2013) \n",
    "## colour criteria;    filter name: 'type'  IDs below\n",
    "##   0 = stars;  1 = SF (star-forming);    2 = Q (quiscient);    3 = outliers\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_3 START\n",
    "time_flag_3 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#  \n",
    "SF_type = np.array([0]*6)                             # initialize arrays\n",
    "Q_type = np.array([0]*6)\n",
    "stars_type = np.array([0]*6)                          # count # of stars by cluster\n",
    "lost_type = np.array([0]*6)                           # objects lost due no data (sub=0), spec only (sub=3), \n",
    "for counter in range(len(master_cat)):\n",
    "    if master_cat['star_flag'][counter] == 1:          # identify STARS, filter type=0\n",
    "        master_cat['type'][counter] = 0              \n",
    "        for ii in range(len(stars_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                stars_type[ii]+=1\n",
    "    elif master_cat['sub'][counter]==1 or master_cat['sub'][counter]==2:    # sub=1 for (spec & phot) subsample, sub=2 for phot subsample; i.e. look at all objects with photometry\n",
    "        if master_cat['uv'][counter] > 1.3 and master_cat['vj'][counter] < 1.6 and master_cat['uv'][counter] > ((0.88*master_cat[counter]['vj']) + 0.6): \n",
    "            if master_cat['type'][counter] !=3:             # skip outliers\n",
    "                master_cat['type'][counter] = 2             # identify passive (QUIESCENT) galaxies, type=2\n",
    "                for ii in range(len(Q_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        Q_type[ii]+=1\n",
    "        else:\n",
    "            if master_cat['type'][counter] !=3:             # skip outliers    \n",
    "                master_cat['type'][counter] = 1             # identify STAR-FORMING galaxies, type=1\n",
    "                for ii in range(len(SF_type)):\n",
    "                    if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                        SF_type[ii]+=1\n",
    "    else:\n",
    "        for ii in range(len(lost_type)):\n",
    "            if master_cat['cluster'][counter] == (ii+1):   # keep stars of outliers by cluster\n",
    "                lost_type[ii]+=1      # objects lost due to spec only (sub=3),no data (sub=0), and possibly outliers (type=3) \n",
    "#        \n",
    "#\n",
    "## SECTION (3.1): SUMMARY table\n",
    "### MAY NEED TO EDIT ### diag_flag_2\n",
    "##  summarize data TYPE population as segregated above, and display in a table\n",
    "diag_flag_2 = 1\n",
    "#\n",
    "if (diag_flag_2 == 1 and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## Summarize initial data stats in table\n",
    "    type_names = Column(['Total','SF','Q','Outliers','Other'],name='Property')\n",
    "    col_names = ['macs0416','macs1149','macs0717','abell370','abell1063','abell2744']\n",
    "    type0 = Column([np.sum([np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type),np.sum(stars_type)]),np.sum(SF_type),np.sum(Q_type),np.sum(outliers),np.sum(lost_type+stars_type)],name='Total')  # total column\n",
    "    type_stats = Table([type_names,type0])\n",
    "    for ii in range(len(spec_only)):\n",
    "        type_col = Column([np.sum([SF_type[ii],Q_type[ii],outliers[ii],lost_type[ii],stars_type[ii]]),SF_type[ii],Q_type[ii],outliers[ii],(lost_type[ii]+stars_type[ii])],name=col_names[ii])\n",
    "        type_stats.add_column(type_col)  # add columns to table one cluster at a time\n",
    "    #\n",
    "    print('Catalogue by TYPE:')\n",
    "    print(type_stats)\n",
    "    print('NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\\n')\n",
    "#\n",
    "## TIME_FLAG_3 END\n",
    "#\n",
    "if time_flag_3 == 1 and time_flag == 0:\n",
    "    print(\"Section 3 took: %s seconds.\\n\\n\" % (time.time() - start_time))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## SECTION 4: apply MEMBER FILTER based on cuts discussed with AM in 2017 (see comments below), based on cuts made in VDB2013. MEMBER isolates: 0=cluster member (secure); 1=field (secure); 2=false pos; 3=false neg; write an interative loop which test varying values for redshift membership cutoffs, and print result to an output document. Then INSPECT BY EYE and pick the one you want, and hard code the cuts after the diag_flag_ loop\n",
    "#\n",
    "## CRITERIA:\n",
    "#\n",
    "## SF: cluster = 0: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) < 0.03; \n",
    "##      field = 1: abs(z_clusterspec) > 0.02 & abs(z_cluster phot) > 0.1; \n",
    "## false pos = 2: abs(z_clusterspec) > 0.01 & abs(z_cluster phot) < 0.03;\n",
    "## false neg = 3: abs(z_clusterspec) < 0.01 & abs(z_cluster phot) > 0.03;\n",
    "## Q: same cutoff for z_clusterspec, cutoff for z_clusterphot > 0.07\n",
    "#\n",
    "## Note: this is only done for spec sample; results used to correct photo sample for completeness at end of analysis in file \"master_smf_8.py\"\n",
    "#\n",
    "### SF sub-sample: SF_spec into secure member, field, false pos/neg\n",
    "#\n",
    "#\n",
    "## TIME_FLAG_4 START\n",
    "time_flag_4 = 1     # track & print time to execute current section\n",
    "#\n",
    "if time_flag_4 == 1 and time_flag == 0:\n",
    "    start_time = time.time()\n",
    "#\n",
    "### MAY NEED TO EDIT ### diag_flag_3\n",
    "##  test different redshift cutoffs and print result to output document\n",
    "diag_flag_3 = 1\n",
    "#\n",
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "        spec_completeness_binning.binning(z_cutoff)\n",
    "        #loading_test_file.binning(z_cutoff)\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loading_test_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f62fa9f7b58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m#spec_completeness_binning.binning(z_cutoff)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loading_test_file' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "        #spec_completeness_binning.binning(z_cutoff)\n",
    "        loading_test_file.binning(z_cutoff)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "## MODULES\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "import spec_completeness_binning\n",
    "import loading_test_file\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 15.792490005493164 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.6080291271209717 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.6826789379119873 seconds.\n",
      "\n",
      "\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mem_fraction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f62fa9f7b58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m#spec_completeness_binning.binning(z_cutoff)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/loading_test_file.py\u001b[0m in \u001b[0;36mbinning\u001b[0;34m(z_cutoff)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmaster_data_7_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/master_data_7_final.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0mSF_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# false pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0mSF_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# false neg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m \u001b[0mSF_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_fraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# cluster membership fraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0mSF_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# overall false pos/neg ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0mentry_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzcut\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'SF'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_4\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mem_fraction' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "        #spec_completeness_binning.binning(z_cutoff)\n",
    "        loading_test_file.binning(z_cutoff)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01\n",
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 15.700178384780884 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.568075180053711 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.6998660564422607 seconds.\n",
      "\n",
      "\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.01 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.015 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.019999999999999997 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.024999999999999998 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.03 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.034999999999999996 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.039999999999999994 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.045 folder already exists.\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/z_spec_0.049999999999999996 folder already exists.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mem_fraction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-2db4e8140240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m#spec_completeness_binning.binning(z_cutoff)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/loading_test_file.py\u001b[0m in \u001b[0;36mbinning\u001b[0;34m(z_cutoff)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfrom\u001b[0m  \u001b[0mmaster_data_7_final\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/master_data_7_final.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0mSF_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# false pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0mSF_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# false neg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m \u001b[0mSF_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_fraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# cluster membership fraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0mSF_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# overall false pos/neg ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0mentry_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzcut\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'SF'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_4\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSF_5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mem_fraction' is not defined"
     ]
    }
   ],
   "source": [
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "            #spec_completeness_binning.binning(z_cutoff)\n",
    "            loading_test_file.binning(z_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 15.205249071121216 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.6233439445495605 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.7651019096374512 seconds.\n",
      "\n",
      "\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n",
      "266790\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.015\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.015 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.015 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.015 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.015 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.015 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.015 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.015 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.015 folder already exists.\n",
      "266790\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.019999999999999997\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.019999999999999997 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.019999999999999997 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.019999999999999997 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.019999999999999997 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.019999999999999997 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.019999999999999997 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.019999999999999997 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.019999999999999997 folder already exists.\n",
      "266790\n",
      "created folder : /Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.024999999999999998\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.024999999999999998 folder already exists.\n",
      "266790\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.024999999999999998 folder already exists.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-76afcb1d5e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m#spec_completeness_binning.binning(z_cutoff)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/loading_test_file.py\u001b[0m in \u001b[0;36mbinning\u001b[0;34m(z_cutoff)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;31m#from  master_data_7_final import master_cat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/master_data_7_final.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    615\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mmaster_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# keep track of cluster members by cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                                     \u001b[0mlost_due_to_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mother_member\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0;31m## INDENT HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "            #spec_completeness_binning.binning(z_cutoff)\n",
    "            loading_test_file.binning(z_cutoff)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "binning() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-4893c3cc2498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m#spec_completeness_binning.binning(z_cutoff)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: binning() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "            #spec_completeness_binning.binning(z_cutoff)\n",
    "            loading_test_file.binning(master_cat,z_cutoff)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loading_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "binning() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-4893c3cc2498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m#spec_completeness_binning.binning(z_cutoff)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: binning() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "if (diag_flag_3 == 1  and diag_flag_master == 2) or diag_flag_master == 1:\n",
    "    ## the following code is part of a diagnostic to test the # of false pos/neg produced by altering the photometric/spectroscopic redshift cutoff. upon completion it will be commented out permenantly.\n",
    "    #\n",
    "    # define cut-offs for SF & Q\n",
    "    z_cutoff_spec = np.arange(0.01,0.055,0.005)       # create array from [0.01,0.05] in steps of 0.005; replace in loop below with z_cutoff once cutoffs are determined \n",
    "    z_cutoff_phot = np.arange(0.01,0.1,0.01)          # create array from [0.01,0.09] in steps of 0.01\n",
    "    #\n",
    "    #\n",
    "    ## these lists don't have a purpose but might come in handy later\n",
    "    ## cluster mass lists to see false pos/neg by mass bin by cluster\n",
    "    #SF_pos = [[],[],[],[],[],[]]\n",
    "    #SF_neg = [[],[],[],[],[],[]]\n",
    "    #Q_pos = [[],[],[],[],[],[]]\n",
    "    #Q_neg = [[],[],[],[],[],[]]    \n",
    "    #\n",
    "    #\n",
    "    ## DIAGNOSTIC loop to test different values of z_cutoff STARTS here\n",
    "        # open a file to print to\n",
    "    #f = open('/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/master_data_section_4_false_pos_neg_redshift_cuts_VARIATIONAL.txt','w+')\n",
    "    #\n",
    "    ## explain what the file does\n",
    "    #header1 = '\\n\\n### The following output lists cluster membership, false\\npos/neg, & overall false pos/neg ratio (see column\\nnames below). The program varies the spectroscopic\\nmembership cutoff in the range [0.01,0.05] in increments\\nof 0.005, testing all photometric cutoffs in the\\nrange [0.01,0.09] in increments of 0.01.'\n",
    "    #header2 = '\\n#\\n#\\n### Columns:  del_z cutoff  Type   Member   False pos.   False neg.   % acceptance   #   False pos/neg ratio\\n#\\n#\\n'\n",
    "    space = ' '\n",
    "    asterisks = '*********************************************************\\n*********************************************************'\n",
    "    #writer = asterisks+'%s\\n'%header1+asterisks+header2+'\\n'\n",
    "    #f.write(writer)\n",
    "    #\n",
    "    ## create file looping through different values for spec/phot membeship cutoff\n",
    "    for cutoff_spec in range(len(z_cutoff_spec)):\n",
    "        for cutoff_phot in range(len(z_cutoff_phot)):\n",
    "            #\n",
    "            ## define spec & phot cutoffs\n",
    "            z_cutoff = np.array([z_cutoff_spec[cutoff_spec],z_cutoff_phot[cutoff_phot]])\n",
    "            #\n",
    "            ## check it directories to store outputs exist. if not, create them\n",
    "            output_dir = '/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_%s'%z_cutoff[0]\n",
    "            check_folder = os.path.isdir(output_dir)\n",
    "            #\n",
    "            ## If folder doesn't exist, then create it.\n",
    "            if not check_folder:\n",
    "                os.makedirs(output_dir)\n",
    "                print(\"created folder : \"+output_dir)\n",
    "            else:\n",
    "                print(output_dir, \"folder already exists.\")\n",
    "            #\n",
    "            ## INDENT HERE for diagnostic \n",
    "            mem = np.array([[0]*6]*2)       # initialize arrays to track cluster members, field, false pos/neg by cluster\n",
    "            field = np.array([[0]*6]*2)     # row_1=SF; row_2=Q; for all arrays\n",
    "            pos = np.array([[0]*6]*2)\n",
    "            neg = np.array([[0]*6]*2)\n",
    "            other_member = 0                 # track objects outside of (phot + spec) subsample\n",
    "            lost_due_to_buffer = np.array([[0]*6]*2)\n",
    "            #\n",
    "            ## The following loop isolates the (spec + phot) sample, i.e. 'sub'=1, and makes the cuts defined above, assigning different classifications to the MEMBER FILTER \n",
    "            for counter in range(len(master_cat)):\n",
    "                if master_cat['sub'][counter] == 1:                   # sub=1 identifies subsample with both spec & phot\n",
    "                    if master_cat['type'][counter]==1:                # type=1 identifies SF sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[0][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #SF_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[0][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[0])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[0][ii]+=1\n",
    "                    elif master_cat['type'][counter]==2:                # type=2 identifies Q sample\n",
    "                        if abs(master_cat['z_clusterspec'][counter]) > 0.02 and abs(master_cat['z_clusterphot'][counter]) > 0.1: \n",
    "                            master_cat['member'][counter] = 1         # member=1 for FIELD\n",
    "                            for ii in range(len(field[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of field objects by cluster\n",
    "                                    field[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) > z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 2         # member=2 for FALSE POSITIVE\n",
    "                            for ii in range(len(pos[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false pos by cluster\n",
    "                                    pos[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) > z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 3         # member=3 for FALSE NEGATIVE\n",
    "                            for ii in range(len(neg[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of false neg by cluster\n",
    "                                    neg[1][ii]+=1\n",
    "                        elif abs(master_cat['z_clusterspec'][counter]) < z_cutoff[0] and abs(master_cat['z_clusterphot'][counter]) < z_cutoff[1]: #Q_cutoff[1]: #\n",
    "                            master_cat['member'][counter] = 0         # member=0 for cluster MEMBERS\n",
    "                            for ii in range(len(mem[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    mem[1][ii]+=1\n",
    "                        else: \n",
    "                            for ii in range(len(lost_due_to_buffer[1])):\n",
    "                                if master_cat['cluster'][counter] == (ii+1):  # keep track of cluster members by cluster\n",
    "                                    lost_due_to_buffer[1][ii]+=1\n",
    "                else: other_member+=1\n",
    "        ## INDENT HERE\n",
    "        #\n",
    "        ## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\n",
    "            #spec_completeness_binning.binning(z_cutoff)\n",
    "            loading_test_file.binning(master_cat,z_cutoff)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## MODULES\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "import time\n",
    "import spec_completeness_binning\n",
    "import loading_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "binning() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e2913b69da24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: binning() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "loading_test_file.binning(master_cat,z_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue by SUB-type:\n",
      "  Property  Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "----------- ----- -------- -------- -------- -------- --------- ---------\n",
      "      total 44465     7431     6868     6370     6795      7611      9390\n",
      "spec & phot  1916      378      334      260      216       227       501\n",
      "  only phot 33837     5846     5491     4908     5481      5669      6442\n",
      "  spec only   104       10       10       32        5         8        39\n",
      "    no data  8192     1152      994     1016     1033      1636      2361\n",
      "      stars   416       45       39      154       60        71        47\n",
      "Other skipped objects: 0\n",
      "Section 1 took: 15.487689018249512 seconds.\n",
      "\n",
      "\n",
      "OUTLIERS total: 152\n",
      "Outlier fraction: 0.07933194154488518\n",
      "|del_z| mean: 0.06808918655077978\n",
      "|del_z| scatter: 0.1667697660208093\n",
      "\n",
      "Section 2 took: 1.6485109329223633 seconds.\n",
      "\n",
      "\n",
      "Catalogue by TYPE:\n",
      "Property Total macs0416 macs1149 macs0717 abell370 abell1063 abell2744\n",
      "-------- ----- -------- -------- -------- -------- --------- ---------\n",
      "   Total 44465     7431     6868     6370     6795      7611      9390\n",
      "      SF 28883     5171     4777     3923     4632      4846      5534\n",
      "       Q  6718     1018     1035     1236     1044      1034      1351\n",
      "Outliers   152       35       13        9       21        16        58\n",
      "   Other  8712     1207     1043     1202     1098      1715      2447\n",
      "NOTE: \"Other\" is comprised of objects without photometry (i.e. stars, and objects with either bad photometry or both bad photometry and bad spectroscopy).\n",
      "\n",
      "Section 3 took: 1.8330299854278564 seconds.\n",
      "\n",
      "\n",
      "/Users/gsarrouh/Documents/Programs/Python/nserc17/working_data/diagnostic_outputs/spec_binning/z_spec_0.01 folder already exists.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "binning() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e5fed48dbcc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloading_test_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/loading_test_file.py\u001b[0m in \u001b[0;36mbinning\u001b[0;34m(z_cutoff)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;31m#from  master_data_7_final import master_cat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programs/Python/nserc17/working_data/HFF_environmental_quenching/master_data_7_final.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m## Now call the \"binning\" function from \"spec_completeness_binning.py\", which takes z_cutoff[spec,phot] as argument. this file will evaluate different binning options for false pos/neg in order to find the combination of z_cutoff[spec,phot] which yields correction factors clostest to 1 overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;31m#spec_completeness_binning.binning(z_cutoff)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: binning() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import loading_test_file\n",
    "loading_test_file.binning(z_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "binning() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e2913b69da24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloading_test_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: binning() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "loading_test_file.binning(master_cat,z_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
